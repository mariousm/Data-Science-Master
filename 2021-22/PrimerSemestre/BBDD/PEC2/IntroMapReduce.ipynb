{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zXPKUv8W1Uso"
   },
   "source": [
    "# Introducción a MapReduce\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zYJDYb3v1bS1"
   },
   "source": [
    "En este notebook vamos a ver la técnica MapReduce, que es una técnica ampliamente utilizada para tratar grandes cantidades de datos. Existen múltiples implementaciones de MapReduce, incluido el famoso Apache Hadoop. Vamos a ver el concepto de forma intuitiva y con algunos ejemplos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GKUVZIC81_Lq"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "# This is formatted as code\n",
    "```\n",
    "\n",
    "Comenzaremos con una tarea básica: dada una lista de cadenas de texto, buscar cual es la cadena más larga. Esto es bastante simple de hacer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 843,
     "status": "ok",
     "timestamp": 1634578549141,
     "user": {
      "displayName": "Jordi Conesa Caralt",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjoNn57kIwM1shjaORJcHiJsfMjG6Lqnp7apqYXPg=s64",
      "userId": "06942367536565960417"
     },
     "user_tz": -120
    },
    "id": "EhOBy4Hn1Fq8"
   },
   "outputs": [],
   "source": [
    "def find_longest_string(list_of_strings):\n",
    "    longest_string = None\n",
    "    longest_string_len = 0 \n",
    "    for s in list_of_strings:\n",
    "        if len(s) >= longest_string_len:\n",
    "            longest_string_len = len(s)\n",
    "            longest_string = s\n",
    "    return longest_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w9IrOatR2awf"
   },
   "source": [
    "Para una pequeña lista esto funciona razonablemente rápido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 246,
     "status": "ok",
     "timestamp": 1634578554929,
     "user": {
      "displayName": "Jordi Conesa Caralt",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjoNn57kIwM1shjaORJcHiJsfMjG6Lqnp7apqYXPg=s64",
      "userId": "06942367536565960417"
     },
     "user_tz": -120
    },
    "id": "4I40x51n1SwL",
    "outputId": "6e77ac65-fbc0-454f-dff6-4aa6e7a89f8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python\n",
      "CPU times: user 1.93 ms, sys: 0 ns, total: 1.93 ms\n",
      "Wall time: 1.79 ms\n"
     ]
    }
   ],
   "source": [
    "list_of_strings = ['abc', 'python', 'wxyz']\n",
    "\n",
    "%time max_length = print(find_longest_string(list_of_strings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O-Svy2HV2yRs"
   },
   "source": [
    "Pero si en vez de 3 elementos tuviéramos 30.000.000?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2154,
     "status": "ok",
     "timestamp": 1634578567221,
     "user": {
      "displayName": "Jordi Conesa Caralt",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjoNn57kIwM1shjaORJcHiJsfMjG6Lqnp7apqYXPg=s64",
      "userId": "06942367536565960417"
     },
     "user_tz": -120
    },
    "id": "ca3Epi8I2vwF",
    "outputId": "530a9f22-b974-408a-9121-1dc8740c2738"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.37 s, sys: 4.33 ms, total: 1.37 s\n",
      "Wall time: 1.37 s\n"
     ]
    }
   ],
   "source": [
    "large_list_of_strings = list_of_strings*10000000\n",
    "%time max_length = max(large_list_of_strings, key=len)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "go4O2RJL3T3s"
   },
   "source": [
    "El tiempo de respuesta es ya de algunos segundos para una operación muy simple.\n",
    "\n",
    "Una forma de mejorar el tiempo de cálculo es usando una CPU más potente y más rápida. El escalado de su sistema mediante el uso de hardware mejor y más rápido se denomina **escalado vertical**. Pero está solución no funciona siempre o no es posible.\n",
    "\n",
    "En vez de esa opción, se podría intentar un **escalado horizontal**, diseñando el código para que pueda ejecutarse en paralelo y ser más rápido cuando se añadan más procesadores o CPUs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xPLopFr94rOp"
   },
   "source": [
    "Para hacer eso, hay que dividir el código en componentes más pequeños y ejecutar cálculos en paralelo de la siguiente manera:\n",
    "\n",
    "1.   dividir nuestros datos en fragmentos,\n",
    "2.   ejecutar la función `find_longest_string` en cada fragmento en paralelo y\n",
    "3.  encontrar la cadena más larga entre las salidas de todos los fragmentos.\n",
    "\n",
    "El código de la función `find_longest_string` lo vamos a dividir en dos pasos:\n",
    "\n",
    "1.   Calcular la longitud `len` de todas las cadenas\n",
    "2.   Obtener el valor máximo `max`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6276,
     "status": "ok",
     "timestamp": 1634578647672,
     "user": {
      "displayName": "Jordi Conesa Caralt",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjoNn57kIwM1shjaORJcHiJsfMjG6Lqnp7apqYXPg=s64",
      "userId": "06942367536565960417"
     },
     "user_tz": -120
    },
    "id": "8hTYpfX_3MZ6",
    "outputId": "04064d96-5c60-4144-9b2e-bf94edb8e26a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('python', 6)\n",
      "CPU times: user 5.56 s, sys: 455 ms, total: 6.01 s\n",
      "Wall time: 6.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# paso 1:\n",
    "list_of_string_lens = [len(s) for s in large_list_of_strings]\n",
    "list_of_string_lens = zip(large_list_of_strings, list_of_string_lens)\n",
    "\n",
    "# paso 2:\n",
    "max_len = max(list_of_string_lens, key=lambda t: t[1])\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qO3i8A7z6Q85"
   },
   "source": [
    "Ahora el código se ejecuta bastante más lento que antes porque en lugar de realizar una sola pasada por todas las cadenas, hace 2:  una para calcular la longitud y otra para encontrar el valor máximo. \n",
    "\n",
    "Entonces el paso 2 no tiene como entrada la lista original de cadenas sino los datos preprocesados. El paso 1 es un mapeador (***map***) pues asigna un valor a otro valor y el paso dos es un reductor (***reduce***) porque obtiene una lista de valores y produce un valor único.\n",
    "\n",
    "```\n",
    "mapper = len\n",
    "\n",
    "def reducer (p,c):\n",
    "    if p[1] > c[1]:\n",
    "        return p\n",
    "    return c\n",
    "```\n",
    "\n",
    "Reescribiendo el código utilizando funciones incluidas en Python `map` y `reduce`, incluidas en la librería `functools`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6421,
     "status": "ok",
     "timestamp": 1634578690483,
     "user": {
      "displayName": "Jordi Conesa Caralt",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjoNn57kIwM1shjaORJcHiJsfMjG6Lqnp7apqYXPg=s64",
      "userId": "06942367536565960417"
     },
     "user_tz": -120
    },
    "id": "0LNFbBa36CcM",
    "outputId": "673fd520-0e6e-4355-ea91-081156ebd7d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.79 s, sys: 8.33 ms, total: 5.8 s\n",
      "Wall time: 5.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import functools\n",
    "\n",
    "\n",
    "# paso 1\n",
    "mapped = map ( len , large_list_of_strings )\n",
    "mapped = zip(large_list_of_strings, mapped)\n",
    "\n",
    "# paso 2\n",
    "\n",
    "reduced = functools.reduce ( lambda x, y: x if x[1] > y[1] else y, mapped )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2pEc0bFr-Dis"
   },
   "source": [
    "Este código hace exactamente lo mismo pero es más genérico y paralelizable.\n",
    "\n",
    "Para paralelizar vamos a dividir la entrada en trozos (chunks) de igual tamaño con la función `chunks`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 214,
     "status": "ok",
     "timestamp": 1634578696138,
     "user": {
      "displayName": "Jordi Conesa Caralt",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjoNn57kIwM1shjaORJcHiJsfMjG6Lqnp7apqYXPg=s64",
      "userId": "06942367536565960417"
     },
     "user_tz": -120
    },
    "id": "laY_DgWIB9Po"
   },
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    n = max(1, n)\n",
    "    return (l[i:i+n] for i in range(0, len(l), n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8324,
     "status": "ok",
     "timestamp": 1634578708831,
     "user": {
      "displayName": "Jordi Conesa Caralt",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjoNn57kIwM1shjaORJcHiJsfMjG6Lqnp7apqYXPg=s64",
      "userId": "06942367536565960417"
     },
     "user_tz": -120
    },
    "id": "qRZiY8r38mkT",
    "outputId": "0923bf33-265c-4875-d466-13cdf5bff494"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('python', 6)\n",
      "CPU times: user 7.94 s, sys: 78.1 ms, total: 8.01 s\n",
      "Wall time: 8.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_chunks = chunks ( large_list_of_strings , 30)\n",
    "\n",
    "# paso 1 \n",
    "\n",
    "reduced_all = []\n",
    "\n",
    "for chunk in data_chunks:\n",
    "  mapped_chunk = map ( len , chunk )\n",
    "  mapped_chunk = zip(chunk, mapped_chunk)\n",
    "\n",
    "  reduced_chunk = functools.reduce ( lambda x, y: x if x[1] > y[1] else y, mapped_chunk )\n",
    "  reduced_all.append (reduced_chunk)\n",
    "\n",
    "# paso 2\n",
    "\n",
    "reduced = functools.reduce ( lambda x, y: x if x[1] > y[1] else y,reduced_all)\n",
    "print (reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dLHF23W3FGhg"
   },
   "source": [
    "Refeactorizando para dejar el proceso con dos funciones obtenemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7650,
     "status": "ok",
     "timestamp": 1634578720602,
     "user": {
      "displayName": "Jordi Conesa Caralt",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjoNn57kIwM1shjaORJcHiJsfMjG6Lqnp7apqYXPg=s64",
      "userId": "06942367536565960417"
     },
     "user_tz": -120
    },
    "id": "8-XmxUeQLFv3",
    "outputId": "9cf814c8-959b-4570-8f75-aaac1600a5b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('python', 6)\n",
      "CPU times: user 7.2 s, sys: 16.4 ms, total: 7.21 s\n",
      "Wall time: 7.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def chunks_mapper(chunk):\n",
    "    mapped_chunk = map(len , chunk) \n",
    "    mapped_chunk = zip(chunk, mapped_chunk)\n",
    "    return functools.reduce ( lambda x, y: x if x[1] > y[1] else y, mapped_chunk )\n",
    "\n",
    "\n",
    "\n",
    "data_chunks = chunks ( large_list_of_strings , 30)\n",
    "\n",
    "#paso 1:\n",
    "mapped = map(chunks_mapper, data_chunks)\n",
    "\n",
    "#paso 2\n",
    "reduced = functools.reduce ( lambda x, y: x if x[1] > y[1] else y,mapped)\n",
    "\n",
    "print (reduced)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GVP7Bn_sQDdd"
   },
   "source": [
    "A continuación vamos a intentar paralelizar el paso 1 usando el módulo `multiprocesing` con la función `pool.map` en vez de la función `map` normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32422,
     "status": "ok",
     "timestamp": 1634578765278,
     "user": {
      "displayName": "Jordi Conesa Caralt",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjoNn57kIwM1shjaORJcHiJsfMjG6Lqnp7apqYXPg=s64",
      "userId": "06942367536565960417"
     },
     "user_tz": -120
    },
    "id": "o3_oIzOI-wdF",
    "outputId": "f49c33a9-cedc-4a35-82f4-a3bf477f9ba4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('python', 6)\n",
      "CPU times: user 8.6 s, sys: 804 ms, total: 9.4 s\n",
      "Wall time: 32.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import multiprocessing as mp \n",
    "pool = mp.Pool(16)\n",
    "\n",
    "\n",
    "data_chunks = chunks ( large_list_of_strings , 16)\n",
    "\n",
    "# paso 1 \n",
    "mapped = pool.map(chunks_mapper, data_chunks)\n",
    "\n",
    "# paso 2\n",
    "reduced = functools.reduce ( lambda x, y: x if x[1] > y[1] else y,mapped)\n",
    "\n",
    "print (reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1UJ2_AP6Q1R-"
   },
   "source": [
    "Como podéis ver la mejora no es importante (cuando no empeora los tiempos) aunque son por los problemas de paralelización del entorno y la exclusión mútua sobre la variable `mapped`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cMn6TfvURNV_"
   },
   "source": [
    "En cualquier caso, se ha arquitecturado una solución usando las funciones `map`y `reduce` que puede ejecutarse en paralelo. Esta arquitectura tiene dos ventajas:\n",
    "\n",
    "\n",
    "\n",
    "1.   Es escalable: si hay más datos se pueden añadir más unidades de procesamiento sin cambiar el código\n",
    "2.   Es genérica: esta arquitectura permite una gran cantidad de tareas reemplazando las funciones `map` y `reduce`.\n",
    "\n",
    "En ambos casos se supone que los datos son enormes y estáticos. Lo que implica que dividir en fragmentos cada vez es poco eficiente y redundante. Por lo que se supone que los datos se almacenan en fragmentos (o *shards*) \n",
    "de origen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mjCO_Pg8WDgQ"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Ahora vamos a ver otro caso. Tenemos una texto relativamente largo que es la Declaración Universal de Derechos Humanos. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2913,
     "status": "ok",
     "timestamp": 1634578787958,
     "user": {
      "displayName": "Jordi Conesa Caralt",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjoNn57kIwM1shjaORJcHiJsfMjG6Lqnp7apqYXPg=s64",
      "userId": "06942367536565960417"
     },
     "user_tz": -120
    },
    "id": "yNOsERXhDhoR",
    "outputId": "8020d76d-fb9d-4f3e-c0de-710953b4132a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package udhr to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/udhr.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('udhr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "executionInfo": {
     "elapsed": 219,
     "status": "ok",
     "timestamp": 1634578792112,
     "user": {
      "displayName": "Jordi Conesa Caralt",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjoNn57kIwM1shjaORJcHiJsfMjG6Lqnp7apqYXPg=s64",
      "userId": "06942367536565960417"
     },
     "user_tz": -120
    },
    "id": "ntMxCUEASBfJ",
    "outputId": "fd62906e-445e-413b-dd07-0477a582ae0d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Declaración Universal de '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import udhr\n",
    "import re\n",
    "\n",
    "text_udhr = udhr.raw('Spanish-Latin1')\n",
    "#text_udhr = udhr.raw('Catalan-Latin1')\n",
    "text_udhr[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kO99iZ7TjJdT"
   },
   "source": [
    "Realizando un limpieza de datos y convirtiéndolos a minúsculas para obtener un array de cadenas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 221,
     "status": "ok",
     "timestamp": 1634578808114,
     "user": {
      "displayName": "Jordi Conesa Caralt",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjoNn57kIwM1shjaORJcHiJsfMjG6Lqnp7apqYXPg=s64",
      "userId": "06942367536565960417"
     },
     "user_tz": -120
    },
    "id": "L6CBvHiqSLk9",
    "outputId": "05fb8817-a356-4242-c2b6-52415b54ac80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arbitrariamente 15\n",
      "CPU times: user 2.06 ms, sys: 961 µs, total: 3.02 ms\n",
      "Wall time: 8.77 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def clean_word ( word ):\n",
    "  return re.sub(r'[^\\w\\s]','',word).lower()\n",
    "\n",
    "\n",
    "clean_text = clean_word ( text_udhr)\n",
    "tokens = clean_text.split ()\n",
    "ls = find_longest_string (tokens)\n",
    "\n",
    "print (ls, len(ls))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XpcqXgsljhFi"
   },
   "source": [
    "Y realizado con `map` y `reduce`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 524,
     "status": "ok",
     "timestamp": 1616522626722,
     "user": {
      "displayName": "Jordi Conesa Caralt",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjoNn57kIwM1shjaORJcHiJsfMjG6Lqnp7apqYXPg=s64",
      "userId": "06942367536565960417"
     },
     "user_tz": -60
    },
    "id": "TPJ_E8PmSi9k",
    "outputId": "09d78671-c6a7-4242-bdbb-ceb34683fe0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('arbitrariamente', 15)\n",
      "CPU times: user 48.3 ms, sys: 9.96 ms, total: 58.3 ms\n",
      "Wall time: 58.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# TODO\n",
    "data_chunks = chunks ( tokens , 1)\n",
    "\n",
    "#paso 1:\n",
    "mapped = map(chunks_mapper, data_chunks)\n",
    "\n",
    "#paso 2\n",
    "reduced = functools.reduce ( lambda x, y: x if x[1] > y[1] else y,mapped)\n",
    "\n",
    "print (reduced)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "704CsTdhjoMH"
   },
   "source": [
    "MapReduce es una técnica esencial para procesar grandes cantidades de datos y que permite una gran cantidad de tareas como contar, buscar,  aprendizaje automático (supervisado y no supervisado), etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hogEpkC5y9PZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "IntroMapReduce.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
