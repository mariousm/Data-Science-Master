{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UbiernaSanMamesMario_PRA",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"width: 100%; clear: both;\">\n",
        "<div style=\"float: left; width: 50%;\">\n",
        "<img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\", align=\"left\">\n",
        "</div>\n",
        "<div style=\"float: right; width: 50%;\">\n",
        "<p style=\"margin: 0; padding-top: 22px; text-align:right;\">M2.875 · Deep Learning · PRA\n",
        "</p>\n",
        "<p style=\"margin: 0; text-align:right;\">2021-2 · Máster universitario en Ciencia de datos (Data science)</p>\n",
        "<p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudios de Informática, Multimedia y Telecomunicación</p>\n",
        "</div>\n",
        "</div>\n",
        "<div style=\"width:100%;\">&nbsp;</div>\n",
        "\n",
        "\n",
        "# PRA: Recurrent Neural Networks\n",
        "\n",
        "En esta práctica se implementará diferentes redes neuronales convolucionales para detectar el glaucoma.\n",
        "\n",
        "**Importante: La entrega debe hacerse en formato notebook y en formato html donde se vea el código y los resultados y comentarios de cada ejercicio. Para exportar el notebook a html puede hacerse desde el menú File $\\to$ Download as $\\to$ HTML.**"
      ],
      "metadata": {
        "id": "NjUN7XSd2X-o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Autor: Mario Ubierna San Mamés"
      ],
      "metadata": {
        "id": "tIZFNxSa2vgc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Presentación"
      ],
      "metadata": {
        "id": "5MFdFvZv2z3z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El objetivo de esta práctica es aplicar los conocimientos adquiridos durante toda la asignatura en un caso clínico real. Para ello se dispondrá de una base de datos que contiene imágenes de ojos sanos y de otros afectados por glaucoma. \n",
        "\n",
        "El glaucoma es una patología que afecta al nervio óptico y cuyos orígenes son diversos, es la segunda causa de ceguera por detrás de la diabetes y los efectos en la pérdida de visión son irreversibles. Las causas que lo producen se pueden tratar si la patología es detectada\n",
        "a tiempo.\n",
        "\n",
        "El objetivo final de esta práctica es, mediante los conocimientos adquiridos, proponer y entrenar un algoritmo que sea capaz de detectar adecuadamente ojos con glaucoma frente a otros sanos."
      ],
      "metadata": {
        "id": "AYi9Rfzj21vF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definición del problema"
      ],
      "metadata": {
        "id": "intFNN0m3VOj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los algoritmos de reconocimiento de imágenes se están implementando en la práctica clínica, integrándose en ocasiones directamente en el hardware que se utiliza para la  exploración (por ejemplo, en los ecógrafos). Este tipo de aproximación es lo que se propone en el siguiente artículo científico, el cual se utilizará como base para realizar esta práctica:\n",
        "\n",
        "*   Diaz-Pinto, A., Morales, S., Naranjo, V. et al. CNNs for automatic glaucoma\n",
        "assessment using fundus images: an extensive validation. BioMed Eng OnLine\n",
        "18, 29 (2019). https://doi.org/10.1186/s12938-019-0649-y\n",
        "\n",
        "En esta práctica se dispone de una serie de imágenes de casos reales. El objetivo es obtener un modelo eficaz para detectar de manera temprana esta patología, reduciendo, por lo tanto, el riesgo de ceguera.\n",
        "\n",
        "La base de datos está formada por imágenes en color de 224x224 píxeles y se ha\n",
        "dividido en 10 particiones distintas que se usarán para aplicar un método de cross validation con el objetivo de minimizar errores estadísticos. Cada una de estas particiones, a su vez, contiene tres subconjuntos: train, test y valid. Las imágenes a su vez están etiquetadas de dos formas: normal o abnormal.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Yn4W5phh3alr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Librerías"
      ],
      "metadata": {
        "id": "n4r15Xdm4yqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image\n",
        "import _pickle as pickle\n",
        "\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.models import load_model\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "OdaJF1Vq40Xh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carga de Google Drive"
      ],
      "metadata": {
        "id": "B4tnATYZ7XMW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnKY0fkd7ZIB",
        "outputId": "c79d2f7d-d6a6-4f61-afbf-ae8aa78a7245"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sección 1 - Análisis exploratorio de los datos"
      ],
      "metadata": {
        "id": "ZGWPA0k74Ug9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este apartado se va a realizar diferentes análisis sobre los datos, así se conseguirá entender mejor la problemática que se busca resolver e idearemos un desarrollo para cumplir el objetivo del proyecto.\n",
        "\n",
        "Pero antes de comenzar con eso hay que realizar la lectura de los datos:"
      ],
      "metadata": {
        "id": "KfvwAQoG4YBa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lectura de los datos"
      ],
      "metadata": {
        "id": "armSo8pR4s4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Método que carga una porción específica de los datos, según el fold y el tipo de dataset que queremos cargar\n",
        "def load_dataset(fold=\"Fold0\", dataset=\"train\"):\n",
        "  root = \"/content/drive/MyDrive/practica_DL_UOC_2022/\"\n",
        "\n",
        "  # Cargamos los datos\n",
        "  df = pd.DataFrame()\n",
        "  lstFilenames = []\n",
        "  lstImages = []\n",
        "  lstTarget = []\n",
        "\n",
        "  # abnormal (1)\n",
        "  for filename in os.listdir(os.path.join(root, fold, dataset, \"abnormal\")):\n",
        "    lstFilenames.append(filename.split(\".\")[0]) # Sin .jpg\n",
        "    lstImages.append(np.array(Image.open(os.path.join(\"/content/drive/MyDrive/practica_DL_UOC_2022/\", fold, dataset, \"abnormal\", filename))))\n",
        "    lstTarget.append(1)\n",
        "\n",
        "  # normal (0)\n",
        "  for filename in os.listdir(os.path.join(root, fold, dataset, \"normal\")):\n",
        "    lstFilenames.append(filename.split(\".\")[0]) # Sin .jpg\n",
        "    lstImages.append(np.array(Image.open(os.path.join(\"/content/drive/MyDrive/practica_DL_UOC_2022/\", fold, dataset, \"normal\", filename))))\n",
        "    lstTarget.append(0)\n",
        "\n",
        "  # Devolvemos el resultado\n",
        "  df = pd.DataFrame(data={\n",
        "    \"FileName\": lstFilenames,\n",
        "    \"Image\": lstImages,\n",
        "    \"Target\": lstTarget\n",
        "    })\n",
        "  \n",
        "  return df"
      ],
      "metadata": {
        "id": "qs2ZfAED9xZv"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Método encargado de cargar todos los datos para un Fold\n",
        "def load_data(fold=\"Fold0\"):\n",
        "\n",
        "  print(\"\\n\" + fold)\n",
        "  \n",
        "  # Cargamos el conjunto de train\n",
        "  print(\"\\tCargando el conjunto de train...\")\n",
        "  df_train = load_dataset(fold=fold, dataset=\"train\")\n",
        "\n",
        "  # Cargamos el conjunto de validación\n",
        "  print(\"\\tCargando el conjunto de valid...\")\n",
        "  df_valid = load_dataset(fold=fold, dataset=\"valid\")\n",
        "\n",
        "  # Cargamos el conjunto de test\n",
        "  print(\"\\tCargando el conjunto de test...\")\n",
        "  df_test = load_dataset(fold=fold, dataset=\"test\")\n",
        "\n",
        "  return df_train, df_valid, df_test"
      ],
      "metadata": {
        "id": "QSHBy-uF4xXX"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El siguiente paso es guardar los dataframes generados para así no tener que hacerlo cada vez:"
      ],
      "metadata": {
        "id": "vnc1qLe2KOM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_data_to_pickle(fold=\"Fold0\", df_train=None, df_valid=None, df_test=None):\n",
        "  root = \"/content/drive/MyDrive/practica_DL_UOC_2022/\"\n",
        "\n",
        "  print(\"\\tGuardamos los conjuntos a formato pickle...\")\n",
        "  df_train.to_pickle(os.path.join(root, fold, \"df_train.pickle\"))\n",
        "  df_valid.to_pickle(os.path.join(root, fold, \"df_valid.pickle\"))\n",
        "  df_test.to_pickle(os.path.join(root, fold, \"df_test.pickle\"))"
      ],
      "metadata": {
        "id": "dwIGPGWHJkND"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realizamos la lectura dejamos programada la lectura de los ficheros pickle"
      ],
      "metadata": {
        "id": "dlZnNCGzO45c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data_from_pickle(fold=\"Fold0\"):\n",
        "  root = \"/content/drive/MyDrive/practica_DL_UOC_2022/\"\n",
        "\n",
        "  df_train = pd.read_pickle(os.path.join(root, fold, \"df_train.pickle\"))\n",
        "  df_valid = pd.read_pickle(os.path.join(root, fold, \"df_valid.pickle\"))\n",
        "  df_test = pd.read_pickle(os.path.join(root, fold, \"df_test.pickle\"))\n",
        "\n",
        "  return df_train, df_valid, df_test"
      ],
      "metadata": {
        "id": "ZQfqOyZlPCzN"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_train, df_valid, df_test = load_data_from_pickle(fold=\"Fold0\")"
      ],
      "metadata": {
        "id": "Kaz8JRqdPXzI"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lo siguiente es hacer la lectura de todos los folds:"
      ],
      "metadata": {
        "id": "NJDkKpP9QwfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FOLDS = 10\n",
        "\n",
        "for nFold in range(FOLDS):\n",
        "  # Obtenemos los datos en un dataframe\n",
        "  df_train, df_valid, df_test = load_data(fold=\"Fold\" + str(nFold))\n",
        "  # Guardamos los datos a formato pickle\n",
        "  save_data_to_pickle(fold=\"Fold\" + str(nFold), df_train=df_train, df_valid=df_valid, df_test=df_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Gy6sWgxQ18H",
        "outputId": "033aa5f0-50ca-494b-f7f1-961b30452da6"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold0\n",
            "\tCargando el conjunto de train...\n",
            "\tCargando el conjunto de valid...\n",
            "\tCargando el conjunto de test...\n",
            "\tGuardamos los conjuntos a formato pickle...\n",
            "\n",
            "Fold1\n",
            "\tCargando el conjunto de train...\n",
            "\tCargando el conjunto de valid...\n",
            "\tCargando el conjunto de test...\n",
            "\tGuardamos los conjuntos a formato pickle...\n",
            "\n",
            "Fold2\n",
            "\tCargando el conjunto de train...\n",
            "\tCargando el conjunto de valid...\n",
            "\tCargando el conjunto de test...\n",
            "\tGuardamos los conjuntos a formato pickle...\n",
            "\n",
            "Fold3\n",
            "\tCargando el conjunto de train...\n",
            "\tCargando el conjunto de valid...\n",
            "\tCargando el conjunto de test...\n",
            "\tGuardamos los conjuntos a formato pickle...\n",
            "\n",
            "Fold4\n",
            "\tCargando el conjunto de train...\n",
            "\tCargando el conjunto de valid...\n",
            "\tCargando el conjunto de test...\n",
            "\tGuardamos los conjuntos a formato pickle...\n",
            "\n",
            "Fold5\n",
            "\tCargando el conjunto de train...\n",
            "\tCargando el conjunto de valid...\n",
            "\tCargando el conjunto de test...\n",
            "\tGuardamos los conjuntos a formato pickle...\n",
            "\n",
            "Fold6\n",
            "\tCargando el conjunto de train...\n",
            "\tCargando el conjunto de valid...\n",
            "\tCargando el conjunto de test...\n",
            "\tGuardamos los conjuntos a formato pickle...\n",
            "\n",
            "Fold7\n",
            "\tCargando el conjunto de train...\n",
            "\tCargando el conjunto de valid...\n",
            "\tCargando el conjunto de test...\n",
            "\tGuardamos los conjuntos a formato pickle...\n",
            "\n",
            "Fold8\n",
            "\tCargando el conjunto de train...\n",
            "\tCargando el conjunto de valid...\n",
            "\tCargando el conjunto de test...\n",
            "\tGuardamos los conjuntos a formato pickle...\n",
            "\n",
            "Fold9\n",
            "\tCargando el conjunto de train...\n",
            "\tCargando el conjunto de valid...\n",
            "\tCargando el conjunto de test...\n",
            "\tGuardamos los conjuntos a formato pickle...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora hay que comprobar que todos los datos estén bien, es decir, que en cada conjunto estén las imágenes correspondientes y que el valor Target sea el que tiene que ser:"
      ],
      "metadata": {
        "id": "4iY0IbJjUe7_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Método que se encarga de comprobar si la lectura está bien\n",
        "def check_data(fold=\"Fold0\", dataset=\"train\", df=None):\n",
        "  root = \"/content/drive/MyDrive/practica_DL_UOC_2022/\"\n",
        "\n",
        "  lstFilenames = df[\"FileName\"].values\n",
        "\n",
        "  # abnormal (1)\n",
        "  for filename in os.listdir(os.path.join(root, fold, dataset, \"abnormal\")):\n",
        "\n",
        "    filename = filename.split(\".\")[0] \n",
        "    # Comprobamos que está la imagen\n",
        "    if not filename in lstFilenames:\n",
        "      return False\n",
        "    # Comprobamos que el target es el adecuado\n",
        "    if df[df[\"FileName\"] == filename][\"Target\"].item() != 1:\n",
        "      return False\n",
        "\n",
        "  # normal (0)\n",
        "  for filename in os.listdir(os.path.join(root, fold, dataset, \"normal\")):\n",
        "\n",
        "    filename = filename.split(\".\")[0] \n",
        "    # Comprobamos que está la imagen\n",
        "    if not filename in lstFilenames:\n",
        "      return False\n",
        "    # Comprobamos que el target es el adecuado\n",
        "    if df[df[\"FileName\"] == filename][\"Target\"].item() != 0:\n",
        "      return False\n",
        "  \n",
        "  return True"
      ],
      "metadata": {
        "id": "_mlReK1HU4TE"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for nFold in range(FOLDS):\n",
        "  # Comprobamos la data para cada FOLD\n",
        "  print(\"Fold\" + str(nFold))\n",
        "  print(\"\\tLeemos los conjuntos de formato pickle...\")\n",
        "  df_train, df_valid, df_test = load_data_from_pickle(fold=\"Fold\" + str(nFold))\n",
        "\n",
        "  bTrain = check_data(fold=\"Fold\" + str(nFold), dataset=\"train\", df=df_train)\n",
        "  print(\"\\tTrain: \" + str(bTrain))\n",
        "\n",
        "  bValid = check_data(fold=\"Fold\" + str(nFold), dataset=\"valid\", df=df_valid)\n",
        "  print(\"\\tValid: \" + str(bValid))\n",
        "\n",
        "  bTest = check_data(fold=\"Fold\" + str(nFold), dataset=\"test\", df=df_test)\n",
        "  print(\"\\tTest: \" + str(bTest))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcpRSDtVVg82",
        "outputId": "a6fe1ae0-a70f-4c28-b209-0782023bfc83"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold0\n",
            "\tLeemos los conjuntos de formato pickle...\n",
            "\tTrain: True\n",
            "\tValid: True\n",
            "\tTest: True\n",
            "Fold1\n",
            "\tLeemos los conjuntos de formato pickle...\n",
            "\tTrain: True\n",
            "\tValid: True\n",
            "\tTest: True\n",
            "Fold2\n",
            "\tLeemos los conjuntos de formato pickle...\n",
            "\tTrain: True\n",
            "\tValid: True\n",
            "\tTest: True\n",
            "Fold3\n",
            "\tLeemos los conjuntos de formato pickle...\n",
            "\tTrain: True\n",
            "\tValid: True\n",
            "\tTest: True\n",
            "Fold4\n",
            "\tLeemos los conjuntos de formato pickle...\n",
            "\tTrain: True\n",
            "\tValid: True\n",
            "\tTest: True\n",
            "Fold5\n",
            "\tLeemos los conjuntos de formato pickle...\n",
            "\tTrain: True\n",
            "\tValid: True\n",
            "\tTest: True\n",
            "Fold6\n",
            "\tLeemos los conjuntos de formato pickle...\n",
            "\tTrain: True\n",
            "\tValid: True\n",
            "\tTest: True\n",
            "Fold7\n",
            "\tLeemos los conjuntos de formato pickle...\n",
            "\tTrain: True\n",
            "\tValid: True\n",
            "\tTest: True\n",
            "Fold8\n",
            "\tLeemos los conjuntos de formato pickle...\n",
            "\tTrain: True\n",
            "\tValid: True\n",
            "\tTest: True\n",
            "Fold9\n",
            "\tLeemos los conjuntos de formato pickle...\n",
            "\tTrain: True\n",
            "\tValid: True\n",
            "\tTest: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Análisis"
      ],
      "metadata": {
        "id": "PzNCYHOEP6DK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lo primero de todo es cargar todos los datos para cada uno de los folds, necearios para realizar la práctica:"
      ],
      "metadata": {
        "id": "8aD1KAbEP8iB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fold0\n",
        "print(\"Fold0\")\n",
        "print(\"\\tLeemos los conjuntos de formato pickle...\")\n",
        "f0_df_train, f0_df_valid, f0_df_test = load_data_from_pickle(fold=\"Fold0\")\n",
        "\n",
        "# Fold1\n",
        "print(\"Fold1\")\n",
        "print(\"\\tLeemos los conjuntos de formato pickle...\")\n",
        "f1_df_train, f1_df_valid, f1_df_test = load_data_from_pickle(fold=\"Fold1\")\n",
        "\n",
        "# Fold2\n",
        "print(\"Fold2\")\n",
        "print(\"\\tLeemos los conjuntos de formato pickle...\")\n",
        "f2_df_train, f2_df_valid, f2_df_test = load_data_from_pickle(fold=\"Fold2\")\n",
        "\n",
        "# Fold3\n",
        "print(\"Fold3\")\n",
        "print(\"\\tLeemos los conjuntos de formato pickle...\")\n",
        "f3_df_train, f3_df_valid, f3_df_test = load_data_from_pickle(fold=\"Fold3\")\n",
        "\n",
        "# Fold4\n",
        "print(\"Fold4\")\n",
        "print(\"\\tLeemos los conjuntos de formato pickle...\")\n",
        "f4_df_train, f4_df_valid, f4_df_test = load_data_from_pickle(fold=\"Fold4\")\n",
        "\n",
        "# Fold5\n",
        "print(\"Fold5\")\n",
        "print(\"\\tLeemos los conjuntos de formato pickle...\")\n",
        "f5_df_train, f5_df_valid, f5_df_test = load_data_from_pickle(fold=\"Fold5\")\n",
        "\n",
        "# Fold6\n",
        "print(\"Fold6\")\n",
        "print(\"\\tLeemos los conjuntos de formato pickle...\")\n",
        "f6_df_train, f6_df_valid, f6_df_test = load_data_from_pickle(fold=\"Fold6\")\n",
        "\n",
        "# Fold7\n",
        "print(\"Fold7\")\n",
        "print(\"\\tLeemos los conjuntos de formato pickle...\")\n",
        "f7_df_train, f7_df_valid, f7_df_test = load_data_from_pickle(fold=\"Fold7\")\n",
        "\n",
        "# Fold8\n",
        "print(\"Fold8\")\n",
        "print(\"\\tLeemos los conjuntos de formato pickle...\")\n",
        "f8_df_train, f8_df_valid, f8_df_test = load_data_from_pickle(fold=\"Fold8\")\n",
        "\n",
        "# Fold9\n",
        "print(\"Fold9\")\n",
        "print(\"\\tLeemos los conjuntos de formato pickle...\")\n",
        "f9_df_train, f9_df_valid, f9_df_test = load_data_from_pickle(fold=\"Fold9\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gw1FCofoQZJf",
        "outputId": "ddff1d11-2da2-48c8-a494-fb244e59689c"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold0\n",
            "\tLeemos los conjuntos de formato pickle...\n",
            "Fold1\n",
            "\tLeemos los conjuntos de formato pickle...\n",
            "Fold2\n",
            "\tLeemos los conjuntos de formato pickle...\n",
            "Fold3\n",
            "\tLeemos los conjuntos de formato pickle...\n",
            "Fold4\n",
            "\tLeemos los conjuntos de formato pickle...\n",
            "Fold5\n",
            "\tLeemos los conjuntos de formato pickle...\n",
            "Fold6\n",
            "\tLeemos los conjuntos de formato pickle...\n",
            "Fold7\n",
            "\tLeemos los conjuntos de formato pickle...\n",
            "Fold8\n",
            "\tLeemos los conjuntos de formato pickle...\n",
            "Fold9\n",
            "\tLeemos los conjuntos de formato pickle...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez cargada toda la información, pasamos a comprobar el número de registros que hay para train, valid y test en cada fold:"
      ],
      "metadata": {
        "id": "VytUOOEPbyh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for nFold in range(FOLDS):\n",
        "  df_train, df_valid, df_test = load_data_from_pickle(fold=\"Fold\" + str(nFold))\n",
        "  print(\"Fold\" + str(nFold) + \":\" + \"\\ttrain(\" + str(len(df_train)) + \")\" + \"\\tvalid(\" + str(len(df_valid)) + \")\" + \"\\ttest(\" + str(len(df_test)) + \")\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2D7expJcAbc",
        "outputId": "f4c810a9-5421-4d21-86f9-7eb7a6f62df1"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold0:\ttrain(1379)\tvalid(154)\ttest(174)\n",
            "Fold1:\ttrain(1379)\tvalid(154)\ttest(174)\n",
            "Fold2:\ttrain(1379)\tvalid(154)\ttest(174)\n",
            "Fold3:\ttrain(1379)\tvalid(154)\ttest(174)\n",
            "Fold4:\ttrain(1379)\tvalid(154)\ttest(174)\n",
            "Fold5:\ttrain(1379)\tvalid(154)\ttest(174)\n",
            "Fold6:\ttrain(1379)\tvalid(154)\ttest(174)\n",
            "Fold7:\ttrain(1379)\tvalid(154)\ttest(174)\n",
            "Fold8:\ttrain(1379)\tvalid(154)\ttest(174)\n",
            "Fold9:\ttrain(1379)\tvalid(154)\ttest(174)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como podemos apreciar en la anterior ejecución, todos los folds contienen el mismo número de imágenes tanto para train como para valid y test.\n",
        "\n",
        "El siguiente punto es comprobar si hay duplicados (imágenes) en cada conjunto, la representación viene de la forma (x) siendo x el número de duplicados en el conjunto:\n"
      ],
      "metadata": {
        "id": "6nYtNAwRetvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for nFold in range(FOLDS):\n",
        "  df_train, df_valid, df_test = load_data_from_pickle(fold=\"Fold\" + str(nFold))\n",
        "  print(\"Fold\" + str(nFold) + \":\" + \n",
        "        \"\\ttrain(\" + str(len(df_train[df_train.duplicated([\"FileName\"])])) + \")\" +\n",
        "        \"\\tvalid(\" + str(len(df_valid[df_valid.duplicated([\"FileName\"])])) + \")\" +\n",
        "        \"\\ttest(\" + str(len(df_test[df_test.duplicated([\"FileName\"])])) + \")\") "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eS54jmQAhMz3",
        "outputId": "20adf3e6-488c-48b6-8891-196ffe55f91b"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold0:\ttrain(0)\tvalid(0)\ttest(0)\n",
            "Fold1:\ttrain(0)\tvalid(0)\ttest(0)\n",
            "Fold2:\ttrain(0)\tvalid(0)\ttest(0)\n",
            "Fold3:\ttrain(0)\tvalid(0)\ttest(0)\n",
            "Fold4:\ttrain(0)\tvalid(0)\ttest(0)\n",
            "Fold5:\ttrain(0)\tvalid(0)\ttest(0)\n",
            "Fold6:\ttrain(0)\tvalid(0)\ttest(0)\n",
            "Fold7:\ttrain(0)\tvalid(0)\ttest(0)\n",
            "Fold8:\ttrain(0)\tvalid(0)\ttest(0)\n",
            "Fold9:\ttrain(0)\tvalid(0)\ttest(0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tal y como podemos apreciar, no hay duplicados en ningún conjuto de ningún fold. Por lo que, no se procede a la eliminación de los mismos.\n",
        "\n",
        "Posteriormente, comprobamos si hay duplicados no dentro de cada conjunto sino que dentro de cada fold, la representación es (x) siendo x el número de duplicados por fold:"
      ],
      "metadata": {
        "id": "b3zpwAItjzo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for nFold in range(FOLDS):\n",
        "  df_train, df_valid, df_test = load_data_from_pickle(fold=\"Fold\" + str(nFold))\n",
        "  lstFilenames = [*df_train[\"FileName\"].values, *df_valid[\"FileName\"].values, *df_test[\"FileName\"].values]\n",
        "  print(\"Fold\" + str(nFold) + \":\" + \n",
        "        \"\\tduplicados(\" +  str(len(np.unique(lstFilenames)) - (len(df_train) + len(df_valid) + len(df_test))) + \")\"\n",
        "        ) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8PC_2FMj-HL",
        "outputId": "83ada94c-71d7-4eab-c204-93ea75570050"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold0:\tduplicados(0)\n",
            "Fold1:\tduplicados(0)\n",
            "Fold2:\tduplicados(0)\n",
            "Fold3:\tduplicados(0)\n",
            "Fold4:\tduplicados(0)\n",
            "Fold5:\tduplicados(0)\n",
            "Fold6:\tduplicados(0)\n",
            "Fold7:\tduplicados(0)\n",
            "Fold8:\tduplicados(0)\n",
            "Fold9:\tduplicados(0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tampoco hay duplicados por fold. Por lo tanto, tampoco se procede a la eliminación de los mismos.\n",
        "\n",
        "Lo siguiente que vamos a comprobar es el número de casos normal y abnormal que hay en cada conjunto de cada fold, la representación viene de la forma (x,y) siendo x los casos normal e y los abnormal: "
      ],
      "metadata": {
        "id": "2Q9qeB2bhLaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for nFold in range(FOLDS):\n",
        "  df_train, df_valid, df_test = load_data_from_pickle(fold=\"Fold\" + str(nFold))\n",
        "  print(\"Fold\" + str(nFold) + \":\" + \n",
        "        \"\\ttrain(N:\" + str(np.count_nonzero(df_train[\"Target\"].values == 0)) + \", A:\" + str(np.count_nonzero(df_train[\"Target\"].values == 1)) +\")\" +\n",
        "        \"\\tvalid(N:\" + str(np.count_nonzero(df_valid[\"Target\"].values == 0)) + \", A:\" + str(np.count_nonzero(df_valid[\"Target\"].values == 1)) +\")\" +\n",
        "        \"\\ttest(N:\" + str(np.count_nonzero(df_test[\"Target\"].values == 0)) + \", A:\" + str(np.count_nonzero(df_test[\"Target\"].values == 1)) +\")\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfLQtXhYfEdQ",
        "outputId": "82b6470a-99b1-4184-da79-0d35d5322821"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold0:\ttrain(N:754, A:625)\tvalid(N:83, A:71)\ttest(N:82, A:92)\n",
            "Fold1:\ttrain(N:740, A:639)\tvalid(N:88, A:66)\ttest(N:91, A:83)\n",
            "Fold2:\ttrain(N:739, A:640)\tvalid(N:83, A:71)\ttest(N:97, A:77)\n",
            "Fold3:\ttrain(N:743, A:636)\tvalid(N:85, A:69)\ttest(N:91, A:83)\n",
            "Fold4:\ttrain(N:746, A:633)\tvalid(N:81, A:73)\ttest(N:92, A:82)\n",
            "Fold5:\ttrain(N:758, A:621)\tvalid(N:71, A:83)\ttest(N:90, A:84)\n",
            "Fold6:\ttrain(N:754, A:625)\tvalid(N:84, A:70)\ttest(N:81, A:93)\n",
            "Fold7:\ttrain(N:737, A:642)\tvalid(N:82, A:72)\ttest(N:100, A:74)\n",
            "Fold8:\ttrain(N:748, A:631)\tvalid(N:80, A:74)\ttest(N:91, A:83)\n",
            "Fold9:\ttrain(N:733, A:646)\tvalid(N:82, A:72)\ttest(N:104, A:70)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como podemos apreciar no hay el mismo número de casos en ningún conjunto para cada fold.\n",
        "\n",
        "Por lo que vamos a comprobar el número de casos normales y abnormal por fold, independientemente del conjunto que sea, la representación sigue siendo igual (x,y), x son los casos normal e y los abnormal:"
      ],
      "metadata": {
        "id": "HJPNgKgrn9ea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for nFold in range(FOLDS):\n",
        "  df_train, df_valid, df_test = load_data_from_pickle(fold=\"Fold\" + str(nFold))\n",
        "  nNormal = np.count_nonzero(df_train[\"Target\"].values == 0) + np.count_nonzero(df_valid[\"Target\"].values == 0) + np.count_nonzero(df_test[\"Target\"].values == 0)\n",
        "  nAbnormal = np.count_nonzero(df_train[\"Target\"].values == 1) + np.count_nonzero(df_valid[\"Target\"].values == 1) + np.count_nonzero(df_test[\"Target\"].values == 1)\n",
        "  print(\"Fold\" + str(nFold) + \":\" + \n",
        "        \"\\tcases(N:\" + str(nNormal) + \", A:\" + str(nAbnormal) + \")\"\n",
        "        ) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Km72csINoQU4",
        "outputId": "bc3a90c8-554a-45da-fc6e-191d96cda35b"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold0:\tcases(N:919, A:788)\n",
            "Fold1:\tcases(N:919, A:788)\n",
            "Fold2:\tcases(N:919, A:788)\n",
            "Fold3:\tcases(N:919, A:788)\n",
            "Fold4:\tcases(N:919, A:788)\n",
            "Fold5:\tcases(N:919, A:788)\n",
            "Fold6:\tcases(N:919, A:788)\n",
            "Fold7:\tcases(N:919, A:788)\n",
            "Fold8:\tcases(N:919, A:788)\n",
            "Fold9:\tcases(N:919, A:788)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tal y como podemos observar todos los folds tienen el mismo número de casos.\n",
        "\n",
        "Con esto finalizamos este punto, destacar que en el informe se incluirán gráficas hechas con [Infogram](https://infogram.com/). Básicamente, porque una vez tenemos los datos que nos interesa es más fácil crear las gráficas y que tengan un aspecto elegante. Estas gráficas se pueden visualizar en el informe entregado con la práctica."
      ],
      "metadata": {
        "id": "e0H8h3J6pkrj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sección 2 - Entrenamiento de la red sobre Fold0"
      ],
      "metadata": {
        "id": "lvt2JHb9qSPu"
      }
    }
  ]
}