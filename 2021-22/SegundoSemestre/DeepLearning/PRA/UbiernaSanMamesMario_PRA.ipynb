{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UbiernaSanMamesMario_PRA",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"width: 100%; clear: both;\">\n",
        "<div style=\"float: left; width: 50%;\">\n",
        "<img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\", align=\"left\">\n",
        "</div>\n",
        "<div style=\"float: right; width: 50%;\">\n",
        "<p style=\"margin: 0; padding-top: 22px; text-align:right;\">M2.875 · Deep Learning · PRA\n",
        "</p>\n",
        "<p style=\"margin: 0; text-align:right;\">2021-2 · Máster universitario en Ciencia de datos (Data science)</p>\n",
        "<p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudios de Informática, Multimedia y Telecomunicación</p>\n",
        "</div>\n",
        "</div>\n",
        "<div style=\"width:100%;\">&nbsp;</div>\n",
        "\n",
        "\n",
        "# PRA: Recurrent Neural Networks\n",
        "\n",
        "En esta práctica se implementará diferentes redes neuronales convolucionales para detectar el glaucoma.\n",
        "\n",
        "**Importante: La entrega debe hacerse en formato notebook y en formato html donde se vea el código y los resultados y comentarios de cada ejercicio. Para exportar el notebook a html puede hacerse desde el menú File $\\to$ Download as $\\to$ HTML.**"
      ],
      "metadata": {
        "id": "NjUN7XSd2X-o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Autor: Mario Ubierna San Mamés"
      ],
      "metadata": {
        "id": "tIZFNxSa2vgc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Presentación"
      ],
      "metadata": {
        "id": "5MFdFvZv2z3z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El objetivo de esta práctica es aplicar los conocimientos adquiridos durante toda la asignatura en un caso clínico real. Para ello se dispondrá de una base de datos que contiene imágenes de ojos sanos y de otros afectados por glaucoma. \n",
        "\n",
        "El glaucoma es una patología que afecta al nervio óptico y cuyos orígenes son diversos, es la segunda causa de ceguera por detrás de la diabetes y los efectos en la pérdida de visión son irreversibles. Las causas que lo producen se pueden tratar si la patología es detectada\n",
        "a tiempo.\n",
        "\n",
        "El objetivo final de esta práctica es, mediante los conocimientos adquiridos, proponer y entrenar un algoritmo que sea capaz de detectar adecuadamente ojos con glaucoma frente a otros sanos."
      ],
      "metadata": {
        "id": "AYi9Rfzj21vF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definición del problema"
      ],
      "metadata": {
        "id": "intFNN0m3VOj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los algoritmos de reconocimiento de imágenes se están implementando en la práctica clínica, integrándose en ocasiones directamente en el hardware que se utiliza para la  exploración (por ejemplo, en los ecógrafos). Este tipo de aproximación es lo que se propone en el siguiente artículo científico, el cual se utilizará como base para realizar esta práctica:\n",
        "\n",
        "*   Diaz-Pinto, A., Morales, S., Naranjo, V. et al. CNNs for automatic glaucoma\n",
        "assessment using fundus images: an extensive validation. BioMed Eng OnLine\n",
        "18, 29 (2019). https://doi.org/10.1186/s12938-019-0649-y\n",
        "\n",
        "En esta práctica se dispone de una serie de imágenes de casos reales. El objetivo es obtener un modelo eficaz para detectar de manera temprana esta patología, reduciendo, por lo tanto, el riesgo de ceguera.\n",
        "\n",
        "La base de datos está formada por imágenes en color de 224x224 píxeles y se ha\n",
        "dividido en 10 particiones distintas que se usarán para aplicar un método de cross validation con el objetivo de minimizar errores estadísticos. Cada una de estas particiones, a su vez, contiene tres subconjuntos: train, test y valid. Las imágenes a su vez están etiquetadas de dos formas: normal o abnormal.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Yn4W5phh3alr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Librerías"
      ],
      "metadata": {
        "id": "n4r15Xdm4yqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image\n",
        "import _pickle as pickle\n",
        "\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.models import load_model\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "OdaJF1Vq40Xh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carga de Google Drive"
      ],
      "metadata": {
        "id": "B4tnATYZ7XMW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnKY0fkd7ZIB",
        "outputId": "c79d2f7d-d6a6-4f61-afbf-ae8aa78a7245"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sección 1 - Análisis exploratorio de los datos"
      ],
      "metadata": {
        "id": "ZGWPA0k74Ug9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este apartado se va a realizar diferentes análisis sobre los datos, así se conseguirá entender mejor la problemática que se busca resolver e idearemos un desarrollo para cumplir el objetivo del proyecto.\n",
        "\n",
        "Pero antes de comenzar con eso hay que realizar la lectura de los datos:"
      ],
      "metadata": {
        "id": "KfvwAQoG4YBa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lectura de los datos"
      ],
      "metadata": {
        "id": "armSo8pR4s4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Método que carga una porción específica de los datos, según el fold y el tipo de dataset que queremos cargar\n",
        "def load_dataset(fold=\"Fold0\", dataset=\"train\"):\n",
        "  root = \"/content/drive/MyDrive/practica_DL_UOC_2022/\"\n",
        "\n",
        "  # Cargamos los datos\n",
        "  df = pd.DataFrame()\n",
        "  lstFilenames = []\n",
        "  lstImages = []\n",
        "  lstTarget = []\n",
        "\n",
        "  # abnormal (1)\n",
        "  for filename in os.listdir(os.path.join(root, fold, dataset, \"abnormal\")):\n",
        "    lstFilenames.append(filename.split(\".\")[0]) # Sin .jpg\n",
        "    lstImages.append(np.array(Image.open(os.path.join(\"/content/drive/MyDrive/practica_DL_UOC_2022/\", fold, dataset, \"abnormal\", filename))))\n",
        "    lstTarget.append(1)\n",
        "\n",
        "  # normal (0)\n",
        "  for filename in os.listdir(os.path.join(root, fold, dataset, \"normal\")):\n",
        "    lstFilenames.append(filename.split(\".\")[0]) # Sin .jpg\n",
        "    lstImages.append(np.array(Image.open(os.path.join(\"/content/drive/MyDrive/practica_DL_UOC_2022/\", fold, dataset, \"normal\", filename))))\n",
        "    lstTarget.append(0)\n",
        "\n",
        "  # Devolvemos el resultado\n",
        "  df = pd.DataFrame(data={\n",
        "    \"FileName\": lstFilenames,\n",
        "    \"Image\": lstImages,\n",
        "    \"Target\": lstTarget\n",
        "    })\n",
        "  \n",
        "  return df"
      ],
      "metadata": {
        "id": "qs2ZfAED9xZv"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Método encargado de cargar todos los datos para un Fold\n",
        "def load_data(fold=\"Fold0\"):\n",
        "\n",
        "  print(\"\\n\" + fold)\n",
        "  \n",
        "  # Cargamos el conjunto de train\n",
        "  print(\"\\tCargando el conjunto de train...\")\n",
        "  df_train = load_dataset(fold=fold, dataset=\"train\")\n",
        "\n",
        "  # Cargamos el conjunto de validación\n",
        "  print(\"\\tCargando el conjunto de valid...\")\n",
        "  df_valid = load_dataset(fold=fold, dataset=\"valid\")\n",
        "\n",
        "  # Cargamos el conjunto de test\n",
        "  print(\"\\tCargando el conjunto de test...\")\n",
        "  df_test = load_dataset(fold=fold, dataset=\"test\")\n",
        "\n",
        "  return df_train, df_valid, df_test"
      ],
      "metadata": {
        "id": "QSHBy-uF4xXX"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El siguiente paso es guardar los dataframes generados para así no tener que hacerlo cada vez:"
      ],
      "metadata": {
        "id": "vnc1qLe2KOM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_data_to_pickle(fold=\"Fold0\", df_train=None, df_valid=None, df_test=None):\n",
        "  root = \"/content/drive/MyDrive/practica_DL_UOC_2022/\"\n",
        "\n",
        "  print(\"\\tGuardamos los conjuntos a formato pickle...\")\n",
        "  df_train.to_pickle(os.path.join(root, fold, \"df_train.pickle\"))\n",
        "  df_valid.to_pickle(os.path.join(root, fold, \"df_valid.pickle\"))\n",
        "  df_test.to_pickle(os.path.join(root, fold, \"df_test.pickle\"))"
      ],
      "metadata": {
        "id": "dwIGPGWHJkND"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realizamos la lectura dejamos programada la lectura de los ficheros pickle"
      ],
      "metadata": {
        "id": "dlZnNCGzO45c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data_from_pickle(fold=\"Fold0\"):\n",
        "  root = \"/content/drive/MyDrive/practica_DL_UOC_2022/\"\n",
        "\n",
        "  print(\"\\tLeemos los conjuntos de formato pickle...\")\n",
        "  df_train = pd.read_pickle(os.path.join(root, fold, \"df_train.pickle\"))\n",
        "  df_valid = pd.read_pickle(os.path.join(root, fold, \"df_valid.pickle\"))\n",
        "  df_test = pd.read_pickle(os.path.join(root, fold, \"df_test.pickle\"))\n",
        "\n",
        "  return df_train, df_valid, df_test"
      ],
      "metadata": {
        "id": "ZQfqOyZlPCzN"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_train, df_valid, df_test = load_data_from_pickle(fold=\"Fold0\")"
      ],
      "metadata": {
        "id": "Kaz8JRqdPXzI"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lo siguiente es hacer la lectura de todos los folds:"
      ],
      "metadata": {
        "id": "NJDkKpP9QwfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FOLDS = 10\n",
        "\n",
        "for nFold in range(FOLDS):\n",
        "  # Obtenemos los datos en un dataframe\n",
        "  df_train, df_valid, df_test = load_data(fold=\"Fold\" + str(nFold))\n",
        "  # Guardamos los datos a formato pickle\n",
        "  save_data_to_pickle(fold=\"Fold\" + str(nFold), df_train=df_train, df_valid=df_valid, df_test=df_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Gy6sWgxQ18H",
        "outputId": "033aa5f0-50ca-494b-f7f1-961b30452da6"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold0\n",
            "\tCargando el conjunto de train...\n",
            "\tCargando el conjunto de valid...\n",
            "\tCargando el conjunto de test...\n",
            "\tGuardamos los conjuntos a formato pickle...\n",
            "\n",
            "Fold1\n",
            "\tCargando el conjunto de train...\n",
            "\tCargando el conjunto de valid...\n",
            "\tCargando el conjunto de test...\n",
            "\tGuardamos los conjuntos a formato pickle...\n",
            "\n",
            "Fold2\n",
            "\tCargando el conjunto de train...\n",
            "\tCargando el conjunto de valid...\n",
            "\tCargando el conjunto de test...\n",
            "\tGuardamos los conjuntos a formato pickle...\n",
            "\n",
            "Fold3\n",
            "\tCargando el conjunto de train...\n",
            "\tCargando el conjunto de valid...\n",
            "\tCargando el conjunto de test...\n",
            "\tGuardamos los conjuntos a formato pickle...\n",
            "\n",
            "Fold4\n",
            "\tCargando el conjunto de train...\n",
            "\tCargando el conjunto de valid...\n",
            "\tCargando el conjunto de test...\n",
            "\tGuardamos los conjuntos a formato pickle...\n",
            "\n",
            "Fold5\n",
            "\tCargando el conjunto de train...\n",
            "\tCargando el conjunto de valid...\n",
            "\tCargando el conjunto de test...\n",
            "\tGuardamos los conjuntos a formato pickle...\n",
            "\n",
            "Fold6\n",
            "\tCargando el conjunto de train...\n",
            "\tCargando el conjunto de valid...\n",
            "\tCargando el conjunto de test...\n",
            "\tGuardamos los conjuntos a formato pickle...\n",
            "\n",
            "Fold7\n",
            "\tCargando el conjunto de train...\n",
            "\tCargando el conjunto de valid...\n",
            "\tCargando el conjunto de test...\n",
            "\tGuardamos los conjuntos a formato pickle...\n",
            "\n",
            "Fold8\n",
            "\tCargando el conjunto de train...\n",
            "\tCargando el conjunto de valid...\n",
            "\tCargando el conjunto de test...\n",
            "\tGuardamos los conjuntos a formato pickle...\n",
            "\n",
            "Fold9\n",
            "\tCargando el conjunto de train...\n",
            "\tCargando el conjunto de valid...\n",
            "\tCargando el conjunto de test...\n",
            "\tGuardamos los conjuntos a formato pickle...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora hay que comprobar que todos los datos estén bien, es decir, que en cada conjunto estén las imágenes correspondientes y que el valor Target sea el que tiene que ser:"
      ],
      "metadata": {
        "id": "4iY0IbJjUe7_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Método que se encarga de comprobar si la lectura está bien\n",
        "def check_data(fold=\"Fold0\", dataset=\"train\", df=None):\n",
        "  root = \"/content/drive/MyDrive/practica_DL_UOC_2022/\"\n",
        "\n",
        "  lstFilenames = df[\"FileName\"].values\n",
        "\n",
        "  # abnormal (1)\n",
        "  for filename in os.listdir(os.path.join(root, fold, dataset, \"abnormal\")):\n",
        "\n",
        "    filename = filename.split(\".\")[0] \n",
        "    # Comprobamos que está la imagen\n",
        "    if not filename in lstFilenames:\n",
        "      return False\n",
        "    # Comprobamos que el target es el adecuado\n",
        "    if df[df[\"FileName\"] == filename][\"Target\"].item() != 1:\n",
        "      return False\n",
        "\n",
        "  # normal (0)\n",
        "  for filename in os.listdir(os.path.join(root, fold, dataset, \"normal\")):\n",
        "\n",
        "    filename = filename.split(\".\")[0] \n",
        "    # Comprobamos que está la imagen\n",
        "    if not filename in lstFilenames:\n",
        "      return False\n",
        "    # Comprobamos que el target es el adecuado\n",
        "    if df[df[\"FileName\"] == filename][\"Target\"].item() != 0:\n",
        "      return False\n",
        "  \n",
        "  return True"
      ],
      "metadata": {
        "id": "_mlReK1HU4TE"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for nFold in range(FOLDS):\n",
        "  # Comprobamos la data para cada FOLD\n",
        "  print(\"Fold\" + str(nFold))\n",
        "  df_train, df_valid, df_test = load_data_from_pickle(fold=\"Fold\" + str(nFold))\n",
        "\n",
        "  bTrain = check_data(fold=\"Fold\" + str(nFold), dataset=\"train\", df=df_train)\n",
        "  print(\"\\tTrain: \" + str(bTrain))\n",
        "\n",
        "  bValid = check_data(fold=\"Fold\" + str(nFold), dataset=\"valid\", df=df_valid)\n",
        "  print(\"\\tValid: \" + str(bValid))\n",
        "\n",
        "  bTest = check_data(fold=\"Fold\" + str(nFold), dataset=\"test\", df=df_test)\n",
        "  print(\"\\tTest: \" + str(bTest))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcpRSDtVVg82",
        "outputId": "2039f9a1-e4dd-409c-f18a-841fddb0e1d5"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold0\n",
            "\tLeemos los conjuntos de formato pickle...\n",
            "\tTrain: True\n",
            "\tValid: True\n",
            "\tTest: True\n",
            "Fold1\n",
            "\tLeemos los conjuntos de formato pickle...\n",
            "\tTrain: True\n",
            "\tValid: True\n",
            "\tTest: True\n",
            "Fold2\n",
            "\tLeemos los conjuntos de formato pickle...\n",
            "\tTrain: True\n",
            "\tValid: True\n",
            "\tTest: True\n",
            "Fold3\n",
            "\tLeemos los conjuntos de formato pickle...\n",
            "\tTrain: True\n",
            "\tValid: True\n",
            "\tTest: True\n",
            "Fold4\n",
            "\tLeemos los conjuntos de formato pickle...\n",
            "\tTrain: True\n",
            "\tValid: True\n",
            "\tTest: True\n",
            "Fold5\n",
            "\tLeemos los conjuntos de formato pickle...\n",
            "\tTrain: True\n",
            "\tValid: True\n",
            "\tTest: True\n",
            "Fold6\n",
            "\tLeemos los conjuntos de formato pickle...\n",
            "\tTrain: True\n",
            "\tValid: True\n",
            "\tTest: True\n",
            "Fold7\n",
            "\tLeemos los conjuntos de formato pickle...\n",
            "\tTrain: True\n",
            "\tValid: True\n",
            "\tTest: True\n",
            "Fold8\n",
            "\tLeemos los conjuntos de formato pickle...\n",
            "\tTrain: True\n",
            "\tValid: True\n",
            "\tTest: True\n",
            "Fold9\n",
            "\tLeemos los conjuntos de formato pickle...\n",
            "\tTrain: True\n",
            "\tValid: True\n",
            "\tTest: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Análisis"
      ],
      "metadata": {
        "id": "PzNCYHOEP6DK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez realizada la lectura vamos a proceder con el análisis de los datos que tenemos."
      ],
      "metadata": {
        "id": "8aD1KAbEP8iB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gw1FCofoQZJf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}