---
title: "A3 - Modelos predictivos"
author: "Mario Ubierna San Mamés"
date: '`r format(Sys.Date(),"%e de %B, %Y")`'
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Modelo de regresión lineal

## Modelo de regresión lineal (regresores cuantitativos)

### Estimar por mínimos cuadrados un modelo lineal

Estimar por mínimos cuadrados ordinarios un modelo lineal que explique la variable DEPARTURE_DELAY en función de la variable ARRIVAL_DELAY. Se evaluará la bondad del ajuste, a partir del coeficiente de determinación. Calcular el coeficiente de correlación y explicar su relación con el coeficiente de determinación.

Lo primero que debemos de hacer antes de comenzar con el ejercicio es la lectura del fichero y comprobar que todo se ha leído de forma correcta:
```{r}
df = read.csv(file = "./data/SFO.csv", sep = ",", header = TRUE, na.strings = "NA",  stringsAsFactors = TRUE, encoding="UTF-8")

# Creamos una copia del df
df_copy = df

head(df_copy)
```

En este primer paso nos pide crear un modelo de regresión lineal simple, cuya variable dependiente sea DEPARTURE_DELAY y como variable independiente ARRIVAL_DELAY. 

Por lo tanto vamos a crear un dataframe con la información que nos es útil para este modelo:
```{r}
df_rls = df_copy[, c("DEPARTURE_DELAY", "ARRIVAL_DELAY")]
head(df_rls)
```

Una vez que tenemos la información, comprobamos si tenemos observaciones que no tienen valores:
```{r}
colSums(is.na(df_rls))
```

Vemos que hay observaciones cuyo atributo ARRIVAL_DELAY no tiene valor, por lo que vamos a ignorar estas observaciones del dataframe usado para crear el modelo de la regresión lineal:
```{r}
df_rls = df_rls[is.na(df_rls$ARRIVAL_DELAY) == FALSE,]
colSums(is.na(df_rls))
```

Una vez limpiado el dataset creamos el modelo de regresión lineal, recordando que la variable dependiente es DEPARTURE_DELAY y la variable independiente ARRIVAL_DELAY:
```{r}
modelo_rls = lm(formula = DEPARTURE_DELAY ~ ARRIVAL_DELAY, df_rls)
summary(modelo_rls)
```

Ahora lo que tenemos que hacer es evaluar la calidad del modelo, a partir de su coeficiente de determinación y de correlación.

El coeficiente de determinación o R2, nos indica el grado de ajuste de la recta de regresión a los valores de la muestra, es decir, el cómo es la proporción de variación en nuestro modelo. R2 es un coeficiente que puede ir entre 0 y 1, cuanto más próximo a uno mejor es el modelo, ya que significa que los errores/residuos que se cometen son muy pequeños y los valores se ajustan a la línea de regresión.

De la anterior ejecución vemos que tenemos un coeficiente de determinación de 0.91, este valor está muy próximo a uno por lo que los puntos se ajustan a la recta de regresión.

Otra forma de medir cómo de bueno es el modelo es a partir del coeficiente de correlación, éste nos indica cómo de relacionadas están dos variables, pudiendo ser una relación positiva (si cuando aumenta una variable la otra aumenta) o negativa (si cuando aumenta una variable la otra disminuye).

Por lo que primero, vamos a calcular la correlación entre ambas variables:
```{r}
cat("El valor del coeficiente de correlación (r) es:", cor(x = df_rls$ARRIVAL_DELAY, y = df_rls$DEPARTURE_DELAY))
```

El coeficiente de correlación es un valor que va entre -1 y 1, siendo -1 cuando están altamente correlacionadas dos variables pero de forma negativa, y siendo 1 cuando están altamente correlacionadas de forma positiva.

Respecto a la ejecución anterior, vemos que r tiene un valor de 0.95, éste un valor muy alto lo que nos indica que ambas variables están altamente correlacionadas y de forma positiva, es decir, cuando una aumenta la otra también.

Cuando realizamos un modelo de regresión simple tenemos una relación entre el coeficiente de determinación y el coeficiente de correlación y es la siguiente, el coeficiente de determinación (R2) es igual al coeficiente de correlación elevado al cuadrado (r^2), es decir, en nuestro caso R2 = 0.9082 y r = 0.9530, por lo tanto R2 = r^2 = 0.9530^2 = 0.9082.

### Regresión lineal múltiple

Se añadirá al modelo anterior la variable independiente DISTANCIA. ¿Existe una mejora del ajuste?. Razonar.

Lo primero que debemos hacer es crear un dataframe con la información relevante:
```{r}
df_rlm = df_rls
df_rlm["DISTANCE"] = df_copy$DISTANCE[is.na(df_copy$ARRIVAL_DELAY) == FALSE]

head(df_rlm)
```
Una vez que tenemos los datos, los introducimos al modelo, recordamos que ahora la variable dependiente sigue siendo la misma (DEPARTURE_DELAY) pero ahora tenemos dos variables independientes (ARRIVAL_DELAY, DISTANCE), debemos de tener en cuenta que asumimos que existe una relación lineal entre las variables, y también que las variables son independientes entre sí:
```{r}
modelo_rlm = lm(formula = DEPARTURE_DELAY ~ ARRIVAL_DELAY + DISTANCE, data = df_rlm)
summary(modelo_rlm)
```

En este caso el coeficiente de determinación R2 es igual a 0.9127 mientras que en el anterior modelo era de 0.9082. Por lo tanto, vamos que sí que hay una mejora significativa ya que a mayor R2 mejor ajustados están los datos a la recta de la regresión.

### División de muestras

Posteriormente, se procederá a dividir la muestra en dos, según los vuelos sean o no más largos. Se tomará por larga distancia aquellos con un recorrido superior a 600 millas. Razonar los resultados.

En este caso, vamos a dividir el dataset en dos muestras y posteriormente evaluaremos qué modelo se comporta mejor, si aquellos en los que la distancia es pequeña o grande.

Lo primero que vamos a hacer es crear los dos modelos:
```{r}
modelo_rlm_distancia_menor = lm(formula = DEPARTURE_DELAY ~ ARRIVAL_DELAY + DISTANCE, data = df_rlm[df_rlm$DISTANCE <= 600,])

modelo_rlm_distancia_mayor = lm(formula = DEPARTURE_DELAY ~ ARRIVAL_DELAY + DISTANCE, data = df_rlm[df_rlm$DISTANCE > 600,])

```

Una vez que hemos generados los modelos, comprobamos para cada modelo que R2 tiene:
```{r}
summary(modelo_rlm_distancia_menor)
summary(modelo_rlm_distancia_mayor)
```

De la anterior ejecución podemos observar que cuando la distancia de los vuelos es menor o igual a 600 millas, el modelo se comporta algo mejor que cuando la distancia es mayor a 600 millas.

Respecto al R2 de los vuelos cuya distancia es inferior o igual a 600 millas, nos proporciona un coeficiente de determinación de 0.9299 mientras que el modelo cuyas distancias son superiores a 600 millas su coeficiente de determinación es de 0.9034. Por lo tanto, a mayor coeficiente mejor se comporta el modelo ya que ajusta mejor los datos, es por ello que el modelo en los que la distancia es pequeña es mejor.

## Modelo de regresión lineal múltiple (regresores cuantitativos y cualitativos)

En este apartado se estudiará la relación de DEPARTURE_DELAY, con las variables explicativas ARRIVAL_DELAY y LATE_AIRCRAFT_DELAY. Para ello se procederá a la recodificación de la variable LATE_AIRCRAFT_DELAY, en en mayor y menor o igual a 15 minutos.

Lo primero que debemos de hacer es crear el dataframe con los datos que nos interesan, además no tenemos en cuenta las observaciones cuyo valor sea NA:
```{r}
df_rlm_cualitativo = df_copy[is.na(df_copy$ARRIVAL_DELAY) == FALSE & is.na(df_copy$LATE_AIRCRAFT_DELAY) == FALSE, c("DEPARTURE_DELAY", "ARRIVAL_DELAY", "LATE_AIRCRAFT_DELAY")]

df_rlm_cualitativo$`d-LATE_AIRCRAFT_DELAY`[df_rlm_cualitativo$LATE_AIRCRAFT_DELAY <= 15] = 0 
df_rlm_cualitativo$`d-LATE_AIRCRAFT_DELAY`[df_rlm_cualitativo$LATE_AIRCRAFT_DELAY > 15] = 1 
df_rlm_cualitativo$`d-LATE_AIRCRAFT_DELAY` = factor(df_rlm_cualitativo$`d-LATE_AIRCRAFT_DELAY`)

head(df_rlm_cualitativo)
```

Creamos el modelo de regresión lineal múltiple con las variables cuantitativas y cualitativas, la variable dependiente es DEPARTURE_DELAY y las variables independientes ARRIVAL_DELAY y d-LATE_AIRCRAFT_DELAY:
```{r}
modelo_rlm_cualitativo = lm(formula = DEPARTURE_DELAY ~ ARRIVAL_DELAY + `d-LATE_AIRCRAFT_DELAY`, data = df_rlm_cualitativo)

summary(modelo_rlm_cualitativo)
```

Como podemos apreciar de la anterior ejecución, el coeficiente de determinación es el mayor que hemos obtenido en lo que vamos de práctica, en este caso R2 es igual a 0.9419. Tiene sentido que dicho valor sea algo mayor ya que al eliminar aquellas observaciones que tengan valores NA, no las hemos tenido en consideración a la hora de crear el modelo, por lo que tenemos menos datos y estos datos están completos, permitiendo que el modelo pueda a ajustar de una mejor forma.

## Diagnosis del modelo

Para la diagnosis se escoge el modelo construído en el apartado b) y se pintarán dos gráficos: uno con los valores ajustados frente a los residuos (que nos permitirá ver si la varianza es constante) y el gráfico cuantil-cuantil que compara los residuos del modelo con los valores de una variable que se distribuye normalmente(QQ plot). Interpretar los resultados.

El primer gráfico que vamos a mostrar, son los valores ajustados respecto a los residuos:
```{r}
library(ggplot2)

residuos = rstandard(modelo_rlm)
ajustados = fitted(modelo_rlm)

qplot(x = ajustados, y = residuos, main = "Residuales Estandarizados vs Valores Ajustados", geom = c("point"), ylab = "Residuales Estandarizados", xlab = "Valores Ajustados") + geom_hline(yintercept = 0 , color = 2)
```

Recordando el R2 que teníamos en el modelo de regresión múltiple del apartado b, su valor era 0.9127, es decir, su R2 es elevado, lo que signfica que los valores se ajustan muy bien al modelo.

Sin embargo, del anterior gráfico vemos que el modelo no se comporta del todo bien para ciertos valores, es decir, a  medida que el valor ajustado aumenta su error también aumenta. Por otro lado, aunque la gran mayoría de valores no siguen un patrón determinado, cuando el valor ajustado es pequeño tenemos un poco de error en el modelo.

Por lo tanto, aunque es verdad que para ciertos valores sí que se aprecia un patrón (cuando lo valores ajustados son altos el residuo aumenta), para la gran mayoría de valores el modelo se comporta perfectamente, por lo que podemos decir que en la gran mayoría de casos el modelo va a funcionar bien.

```{r}
ggplot(as.data.frame(residuos),aes(sample = residuos)) +  geom_qq() 
```

Del anterior gráfico podemos observar el cómo los residuos siguen la distribución normal, de seguirla perfectamente tendríamos que todos los residuos estarían alineados en un recta diagonal, pero tal y como vemos en nuestro caso hace una "S" nuestros datos, es  decir, cuando los valores ajustados son muy pequeños el modelo no ajusta de forma perfecta, y cuando los valores ajustados son muy grandes se sigue cometiendo cierto error. Sin embargo, cuando los valores no son ni muy grandes ni muy pequeños el modelo ajusta bien.

Resumiendo, vemos que no seguimos una distribución normal y que el modelo por norma general se comporta bien, aunque hay casos en los que hay un poco de error.

## Predicción del modelo

Según el modelo del apartado b), calcular el retraso en la salida de un avión, que después de recorrer 2500 millas ha llegado a su destino con 30 minutos más tarde.

```{r}
summary(modelo_rlm)
```

```{r}
df_predict = data.frame(30,2500)
colnames(df_predict) = c("ARRIVAL_DELAY", "DISTANCE")

cat("El retraso que se produce es de:", predict(modelo_rlm, df_predict), "min")
```

Respecto al retraso que se produce cuando recorremos 2500 millas y hemos llegado 30 minutos tarde al destino es de 37 minutos.

# Regresión logística

## Estudio de relaciones entre variables.

Se quiere estudiar la probabilidad que tiene un avión de sufrir un retraso.

Para ello, primero se creará una nueva variable dicotómica llamada delay_SFO. Esta nueva variable está relacionada con los valores de la variable Departure_Delay. Se codificará de la siguiente: Si el valor de dicha variable es menor a 15 minutos, se puede asumir que el vuelo no va con retraso y se codificará con el valor 0, en caso contrario, se codificará con el valor 1.

- Visualizar la relación entre delay_SFO y las variables independientes:DAY_OF_WEEK y AIRLINE. Calcular las frecuencias relativas por fila y columna. Interpretar el significado. Visualizar con barplot.

- Para comprobar si existe asociación entre las variable dependiente y cada una de las variables explicativas, se aplicará el test Chi-cuadrado de Pearson. Un resultado significativo nos dirá que existe asociación. Interpretar.

### Visualizar la relación entre variables

En este primer apartado vamos a visializar la relación que hay entre delay_SFO y la variables independientes, pero antes de comenzar debemos crear el dataframe correspondiente, junto con la variable delay_SFO:
```{r}
df_rlgs = df_copy[, c("DEPARTURE_DELAY", "DAY_OF_WEEK", "AIRLINE")]

# Creamos la variable delay_SFO
df_rlgs$delay_SFO[df_rlgs$DEPARTURE_DELAY <= 15] = 0
df_rlgs$delay_SFO[df_rlgs$DEPARTURE_DELAY > 15] = 1
df_rlgs$delay_SFO = factor(df_rlgs$delay_SFO)

# Convertimos a factor DAY_OF_WEEK
df_rlgs$DAY_OF_WEEK = factor(df_rlgs$DAY_OF_WEEK)

head(df_rlgs)
```

Comprobamos que no hay valores NA, para así cuando tengamos que entrenar el modelo, lo hacemos ya con los datos completos:
```{r}
colSums(is.na(df_rlgs))
```

De la anterior ejecución, vemos que no hay columanas sin valores.

Una vez hecho todo esto, pasamos a ver la relación de delay_SFO respecto a los días de la semana, y obtenemos la tabla de frecuencias relativas:
```{r}
# Calculamos la tabla con frecuencias absolutas
table_DAY_OF_WEEK = table(df_rlgs$delay_SFO, df_rlgs$DAY_OF_WEEK)
rownames(table_DAY_OF_WEEK) = c("0 - No retraso", "1 - Retraso")
colnames(table_DAY_OF_WEEK) = c("1- Lunes", "2", "3", "4", "5", "6", "7")
```

La tabla de frecuencias relativas de delay_SFO respecto a DAY_OF_WEEK es la siguiente:

```{r}
# Tabla con frecuencias relativas
round(prop.table(table_DAY_OF_WEEK, 1), 2)
```

La tabla de frecuencias relativas de DAY_OF_WEEK respecto a delay_SFO es la siguiente:

```{r}
# Tabla con frecuencias relativas
round(prop.table(table_DAY_OF_WEEK, 2), 2)
```

De las dos anteriores ejecuciones vemos que los días que más retrasos se producen son los lunes, jueves y domingos. Dentro de estos días el día más probable de que el vuelo vaya con retraso es el lunes.

Por otro lado, los días en los que menos retraso se producen son los martes, miércoles, jueves y viernes. Dentro de éstos, el mejor día para viajar sería el miércoles, ya que es el día con mayor éxito de vuelos con no retraso.

En el siguiente  gráfico podemos visualizar el análisis que hemos hecho, el primer gráfico se corresponde con la primera tabla y el segundo gráfico con la segunda tabla:
```{r}
ggplot(df_rlgs, aes(delay_SFO, fill = factor(DAY_OF_WEEK))) + geom_bar(position = "fill") +
  xlab("Retraso") + 
  ylab("Frecuencia") +
  ggtitle("Retraso y no retraso de los vuelos respecto al día de la semana")

ggplot(df_rlgs, aes(DAY_OF_WEEK, fill = factor(delay_SFO))) + geom_bar(position = "fill") +
  xlab("Día de la semana") + 
  ylab("Frecuencia") +
  scale_fill_manual(name = "Clase", values=c("#00bfc4","#f8766d")) +
  ggtitle("Día de la semana respecto al retraso o no retraso de vuelos")
```

Ahora pasamos a ver la relación de delay_SFO respecto a las aerolíneas y obtenemos la tabla de frecuencias relativas:
```{r}
# Calculamos la tabla con frecuencias absolutas
table_AIRLINE = table(df_rlgs$delay_SFO, df_rlgs$AIRLINE)
rownames(table_AIRLINE) = c("0 - No retraso", "1 - Retraso")
```

La tabla de frecuencias relativas de delay_SFO respecto a AIRLINE es la siguiente:

```{r}
# Tabla con frecuencias relativas
round(prop.table(table_AIRLINE, 1), 2)
```

La tabla de frecuencias relativas de AIRLINE respecto a delay_SFO es la siguiente:

```{r}
# Tabla con frecuencias relativas
round(prop.table(table_AIRLINE, 2), 2)
```

De las dos anteriores ejecuciones vemos que las aerolíneas que tinen más vuelos con restraso son UA, OO. Dentro de éstas dos, la que tiene un peor porcentaje respecto al retraso es UA.

Por otro lado, las aerolíneas con más vuelos sin retraso son también UA y OO. Dentro de éstas dos, la que tiene un mejor porcentaje es OO.

En el siguiente  gráfico podemos visualizar el análisis que hemos hecho, el primer gráfico se corresponde con la primera tabla y el segundo gráfico con la segunda tabla:
```{r}
ggplot(df_rlgs, aes(delay_SFO, fill = AIRLINE)) + geom_bar(position = "fill") +
  xlab("Retraso") + 
  ylab("Frecuencia") +
  ggtitle("Retraso y no retraso de los vuelos respecto a la aerolínea")

ggplot(df_rlgs, aes(AIRLINE, fill = factor(delay_SFO))) + geom_bar(position = "fill") +
  xlab("Aerolínea") + 
  ylab("Frecuencia") +
  scale_fill_manual(name = "Clase", values=c("#00bfc4","#f8766d")) +
  ggtitle("Aerolínea respecto al retraso o no retraso de vuelos")
```

### Test Chi-Cuadrado de Pearson.

Para comprobar si existe asociación entre las variable dependiente y cada una de las variables explicativas, se aplicará el test Chi-cuadrado de Pearson. Un resultado significativo nos dirá que existe asociación. Interpretar.

El test de Chi-cuadrado nos permite saber el cómo de asociadas están dos variables, es decir, si la proporción de una variable depende de la otra.

Partimos de que la hipótesis nula es las variables son idependientes, por lo tanto una variable no depende de la otra. La hipótesis alternativa es que las variables son dependientes.

Primero realizamos el test Chi-cuadrado de Pearson para la variable DAY_OF_WEEK:
```{r}
chisq.test(table_DAY_OF_WEEK)
```

Como podemos apreciar el p-value es inferior a alfa (0.05), por lo que podemos rechazar la hipótesis nula a favor de la alternativa, es decir, que las variables son dependientes, sí que hay una asociación.

Si analizamos las desviaciones de los residuos obtenemos la siguiente información:
```{r}
chisq.test(table_DAY_OF_WEEK)$stdres
```
Vemos que las mayores desviaciones se producen con el lunes, sábado y miércoles, es decir, sí que hay diferencias significativas entre estos niveles.


En segundo lugar hacer el mismo test pero para la variable AIRLINE:
```{r}
chisq.test(table_AIRLINE)
```

En este caso el p-value vuelve a es inferior al nivel de significancia alfa (0.05), por lo que concluimos que las variables son dependientes, sí que existe una asociación entre ellas.

Analizamos las desviaciones de los residuos:
```{r}
chisq.test(table_AIRLINE)$stdres
```

Respecto a las aerolíneas en las que verdaderamente hay una diferencia significativa son: UA, US, AA, VX y DL.

## Modelo de regresión logística

### Modelo regresión logística según DAY_OF_WEEK

Estimar el modelo de regresión logística tomando como variable dependiente delay_SFO y variable explicativa DAY_OF_WEEK. Se tomará como día de referencia el lunes. Se puede considerar que el día de la semana es un factor de riesgo? Justifica tu respuesta.

Lo primero que debemos de hacer es convertir los días de la semana a variables dummy:
```{r}
df_rlgs$DAY_OF_WEEK = relevel(df_rlgs$DAY_OF_WEEK, ref = "1")
```

Creamos el modelo de regresión logística:
```{r}
modelo_rlgs_DAY_OF_WEEK = glm(formula = delay_SFO ~ DAY_OF_WEEK, family = binomial(link=logit), data = df_rlgs)

summary(modelo_rlgs_DAY_OF_WEEK)
```

De la anterior ejecución vemos que todos los días de la semana son significativos, ya que tienen un Pr(>|z|) < 0.05.

Por otro lado, vamos a ver si todos los días de la semana son un factor de riesgo o no. Para ello tenemos que calcular el OR (odds-ratio):
```{r}
exp(coefficients(modelo_rlgs_DAY_OF_WEEK))
```

Como podemos apreciar todos los ratios que nos calcula son inferiores a 1, esto significa que son factores de protección y no de riesgo, es decir, que la probabiliad de que haya un retraso en cualquiera de los días respecto al lunes es inferior que en el propio lunes.

Por lo tanto, no podemos considerar el día de la semana como un factor de riesgo.

### Modelo regresión logística según AIRLINE

Idem al anterior tomando como variable explicativa AIRLINE. Se tomará como aerolínea de referencia AA. ¿Se puede considerar que la aerolínea es un factor de riesgo? Justifica tu respuesta.

Lo primero que debemos de hacer es convertir las aerolíneas a variables dummy:
```{r}
df_rlgs$AIRLINE = relevel(df_rlgs$AIRLINE, ref = "AA")
```

Creamos el modelo de regresión logística:
```{r}
modelo_rlgs_AIRLINE = glm(formula = delay_SFO ~ AIRLINE, family = binomial(link=logit), data = df_rlgs)

summary(modelo_rlgs_AIRLINE)
```

En este caso vemos que no todas las aerolíneas tienen un nivel de signifancia, ya que la aerolínea DL su Pr(>|z|) > 0.05. Respecto al resto de aerolíneas, vemos que todas ellas son significantes, aunque algunas más que otras ya que las aerolíneas AS y VX tienen un nivel de significancia bajo respecto al resto de aerolíneas.

Por otro lado, vamos a ver si todas las aerolíneas son un factor de riesgo o no. Para ello tenemos que calcular el OR (odds-ratio):
```{r}
exp(coefficients(modelo_rlgs_AIRLINE))
```

A diferencia de los días de la semana, no todas las aerolíneas tienen un mejor ratio que la de referencia "AA", solamente las aerolíneas HA y US proporcionan un mejor ratio, es decir, que cuando tomamos un vuelo de estas compañías el retraso que se produce es menor que el retraso que tenemos con la aerolínea AA.

Por lo tanto, las aerolíneas HA y US son un factor de protección mientras que todas las demás son un factor de riesgo.

### Modelo de regresión logística según DAY_OF_WEEK y DISTANCE

Se creará un modelo con la variable dependiente y las variable explicativas DAY_OF_WEEK (la obtenida en el apartado a) y DISTANCE. ¿Se observa una mejora con referencia a los anteriores? Explicar.

Volvemos a crear el modelo y analizamos los resultados obtenidos:
```{r}
df_rlgs_DAY_OF_WEEK_DISTANCE = df_rlgs[, c("delay_SFO", "DAY_OF_WEEK")]
df_rlgs_DAY_OF_WEEK_DISTANCE$DISTANCE = df_copy[, c("DISTANCE")]


modelo_rlgs_DAY_OF_WEEK_DISTANCE = glm(formula = delay_SFO ~ DAY_OF_WEEK + DISTANCE, family = binomial(link=logit), data = df_rlgs_DAY_OF_WEEK_DISTANCE)

summary(modelo_rlgs_DAY_OF_WEEK_DISTANCE)
```

Respecto a si todas las variables son significantes vemos que no, ya que la variable distancia tiene un Pr(>|z|) > 0.05, por lo tanto, solo los días de la semana son significantes

Para poder medir cómo de bueno es el modelo, nos tenemos que fijar en la devianza de cada modelo. Si la devianza residual es menor que la devianza nula, entonces hemos conseguido mejorar el modelo.

Respecto al primer modelo:
```{r}
summary(modelo_rlgs_DAY_OF_WEEK)
```

Observamos que la devianza residual es menor que la devianza nula, por lo que sí que conseguimos mejorar el modelo.

Respecto al segundo modelo:
```{r}
summary(modelo_rlgs_AIRLINE)
```

La devianza residual en este caso es menor que la devianza nula y además, esta devianza residual es menor que en el anterior modelo, por lo que este modelo es mejor.

Respecto al modelo calculado en este apartado:
```{r}
summary(modelo_rlgs_DAY_OF_WEEK_DISTANCE)
```

En este caso la devianza residual sigue siendo inferior, y aunque es mejor que el modelo del apartado a, ya que la devianza residual es menor, no consigue ser mejor que el modelo del apartado b, ya que el modelo calculado en este apartado tiene una devianza residual mayor.

Por lo tanto, el modelo de este apartado es mejor que el modelo del apartado a pero no que el del apartado b.

### Modelo de regresión logística con las variables significativas

Se creará un nuevo modelo con la variable dependiente y tomando como variables explicativas, aquéllas que han sido significativas en los apartados anteriores, y además se añadirá la variable ARRIVAL_DELAY.¿Se observa una mejora con referencia a los anteriores? Explicar. Realizad el cálculo de las OR.

Respecto al primer modelo recordamos que todos los días de la semana eran significativos, en el segundo modelo todas las aerolíneas eran significativas menos la aerolínea DL, y respecto al tercer modelo los días de la semana sí que son significativos pero la distancia no.

Por lo tanto, vamos a crear un modelo cuyas variables independientes van a ser: DAY_OF_WEEK, AIRLINE (todas menos DL) y ARRIVAL_DELAY:
```{r}

```

## Predicción

Según el modelo del apartado c), calcula la probabilidad de retraso en el vuelo, si nuestro destino está a 1500 millas y viajamos en jueves.

Realizamos la predicción del retraso a partir del modelo c):
```{r}
df_predict = data.frame("4", 1500)
colnames(df_predict) = c("DAY_OF_WEEK", "DISTANCE")

cat("La probabilidad de que se produzca un restraso es de:", predict(modelo_rlgs_DAY_OF_WEEK_DISTANCE, df_predict, type = "response") * 100, "%")
```

Lo que nos indica la anterior ejecución es que la probabilidad de que se produzca un restraso cuando nuestro destino está a 1500 millas y viajamos un jueves es de un 22%, es decir, es más probable que no se produzca un restraso a que se produzca.

## Bondad del ajuste

Usa el test de Hosman-Lemeshow para ver la bondad de ajuste, tomando el modelo del apartado c). En la librería ResourceSelection hay una función que ajusta el test de Hosmer- Lemeshow.

Este test lo que nos permite saber es cómo de bueno es el modelo a partir de los datos previstos vs los observados, este test tiene sentido solamente cuando alguna de las variables independientes es continua, en nuestro caso la variable DISTANCE.

Partimos de que la hipótesis nula indica que no hay diferencia entre los valores previstos respecto a los observados, por lo que la hipótesis alternativa lo que nos indica es lo contrario, es decir, que sí que hay diferencia.

Realizamos el cálculo del test de Hosman-Lemeshow:
```{r}
library(ResourceSelection)

hoslem.test(df_rlgs_DAY_OF_WEEK_DISTANCE$delay_SFO,fitted(modelo_rlgs_DAY_OF_WEEK_DISTANCE))
```

Tal y como podemos apreciar el p-value es menor que el nivel de significancia alfa (0.05), por lo tanto rechazamos la hipótesis nula a favor de la alternativa, esto significa que en este modelo sí que hay una diferencia significativa entre los valores previstos respecto a los valores observados, es decir, en este caso el modelo no se ajusta del todo bien a los datos.

## Curva ROC

Dibujar la curva ROC, y calcular el área debajo de la curva con los modelos de los apartados c) y d).Discutir el resultado.

Dibujamos la curva ROC para el modelo del apartado c:
```{r}
library(pROC)

prob=predict(modelo_rlgs_DAY_OF_WEEK_DISTANCE, df_rlgs_DAY_OF_WEEK_DISTANCE, type="response")
roc1=roc(df_rlgs_DAY_OF_WEEK_DISTANCE$delay_SFO,prob, data=df_rlgs_DAY_OF_WEEK_DISTANCE)
plot (roc1)

```

Calculamos el área bajo la curva:
```{r}
auc(roc1)
```

Vemos que nos proporciona una área bajo la curva muy pequeña, es decir, el modelo no descrimina del todo bien los datos. Por lo tanto, este modelo comparando su bondad de ajuste con la curva ROC, vemos que no es el modelo ideal para este problema.

Realizamos lo mismo pero para el modelo del apartado d:

# Conclusiones del análisis

En este apartado se deberán exponer las conclusiones en base a los resultados obtenidos en todo el estudio. Regresión lineal y logística.

Respecto a esta práctica hemos hecho diferentes modelos predictivos, para ser más exactos dos: modelo de regresión lineal (simple o múltiple), y modelo de regresión logística (simple o múltiple).

Respecto al primer ejercicio, en los modelos de regresión lineal (regresores cuantitativos) hemos visto que al introducir una nueva variable, en este caso DISTANCE, hemos conseguido un mejor modelo ya que el coeficiente de determinación aumentaba. También hemos estudiado la correlación entre las variables y hemos visto que era una correlación elevada.

Siguiendo con ese primer ejercicio, cuando hemos creado dos modelos dependiendo de si la distancia era mayor o menor a 600 millas, hemos comprobado que no se comportaban igual, es decir, el modelo en el que la distancia era menor o igual a 600 millas se comportaba mejor (ajustaba mejor los datos) que el modelo cuya distancia era superior a 600 millas.

Posteriormente, hemos creado un modelo de regresión lineal múltiple, pero en este caso con variables cuantitativas y cualitativas, hemos conseguido el R2 mayor en este apartado, por lo que este modelo es el que mejor se comportaba respecto a todos los que se han hecho en este ejercicio.

Una vez realizados todos los modelos hemos analizado el modelo del apartado b, y hemos visto que para ciertos valores el modelo no se comporta de forma correcta (aunque para la mayoría sí) ya que los residuos no siguen una distribución normal.

Respecto al segundo ejercicio, hemos realizado diferentes modelos de regresión logística,

También en este ejercicio hemos analizado la bondad de ajuste respecto al modelo del apartado c, y podemos concluir que dicho modelo no es el idóneo, ya que según el test de Hosman-Lemeshow sí que hay una diferencia significativa entre los valores que se predicen y los observados, es decir, el modelo no ajusta bien.

Finalmente hemos realizado el análisis de las curvas ROC tanto para el modelo del apartado c y del apartado d. Respecto a la curva que proporciona el modelo del apartado c, no es la idónea ya que el área que nos da es muy pequeño, es decir, el modelo no ajusta bien los datos. Respecto a la curva que proporciona el modelo del apartado d ..........



