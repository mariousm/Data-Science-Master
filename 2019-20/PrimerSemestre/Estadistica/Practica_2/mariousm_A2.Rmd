---
title: "A2 - Analítica descriptiva e inferencial"
author: "Mario Ubierna San Mamés"
date: '`r format(Sys.Date(),"%e de %B, %Y")`'
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Lectura del fichero

Leer el fichero fifa_clean.csv. Validar que los datos leídos son correctos. Si no es así, realizar las conversiones
oportunas.

Lo primero que debemos realizar es la carga del fichero y visualizamos que se ha cargado:
```{r}
df = read.csv(file = "./data/fifa_clean.csv", sep = ",", stringsAsFactors = TRUE)

head(df)
```
A priori los datos se han cargado correctamene, pero vamos a comprobar si cada variable tiene el tipo de variable correcto:
```{r}
str(df)
```

Tal y como podemos apreciar, prácticamente todas las variables tienen su tipo de variable correcto, pero hay un par de excepciones, tanto la variable Club_Joining como Birth_Date son variables de tipo Date y las ha categorizado como Factor, por lo que vamos a hacer dicha transformación:
```{r}
df_copy = df # Creamos una copia del dataframe

df_copy$Club_Joining = as.Date(df_copy$Club_Joining, format = "%m/%d/%Y")
df_copy$Birth_Date = as.Date(df_copy$Birth_Date, format = "%m/%d/%Y")
```

Comprobamos que se han realizado los cambios de forma correcta:
```{r}
str(df_copy$Club_Joining)
str(df_copy$Birth_Date)
```

# Rating de los jugadores

Nos interesa investigar los valores que toma la variable Rating en la población. Para ello, realizad un primer
análisis visual de esta variable a partir de la muestra. Posteriormente, calculad el intervalo de confianza de la
variable Rating de los jugadores. Seguid los pasos que se indican a continuación.

## Análisis visual

Mostrad visualmente la distribución de la variable Rating. Usad el gráfico o gráficos que creáis más oportunos.
Describid brevemente lo que se observa en los gráficos que representáis.

En el siguiente gráfico podemos ver el cómo es la distribución del rating:
```{r}
library(ggplot2) # Importamos la librería ggplot2

ggplot(mapping = aes(x=df_copy$Rating)) + geom_density()
```

Tal y como podemos apreciar, la distribución parace seguir una distribución normal, lógicamente no es una distribución perfecta pero si tenemos en mente la distribución normal estándar se asemeja. Este primer gráfico nos permite hacernos una idea de cómo es la distribución, dónde puede estar la media, si hay más datos a la izquierda de la función o a la derecha...

Para ser más técnicos podríamos hacer un diagrama boxplot:
```{r}
boxplot(x = df_copy$Rating,
        main = "Raiting de los jugadores",
        ylab = "Valor de Rating"
        )
```

Este tipo de gráficos nos proporciona mucha información:

- Podemos ver que la mediana está entorno al 66, lo cual nos indica que por norma general los jugadores profesionales recogidos en el FIFA tienen una calidad media-baja.

- Nos da información sobre el primer cuartil, es decir, el punto en el que el 25% de los datos está por debajo a ese valor, el valor de este cuartil es entorno a 63.

- Apreciamos el tercer cuartil, el punto en el que el 75% de los datos son menores o iguales a ese valor, este valor es más o menos 71.

- Con el primer y tercer cuartil sacamos el rango intercuartílico, en este caso, podemos ver que es pequeño dicho rango lo que nos da a entender que muchos de los datos, para ser más exactos el 50%, se mueven entre 63 y 71, es decir, los jugadores de media son regulares.

- También observamos tanto el límite inferior como superior, gracias a ellos podemos identificar outliers, valores fuera de lo común, y vemos que esto tiene un significado positivo y negativo al mismo tiempo, ya que hay jugadores muy  (aunque son pocos) y jugadores muy buenos.

## Intervalo de confianza

Calculad el intervalo de confianza de la variable Rating. A continuación, explicad el resultado y cómo se debe
interpretar el resultado obtenido.

Nota: Los cálculos se deben realizar manualmente. No se pueden usar funciones de R que calculen directamente
el intervalo de confianza. En cambio, sí se pueden usar funciones como mean, sd, qnorm, pnorm, qt y pt

Al realizar este ejercicio no se nos proporciona la varianza poblacional por lo que tenemos que calcular la varianza o la desviación de la muestra, esto lógicamente supone más incertidumbre ya que calculamos la desviación a partir de la muestra no de la población, es por ello que se recomienda hacer el cálculo a partir de la distribución t-student.

Aunque podríamos aplicar el teorema del límite central, asumiendo que al calcular la media de la muestra y tener una muestra lo suficientemente grande seguimos una distribución normal, vamos a realizar los cálculos como si el teorema del límite central no existiera. 

Por otro lado, consideramos que el nivel de confianza es del 95%. Para calcular el intervalo de confianza, primero calculamos el alfa (nivel de significancia), junto con la desviación de la muestra y el tamaño de la muestra:
```{r}
alfa = 1 - 0.95
tam_muestra = length(df_copy$Rating)
desviacion = sd(df_copy$Rating)
```

Una vez tenemos los valores anteriores, calculamos el estadístico y el valor z para esta distribución:
```{r}
estadistico = desviacion / sqrt(tam_muestra)
z = qt(alfa/2, tam_muestra - 1, lower.tail = FALSE)
```

Finalmente, calculamos el límite inferior y superior:
```{r}
lim_inferior = round(mean(df_copy$Rating) - (z * estadistico), 2)
lim_superior = round(mean(df_copy$Rating) + (z * estadistico), 2)

cat("El límite inferior del intervalo de confianza (L) es igual a: ", lim_inferior)
cat("El límite superior del intervalo de confianza (U) es igual a: ", lim_superior)
```

Tal y como podemos apreciar en la anterior ejecución tenemos el siguiente intervalo de confianza [66.06, 66.27]. Cuando calculamos el intervalo de confianza no podemos afirmar que cualquier valor de la población esté dentro del intervalo, lo que conseguimos establecer al calcular el intervalo de confianza es asegurarnos, en nuestro caso a un 95%, del procedimiento, es decir, que el nivel de confianza en el procedimiento de cualquier muestra esté garantizado dando lugar a un intervalo que contenga el valor. 

En resumen, de lo que nos garantizamos es que el 95% de los intervalos de confianza calculados a partir de cada meustra contengan el valor medio del rating.

# Diferencias entre jugadores

Existe una creencia que los jugadores zurdos tienen mejor control de la pelota que los diestros. Vamos a
comprobar qué dicen los datos al respecto. Nos preguntamos si los jugadores zurdos tienen mejor control
de pelota (Ball_Control), valoración (Rating) y mejor Dribbling que los diestros. Para ello, primero
seleccionad los jugadores que no son porteros (los porteros tienen el valor GK -Goal Keeper- en Club_Position).
Entonces, debéis obtener dos muestras. La primera muestra contiene todos los jugadores de campo (no
porteros) zurdos (Preffered_Foot igual a Left). La segunda muestra contiene todos los jugadores de campo
(no porteros) diestros (Preffered_Foot Right). Usad un nivel de confianza del 95 %.

## Pregunta de investigación

Formulad la/s pregunta/s de investigación que se plantea/n en este apartado.

En este ejercicio nos podemos hacer tres preguntas:

- ¿El control de la pelota de los jugadores zurdos es mejor que el control de pelota de los jugadores diestros?

- ¿La valoración de los jugadores zurdos es mejor que la valoración de los jugadores diestros?

- ¿El dribbling de los jugadores zurdos es mejor que el dribbling de los jugadores diestros?

## Representación visual

Representad visualmente, mediante el gráfico que sea más apropiado el valor de estas variables en jugadores
de campo (no porteros) diestros y zurdos. Se deben mostrar los valores de forma comparativa entre zurdos y
diestros. Interpretad los gráficos.

Antes que visualizar los dastos entre zurdos y diestros, tenemos que quedarnos con los jugadores de campo que no son porteros, y vamos a crear dos dataframes uno para los zurdos y otro para los diestros :
```{r}
df_copy_players = df_copy[df_copy$Club_Position != "GK",]
df_copy_players_left = df_copy_players[df_copy_players$Preffered_Foot == "Left",]
df_copy_players_right = df_copy_players[df_copy_players$Preffered_Foot == "Right",]
```

Una vez que ya tenemos filtrado los jugadores de campo, vamos a mostrar una visualización por cada variable a analizar (Ball_control, Rating, Dribbling).

Analizamos la variable Ball_Control respecto a zurdos y diestros:
```{r}
boxplot(df_copy_players_left$Ball_Control, 
        df_copy_players_right$Ball_Control, 
        main = "Control de balón de zurdos respecto a diestros",
        xlab = "Zurdos - Diestros",
        ylab = "Valor de Ball_Control"
        )
```

Tal y como podemos apreciar en la anterior gráfica la mediana de los jugadores zurdos es un poco más alta que la de diestros, además el primer cuartil de los zurdos es mayor que el de los diestros (esto significa que el 25% de los datos ordenados de menor a mayor tienen un mejor control de balón los zurdos respecto a los diestros).

Por otro lado, el nivel mínimo de los zurdos es algo mayor, por lo que a priori son menos malos, aunque el nivel máximo es un poco menor respecto a los diestros.

En resumen, dado el control de balón a priori podemos ver que la calidad media de los jugadores zurdos es un poco mejor, pero esto lo tendremos que confirmar con el contraste de hipóstesis.

Analizamos la variable Rating respecto a zurdos y diestros:
```{r}
boxplot(df_copy_players_left$Rating, 
        df_copy_players_right$Rating, 
        main = "Rating de zurdos respecto a diestros",
        xlab = "Zurdos - Diestros",
        ylab = "Valor de Rating"
        )
```

Al igual que sucedía en el gráfico anterior, la mediana de los zurdos es un poco mayor respecto a la de diestros. Su primer cuartil también es algo mayor junto con el nivel mínimo.

A primera vista sucede lo mismo que en el anterior gráfico, la calidad media del rating de los zurdos respecto a los diestros es algo mejor, pero tendremos que hacer un contraste de hipótisis para ver si es significativa dicha diferencia o no.

Analizamos la variable Dribbling respecto a zurdos y diestros:
```{r}
boxplot(df_copy_players_left$Dribbling, 
        df_copy_players_right$Dribbling, 
        main = "Dribbling de zurdos respecto a diestros",
        xlab = "Zurdos - Diestros",
        ylab = "Valor de Dribbling"
        )
```

De los tres gráficos analizados, este es el más representativo. Hay más diferencia entre la mediana de los zurdos respecto a los diestros y también en su primer cuartil. Además, de que el nivel mínimo de los zurdos es muchísimo mayor que el de diestros.

Por lo tanto, a priori sí que parece que respecto al dribbling los zurdos son mejores que los diestros, pero lo tenemos que analizar más detenidamente.

En resumen, en las tres variables que hemos analizado hay una ventaja en que los zurdos son mejores que los diestros, pero esto lo que vamos a comprobar a continuación, si es verdad o no.

## Hipótesis nula y alternativa

Escribid la/s hipótesis nula/s y la/s hipótesis alternativa/s.

En este ejercicio se plantean tres preguntas, por lo que vamos a tener tres hipótesis nulas y tres hipótesis alternativas.

Respecto al control del balón presentamos las siguientes hipótesis:

- H0 (hipótesis nula): Ball_Control de zurdos = Ball_Control de diestros.

- H1 (hipótesis alternativa): Ball_Control de zurdos > Ball_Control de diestros.

Respecto al rating presentamos las siguientes hipótesis:

- H0 (hipótesis nula): Rating de zurdos = Rating de diestros.

- H1 (hipótesis alternativa): Rating de zurdos > Rating de diestros.

Respecto al dribbling presentamos las siguientes hipótesis:

- H0 (hipótesis nula): Dribbling de zurdos = Dribbling de diestros.

- H1 (hipótesis alternativa): Dribbling de zurdos > Dribbling de diestros.

# Método

En función de las características de la muestra, decidid qué método aplicar para validar la hipótesis planteada.
Para ello, debéis especificar como mínimo: a) si es un contraste de una muestra o de dos muestras (en caso
de dos muestras, si éstas son independientes o están relacionadas), b) si podéis asumir normalidad y por
qué, c) si el test es paramétrico o no paramétrico, d) si el test es bilateral o unilateral, e) si se puede asumir
homocedasticidad o heterocedasticidad.

Justificad vuestras elecciones.

En este problema tenemos tres hipótesis planteadas, y todas ella son iguales:

- El contraste son de dos muestras, es decir, por un lado tenemos la muestra de zurdos y por otro lado tenemos la muestra de diestros. Estas muestras son independientes ya que no hay una relación entre muestras, es decir, no hay un hermano diestro para cada zurdo por ejemplo, no tenemos una relación para pode asociar a los elementos de cada muestra.

- Sí que podríamos asumir normalidad, para asumir normalidad podemos aplicar el teorema del límite central, el cual nos indica que la media de una muestra que sea lo suficientemente grande (mayor de 30 observaciones) sigue una distribución normal. Al poder calcular la media de ambas muestras esto lo cumplimos, solo nos hace falta comprobar que tenemos el número de observaciones mínimas, pero tal y como vemos a continuación esto también se cumple:
```{r}
cat("El número de observaciones de zurdos es: ", nrow(df_copy_players_left))
cat("El número de observaciones de diestros es: ", nrow(df_copy_players_right))
```

- El test es paramétrico, esto se debe a que los tests paramétricos son aquellos contrastes que trabajan con la asunción de que los datos siguen una determinada distribución, siendo la más habitual la normalidad de los datos, como bien hemos mencionado en el punto anterior sí que podríamos asumir normalidad de los datos por lo tanto es paramétrico.

- Para saber si el bilateral o unilateral nos podemos fijar en cómo está definida la hipótesis alternativa, en nuestro caso está definida con el símbolo mayor ">", por lo que solo vamos a aceptar la hipótesis alternativa si el valor observado es mayor que el valor crítico, en ese caso rechazaríamos la hipótesis nula. Por lo tanto, este caso se trata de un problema unilateral por la derecha.

- Respecto a si es homocedasticidad o heterocedasticidad hacemos uso de la función var.test y comprobamos si el p-valor es menor que alfa (nivel de signifancia), en nuestro caso si p-valor < alfa (0.05) rechazamos la hipótesis nula siendo ésta que las varianzas son iguales, tal y como podemos ver a continuación en todas las variables el p-valor es menor que alfa, por lo que rechazamos la hipótesis nula, lo cual significa que estamos en un caso de heterocedasticidad: 
```{r}
var.test(df_copy_players_left$Ball_Control, df_copy_players_right$Ball_Control , conf.level = 0.95)
var.test(df_copy_players_left$Rating, df_copy_players_right$Rating, conf.level = 0.95)
var.test(df_copy_players_left$Dribbling, df_copy_players_right$Dribbling, conf.level = 0.95)
```


