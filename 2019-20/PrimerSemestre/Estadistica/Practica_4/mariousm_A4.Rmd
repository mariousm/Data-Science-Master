---
title: "A4 - Análisis de varianza y repaso del curso"
author: "Mario Ubierna San Mamés"
date: '`r format(Sys.Date(),"%e de %B, %Y")`'
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Importación de librerías:
```{r}
library(ggplot2)
library(nortest)
```

# Lectura del fichero y preparación de los datos

Leed el fichero trainCLEAN.csv y guardad los datos en un objeto con identificador denominado claim. A contiunación, verificad que los datos se han cargado correctamente.
```{r}
claim = read.csv(file = "./data/trainCLEAN.csv", sep = ",", stringsAsFactors = TRUE, na.strings = NA)

head(claim)
```

Comprobamos los tipos de las variables y que se han cargado todas:
```{r}
str(claim)
```

Vemos que seguimos manteniendo las 15 variables iniciales, por lo que la lectura se ha realizado de forma correcta.

## Preparación de los datos

Cambiamos el nombre de las variables a castellano. En concreto, se pide que se denominen de la siguiente forma: Id, Ocurrencia, Apertura, Edad, Sexo, Estado, Dependientes, OtrosDepend, Salario, Jornada, CosteInicio, CosteFinal, HorasSemana, DiasSemana y Descripcion:
```{r}
colnames(claim) = c("Id", "Ocurrencia", "Apertura", "Edad", "Sexo", "Estado", "Dependientes", "OtrosDepend", "Salario", "Jornada", "HorasSemana", "DiasSemana", "Descripcion", "CosteInicio", "CosteFinal")

str(claim)
```

### Las variables ‘Ocurrencia‘ y ‘Apertura‘ están clasificadas como factor. Para poder trabajar con ellas hay que convertirlas en fechas:
```{r}
claim$Ocurrencia = as.Date(claim$Ocurrencia)
claim$Apertura = as.Date(claim$Apertura)

head(claim[, c("Ocurrencia", "Apertura")])
```

### Crear una variable denominada ‘tiempo‘ que contabilice en días el tiempo que tarda en abrirse un siniestro por la compañía desde su ocurrencia:
```{r}
claim$tiempo = as.integer(claim$Apertura - claim$Ocurrencia)

head(claim[, c("tiempo", "Ocurrencia", "Apertura")])
```

## Clasificación de tiempo

La variable tiempo indica la duración de apertura del siniestro de la siguiente forma: “Muy rápido” si se apertura en 15 días o menos, “Rápido” si se apertura entre 16 y 30 días, “Lento” si se apertura entre 31 y 89 días, y “Muy lento” si tarda 90 días o más en aperturarse el siniestro. Cread una variable categórica denominada Clasificacion, que clasifique el siniestro según estas categorías:
```{r}
claim$Clasificacion = as.factor(cut(claim$tiempo, breaks = c(-1, 15, 30, 89, 1095), labels = c("Muy rápido", "Rápido", "Lento", "Muy lento")))

head(claim[, c("tiempo", "Clasificacion")])
```

## Valores ausentes

### Analizad el número de categorías distintas en las variables ‘Descripcion‘, ‘Sexo‘ y ‘Estado‘. ¿Cuántas descripciones distintas hay de los siniestros?
```{r}
summary(claim)
```

Respecto a la variable Descripción vemos que tenemos muchos tipos de categorías, para ser más exactos hay 52417 categorías diferentes.

En cuanto a la variable Sexo, hay tres categorías: F, M y U. Éste último tipo nos indica que se desconoce si es de género femenino o masculino.

Finalmente, la variable Estado hay cuatro tipos: Sin valor (NA), M, S y U. Al igual que antes este último tipo nos indica que es deconocido el estado para dicha observación.

### Representad los observaciones con la categoría "U" (U=unknown) en las variables ‘Sexo‘y ‘Estado‘ como missings.

```{r}
claim[claim$Sexo == "U", "Sexo"] = NA 
claim[claim$Estado == "U", "Estado"] = NA
```


Comprobamos que se han realizado los cambios:
```{r}
summary(claim$Sexo)
summary(claim$Estado)
```

Ahora vemos que ya tenemos todos los valores perdidos como NA.

### Comprobad la proporción de observaciones que tienen valores ausentes y sacad conclusiones sobre cómo de serio es el problema de valores ausentes en estos datos.

En el anterior apartado hemos visto que hay 2 observaciones con valor NA para la variable Sexo, realmente son observaciones insignificantes ya que hay un total de 54000 registros y solo dos son NA. Por lo que, podríamos eliminar dichas observaciones sin problemas.

Respecto a la variable Estado vemos que tenemos más registros como NA, para ser más exactos hay 5294 observaciones de un total de 54000 registros, esto representa un 9.8% de los datos, es decir, en este caso sí que es significativo. Podríamos crear un modelo de regresión lineal para predecir dicho valor, imputar el valor más frecuente, pero en el siguiente apartado se nos pide que se eliminen dichas observaciones.

### Eliminad los valores ausentes del conjunto de datos. Denominamos al conjunto de datos claimNet.

Ejecutamos el summary para ver qué variables tienen valores ausentes, los cuales son distintos de los missings, los primeros son aquellos en los que no viene un valor, mientras que lo segundo sí que viene un valor pero es del tipo unknown:
```{r}
summary(claim)
```

De la anterior ejecución vemos que la variable Estado tiene 29 como vacíos (valores ausentes), por lo que procedemos la eliminación de dichos registros, también elimanos las observaciones cuyo valores sea NA:
```{r}
claimNet = claim[claim$Estado != "", ]
claimNet = claimNet[!is.na(claimNet$Estado),]
claimNet = claimNet[!is.na(claimNet$Sexo),]

summary(claimNet)
```

Vemos que ahora el dataset ha pasado de 54000 registros a 48675.

## Saluda mental

La compañía está preocupada por las bajas por salud mental. Por este motivo, quiere monitorizar las bajas que incluyan las palabras Stress, Anxiety, Harassment o Depression. Se pide:

### Crear la variable dicotómica denominada ‘RiesgoSM‘ si la variable ‘Descripcion‘ incluye alguna de estas palabras.

Lo primero de todo es definir la función que nos devuelve un vector con la variable dicotimizada, un 1 si encuentra la palabra en la descripción o 0 en caso contrario:
```{r}
getRiesgoSM = function(descripciones) {
  riesgoSM = c()

  for (desc in descripciones) {
    if (grepl("STRESS", toupper(desc)) == TRUE ||
        grepl("ANXIETY", toupper(desc)) == TRUE || 
        grepl("HARASSMENT", toupper(desc)) == TRUE || 
        grepl("DEPRESSION", toupper(desc)) == TRUE) {
     riesgoSM[length(riesgoSM) + 1] = 1
   } else {
     riesgoSM[length(riesgoSM) + 1] = 0
   } 
  }
  
  return(riesgoSM)
}
```

Una vez definida la función la llamamos y creamos la variables en el dataframe:
```{r}
claimNet$RiesgoSM = getRiesgoSM(claimNet$Descripcion)

#La convertimos a factor
claimNet$RiesgoSM = as.factor(claimNet$RiesgoSM)

# Comprobamos que se ha creado correctamente
str(claimNet)
```

## Análisis visual

Mostrad con diversos diagramas de caja la distribución de la variable ‘CosteFinal‘ en escala logarítmica según la variable ‘Sexo‘, según ‘Estado‘, según ‘Clasificacion‘ y según ‘RiesgoSM‘. E interpretad los gráficos brevemente.

Lo primero de todo es crear una nueva variable para convertir a escala logarítmica el CosteFinal:
```{r}
claimNet$LogCosteFinal = log(claimNet$CosteFinal)

summary(claimNet)
```

Una vez que ya tenemos la variable CosteFinal en escala logarítmica, hacemos el análisis de la misma respecto al sexo:
```{r}
boxplot(claimNet[claimNet$Sexo == "F", "LogCosteFinal"],
        claimNet[claimNet$Sexo == "M", "LogCosteFinal"],
        main = "CosteFinal respecto al Sexo",
        xlab = "Femenino - Masculino",
        ylab = "Valor de CosteFinal"
        )
```

Del anterior gráfico podemos observar que el género femenino tiene un valor mínimo algo mayor que el masculino, es por ello que su mediana es un pelín más elevada, esto lo que significa es que de media las mujeres tienen un CosteFinal algo mayor, en otras palabras la indemnización suele ser algo mayor si eres mujer.

Por otro lado, observamos que hay bastantes valores atípicos en los dos sexos, pero especialemnte más en el masculino, es decir, suele haber más casos "especiales" si eres hombre que si eres mujer.

Continuiamos analizando el CosteFinal, pero ahora respecto a el estado civil:
```{r}
boxplot(claimNet[claimNet$Estado == "M", "LogCosteFinal"],
        claimNet[claimNet$Estado == "S", "LogCosteFinal"],
        main = "CosteFinal respecto al Estado",
        xlab = "Casado - Soltero",
        ylab = "Valor de CosteFinal"
        )
```

En este caso, vemos que sucede algo parecido, si eres casado tu valor en el límite inferior es algo mayor que si estás soltero haciendo que la mediana sea algo mayor, es decir, si estás casado sueles obtener una mejor indemnización que si estás soltero.

Por otro lado, vemos que también hay muchos valores atípicos, pero en este caso está bastante bien equilibrado entre ambos grupos.

Analizamos el CosteFinal según la variable Clasificación:
```{r}
boxplot(claimNet[claimNet$Clasificacion == "Muy rápido", "LogCosteFinal"],
        claimNet[claimNet$Clasificacion == "Rápido", "LogCosteFinal"],
        claimNet[claimNet$Clasificacion == "Lento", "LogCosteFinal"],
        claimNet[claimNet$Clasificacion == "Muy lento", "LogCosteFinal"],
        main = "CosteFinal respecto a la Clasificación",
        xlab = "Muy rápido - Rápido - Lento - Muy lento",
        ylab = "Valor de CosteFinal"
        )
```

El anterior gráfico es muy interesante, ya que nos indica que si la duración de apertura del siniestro es muy lenta, podemos entender que se realiza un estudio muy detallado, por lo que apenas tenemos valores atípicos y éstos están muy bien contralados. Sin embargo, con el resto de variables sucede todo lo contrario.

También es curioso ver que si la clasificación es rápida tiende a tener una mayor indemnización, es decir, el coste que le supone a la asegurado es mayor, esto lo apreciamos gracias a la mediana correspondiente.

Por último, vamos a analizar el CosteFinal según el RiesgoSM:
```{r}
boxplot(claimNet[claimNet$RiesgoSM == "1", "LogCosteFinal"],
        claimNet[claimNet$RiesgoSM == "0", "LogCosteFinal"],
        main = "CosteFinal respecto al RiesgoSM",
        xlab = "Hay riesgo (1) - No hay riesgo (0)",
        ylab = "Valor de CosteFinal"
        )
```

Este gráfico es el más llamativo de todos ya que en los anteriores estaban más o menos nivelados, pero en este caso vemos que el riesgo de padecer un enfermedad de salud mental influye bastante en el coste final, siendo el límite inferior más elevado y su mediana también.

Por otro lado, si no hay riesgo tenemos más valores atípicos, es decir, hay más situacioens "especiales" que por los motivos que sean se dan una indemnización mayor o menor.

## Comprobación de normalidad

¿Podemos asumir que la variable CosteFinal tiene una distribución normal? Debéis justificar la respuesta a partir de métodos visuales y contrastes.

### Realizad la insepección visual de normalidad de CosteFinal

Lo primero de todo es analizar la variables CosteFinal de forma gráfica:
```{r}
ggplot(mapping = aes(x=claimNet$CosteFinal)) + geom_density()
```

Como podemos apreciar de la anterior ilustración, CosteFinal no sigue una distribución normal, pero vamos a anilizarlo en el siguiente punto a partir de un test.

### Realizad contraste de normalidad de Lilliefors de CosteFinal

Aplicamos el test de Lilliefors, en dicho test la hipótesis nula es que la variable sigue una distribución norma, y la alternativa en caso contrario:
```{r}
lillie.test(claimNet$CosteFinal)
```

Como nos da un pvalue más pequeño que alfa (0.05), es decir, pvalue < alfa, podemos rechazar la hipótesis nula a favor de la alternativa, es decir, que nuestra variable no sigue una distribución normal.

### Realizad la insepección visual de normalidad de CosteFinal en escala logarítmica

Realizamos el mismo gráfico que antes pero para la variable LogCosteFinal:
```{r}
ggplot(mapping = aes(x=claimNet$LogCosteFinal)) + geom_density()
```

Como podemos apreciar, a priori cuando escalamos la variable logarítmica sí que sigue una distribución normal, pero para confirmarlo ejecutamos el mismo test que en el caso anterior.

### Realizad contraste de normalidad de Lilliefors de CosteFinal en escala logarítmica

Volvemos a aplicar el test de Lilliefors:
```{r}
lillie.test(claimNet$LogCosteFinal)
```

En este caso nos da un pvalue mayor que alfa, es decir, pvalue > 0.05, por lo tanto podemos asegurar que la variable CosteFinal en escala logarítmica sigue una distribución normal.

# Estadística inferencial

Utilizando el conjunto de datos claimNet.

## Intervalo de confianza de la media poblacional de la variable CosteFinal

Calculad manualmente el intervalo de confianza al 95% de la media poblacional de la variable ‘CosteFinal‘ en escala normal (No se pueden utilizar funciones como t.test o z.test para el cálculo). A partir del resultado obtenido, explicad cómo se interpreta el intervalor de confianza.

En este ejercicio no tenemos una muestra sino que el dataset es el conjunto de toda la población, por lo que, aunque no conozcamos a priori la desviación de la población y su media, lo podríamos calcular fácilmente porque tenemos a la población en sí, no una muestra de ella.

Además, debemos asumir que seguimos una distribución normal, antes hemos comprobado que para esta variable no es así, pero aplicando el Teorema del Límite Central, si tenemos una muestra lo suficientemente grande (mayor que 30 observaciones) la media de la misma sigue una distribución normal. Como podemos calcular la media, solo tenemos que comprobar el tamaño de nuestra muestra que es más bien el tamaño de la población:
```{r}
cat("El tamaño de la muestra (población) es igual a", length(claimNet$CosteFinal))
```

De la anterior ejecución vemos que tenemos una muestra muy grande, ya que ésta es la población en sí.

Por lo tanto, lo primero que vamos a hacer es calcular la media y la desviación de la población:
```{r}
media_poblacion = mean(claimNet$CosteFinal)
sd_poblacion = sd(claimNet$CosteFinal)
```

Lo segundo es definir nuestra alfa (nivel de significancia) y el tamaño de la población:
```{r}
alfa = 1 - 0.95
tam_poblacion = length(claimNet$CosteFinal)
```

Calculamos el estadístico correspondiente:
```{r}
estadistico = sd_poblacion / sqrt(tam_poblacion)
z = qnorm(alfa/2, lower.tail = FALSE)
```

Finalmente, calculamos los límites:
```{r}
lim_inferior = round(media_poblacion - (z * estadistico), 2)
lim_superior = round(media_poblacion + (z * estadistico), 2)

cat("El límite inferior del intervalo de confianza (L) es igual a: ", lim_inferior)
cat("El límite superior del intervalo de confianza (U) es igual a: ", lim_superior)
```

De la anterior ejecución observamos que el intervalo de confianza es [9450.35, 9958.81]. Cuando calculamos el intervalo de confianza no podemos afirmar que cualquier valor de la población esté dentro del intervalo, lo que conseguimos definir al calcular el intervalo de confianza es asegurarnos, en nuestro caso a un 95%, del procedimiento, es decir, que el nivel de confianza en el procedimiento de cualquier muestra esté garantizado dando lugar a un intervalo que contenga el valor.

Resumiendo, de lo que nos garantizamos es que el 95% de los intervalos de confianza calculados a partir de cada muestra contengan el valor del CosteFinal.

## Contraste de hipótesis para la diferencia de medias

¿Podemos aceptar que la indemnización a las mujeres supera en más de 1000 EUR la de los hombres? Responded a la pregunta utilizando un nivel de confianza del 95%.

Nota: se deben realizar los cálculos manualmente. No se pueden usar funciones de R que calculen directamente
el contraste como t.test o similar. Sí se pueden usar funciones como mean, sd, qnorm, pnorm, qt y pt.

### Escribid la hipótesis nula y la alternativa

En este caso, presentamos las siguientes hipótesis:

- H0 (hipótesis nula): media_CosteFinal_Mujeres = (media_CosteFinal_Hombres + 1000)

- H1 (hipótesis alternativa): media_CosteFinal_Mujeres > (media_CosteFinal_Hombres + 1000)

###  Justificación del test a aplicar

En este problema tenemos questión a responder y presenta las siguientes características:

- El contraste es de dos muestras, por un lado está la muestra de las mujeres y por otro el de hombres. Estas muestras son independientes no hay una relación entre sí.

- Sí que podemos asumir normalidad, es decir, podemos aplicar el Teorema del Límite Central, éste nos dice que si la media de una muestra es lo suficientemente grande (mayor que 30 observaciones) sigue una distribución normal. Al poder calcular la media de ambas muestras solo nos falta comprobar el tamaño de las mismas:
```{r}
claimNet_femenino = claimNet[claimNet$Sexo == "F",]
claimNet_masculino = claimNet[claimNet$Sexo == "M",]

cat("El número de observaciones del sexo femenino es: ", nrow(claimNet_femenino))
cat("El número de observaciones del sexo masculino es: ", nrow(claimNet_masculino))
```

- El test es paramétrico, éstos se basan en que los datos siguen una determinada distribución, por norma general que siguen una distribución normal, por lo que tal y como hemos visto en el punto anterior podemos asumir la normalidad de los datos.

- El problema es unilateral por la derecha, ésto nos lo determina la hipótesis alternativa, ya que al tener el símbolo ">" mayor que, solo aceptamos la hipótesis alternativa si el valor observado es mayor que el valor crítico.

- Respecto a si es homocedasticidad o heterocedasticidad hacemos uso de la función var.test y comprobamos si el p-valor es menor que alfa (nivel de signifancia), en nuestro caso si p-valor < alfa (0.05) rechazamos la hipótesis nula siendo ésta que las varianzas son iguales, tal y como podemos ver a continuación el p-valor es menor que alfa, por lo que rechazamos la hipótesis nula, lo cual significa que estamos en un caso de heterocedasticidad:
```{r}
var.test(claimNet_femenino$CosteFinal, claimNet_masculino$CosteFinal, conf.level = 0.95)
```

### Cálculos

Realizad los cálculos del estadístico de contraste, valor crítico y valor p con un nivel de confianza del 95%.

Lo primero de todo es definir la función que nos calcula el estadístico, el valor crítico y el pvalor:
```{r}
muestrasIndependientes_varianzasDesconocidas = function(valores_fem, valores_masc, alfa) {
  
  # Calculamos el estadístico de contraste
  sd_fem = sd(valores_fem)
  sd_masc = sd(valores_masc)
  n_fem = length(valores_fem) 
  n_masc = length(valores_masc)
  
  # -1000 porque se indica en la hipótesis media_CosteFinal_Mujeres > (media_CosteFinal_Hombres + 1000)
  numerador = mean(valores_fem) - mean(valores_masc) - 1000
  denominador = sqrt(((sd_fem)^2/n_fem) + ((sd_masc)^2/n_masc))
  
  z_obs = numerador / denominador
  
  # Calculamos los grados de libertad
  numerador = (((sd_fem)^2/n_fem) + ((sd_masc)^2/n_masc))^2
  denominador = (((sd_fem)^2/n_fem)^2 / (n_fem - 1)) + (((sd_masc)^2/n_masc)^2 / (n_masc - 1))
  grados_libertad = as.integer(numerador / denominador)
  
  # Calculamos el punto crítico
  z_cri = qt(alfa, df = grados_libertad, lower.tail = FALSE)
  
  # Calculamos el p-valor
  p_value = pt(z_obs, df = grados_libertad, lower.tail = FALSE)
  
  # Devolvemos los valores
  return(data.frame(L = "-INF", U = z_cri, Estadistico_Contraste = z_obs, P_Valor = p_value, Grados_Libertad = grados_libertad))
}
```

Una vez definida la función la llamamos para obtener los resultados:
```{r}
muestrasIndependientes_varianzasDesconocidas(claimNet_femenino$CosteFinal, claimNet_masculino$CosteFinal, 0.05)
```

# Interpretación del test

Podemos interpretar el test de dos formas distintas:

- La primera, comprobamos si el valor observado está fuera de la región de aceptación, si está fuera podemos rechazar la hipótesis nula en favor de la alternativa. En nuestro caso, la región de aceptación es el intervalo [-INF, 1.64495] y el valor observado 3.591609, como el valor observado está fuera de la región de aceptación rechazamos la hipótesis nula a favor de la alternativa, es decir, que es verdad que la indemnización de las mujeres supera en más de 1000 euros a la de hombres con un nivel de confianza del 95%.

- La segunda opción es comprobar el pvalor, si éste es menor que alfa rechazamos la hipótesis nula, en nuestro caso pvalor = 0.00016 < alfa = 0.05, al ser menor que alfa rechazamos la hipótesis nula en favor de la alternativa, es decir, confirmamos que la indemnización de las mujeres supera en 1000 euros a la de hombres con un nivel de confianza del 95%. 














