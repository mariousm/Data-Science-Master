---
title: 'Minería de datos: PRA1 - Selección y preparación de un juego de datos'
author: "Autor: Mario Ubierna San Mamés"
date: "Abril 2021"
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
    includes:
      in_header: 75.584-PEC-header.html
  word_document: default
  pdf_document:
    highlight: zenburn
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
******
# Introducción
******
## Presentación
Esta práctica cubre de forma transversal la asignatura.

Las Prácticas 1 y 2 de la asignatura se plantean de una forma conjunta de modo que la Práctica 2 será continuación de la 1.

El objetivo global de las dos prácticas consiste en seleccionar uno o varios juegos de datos, realizar las tareas de **preparación y análisis exploratorio** con el objetivo de disponer de datos listos para **aplicar algoritmos** de clustering, asociación y clasificación.

## Competencias
Las competencias que se trabajan en esta prueba son:  

* Uso y aplicación de las TIC en el ámbito académico y profesional.
* Capacidad para innovar y generar nuevas ideas.
* Capacidad para evaluar soluciones tecnológicas y elaborar propuestas de proyectos teniendo en cuenta los recursos, las alternativas disponibles y las condiciones de mercado.
* Conocer las tecnologías de comunicaciones actuales y emergentes así como saberlas aplicar convenientemente para diseñar y desarrollar soluciones basadas en sistemas y tecnologías de la información.
* Aplicación de las técnicas específicas de ingeniería del software en las diferentes etapas del ciclo de vida de un proyecto.
* Capacidad para aplicar las técnicas específicas de tratamiento, almacenamiento y administración de datos.
* Capacidad para proponer y evaluar diferentes alternativas tecnológicas para resolver un problema concreto.

## Objetivos
La correcta asimilación de todos los aspectos trabajados durante el semestre.  
En esta práctica abordamos un caso real de minería de datos donde tenemos que poner en juego todos los conceptos trabajados.
Hay que trabajar todo el ciclo de vida del proyecto. Desde el objetivo del proyecto hasta la implementación del conocimiento encontrado pasando por la preparación, limpieza de los datos, conocimiento de los datos, generación del modelo, interpretación y evaluación.

## Descripción de la PRA a realizar

## Recursos Básicos
Material docente proporcionado por la UOC. 

## Criterios de valoración

**Ejercicios prácticos** 

Para todas las PRA es **necesario documentar** en cada apartado del ejercicio práctico que se ha hecho y como se ha hecho.

## Formato y fecha de entrega PRA_1
El formato de entrega es: usernameestudiant-PRAn.html/doc/docx/odt/pdf  
Fecha de entrega: 05/05/2021  
Se debe entregar la PRA_1 en el buzón de entregas del aula  

## Nota: Propiedad intelectual 

> A menudo es inevitable, al producir una obra multimedia, hacer uso de recursos creados por terceras personas. Es por lo tanto comprensible hacerlo en el marco de una práctica de los estudios de Informática, Multimedia y Telecomunicación de la UOC, siempre y cuando esto se documente claramente y no suponga plagio en la práctica. 

> Por lo tanto, al presentar una práctica que haga uso de recursos ajenos, se debe presentar junto con ella un documento en que se detallen todos ellos, especificando el nombre de cada recurso, su autor, el lugar donde se obtuvo y su estatus legal: si la obra esta protegida por el copyright o se acoge a alguna otra licencia de uso (Creative Commons, licencia GNU, GPL ...). 
El estudiante deberá asegurarse de que la licencia no impide específicamente su uso en el marco de la práctica. En caso de no encontrar la información correspondiente tendrá que asumir que la obra esta protegida por copyright. 

> Deberéis, además, adjuntar los ficheros originales cuando las obras utilizadas sean digitales, y su código fuente si corresponde.  

******
# Enunciado
******
Todo estudio analítico debe nacer de una necesidad por parte del **negocio** o de una voluntad de dotarle de un conocimiento contenido en los datos y que solo podremos obtener a través de una colección de buenas prácticas basadas en la Minería de Datos.  

El mundo de la analítica de datos se sustenta en 3 ejes:  

1. Uno de ellos es el profundo **conocimiento** que deberíamos tener **del negocio** al que tratamos de dar respuestas mediante los estudios analíticos.  

2. El otro gran eje es sin duda las **capacidades analíticas** que seamos capaces de desplegar y en este sentido, las dos prácticas de esta asignatura pretenden que el estudiante realice un recorrido sólido por este segundo eje.  

3. El tercer eje son los **Datos**. Las necesidades del Negocio deben concretarse con preguntas analíticas que a su vez sean viables responder a partir de los datos de que disponemos. La tarea de analizar los datos es sin duda importante, pero la tarea de identificarlos y obtenerlos va a ser para un analista un reto permanente.  

Como **primera parte** del estudio analítico que nos disponemos a realizar, se pide al estudiante que complete los siguientes pasos:   


1. Plantear un problema de analítica de datos detallando los objetivos analíticos y explica una metodología para resolverlos de acuerdo con lo que se ha practicado en las PEC y lo que se ha aprendido en el material didáctico.

2. Seleccionar un juego de datos y justificar su elección. El juego de datos deberá tener capacidades para que se le puedan aplicar algoritmos supervisados, algoritmos no supervisados y reglas de asociación y deberá estar alineado con el problema analítico planteado en el paso anterior.   
El juego de datos deberá tener como mínimo 100 observaciones y debe ser distinto del usado en las PEC anteriores.

3. Realizar un análisis exploratorio del juego de datos seleccionado.   

4. Realizar tareas de limpieza y acondicionado para poder ser usado en procesos de modelado.

5. Realizar métodos de discretización

6. Aplicar un estudio PCA sobre el juego de datos. A pesar de no estar explicado en el material didáctico, se valorará si en lugar de PCA investigáis por vuestra cuenta y aplicáis SVD (Single Value Decomposition).


******
# Solución
******

## Planteamiento del problema de analítica de datos

En esta primera fase lo que debemos de realizar es el planteamiento del problema de analítica que vamos a resolver, detallando cuáles son los objetivos analíticos y explicar qué metodologías podríamos seguir para resolver dicho problema.

El cáncer es una de las mayores enfermades que sufrimos diariamente, todo el mundo conoce a gente que ha padecido o padece de dicha enfermedad, cuando escuchamos la palabra cáncer nos ponemos en alerta debido al gran desconocimiento que tenemos sobre por qué surge esa enferdad, cómo evoluciona, cómo evitarla...

Al no conocer bien las diferentes causas de esta enfermedad no sabemos cuándo empieza hasta que no tenemos síntomas a nivel celular de que nuestras células están cambiando/mutando, de ser células beningnas a malignas.

Por experiencia personal este es un tema delicado ya que ha afectado a mi familia directamente, para ser más concisos, algunas mujeres de mi familia padecieron cáncer de mama. Este tipo de cáncer sobre todo en las mujeres es el segundo tipo de cáncer que más ocurre entre ellas, solo en España según la AECC (la Asociación Española Contra el Cáncer), en 2018 se estimó que 130000 mujeres fueron diagnósticadas con dicha enfermedad.

A día de hoy seguimos teniendo miedo del cáncer debido a que no tenemos un cura como tal, sino que la única forma de superarlo es diagnosticarlo pronto, y es aquí donde entra en juego la minería de datos, ya que gracias a diferentes algoritmos podemos identificar si un persona padece cáncer o no antes de que sea demasiado tarde.

Por lo tanto, una vez que tenemos el contexto del problema vamos a definir cada una de las fases del proyecto de minería de datos:

### Definición del proyecto

Lo primero que debemos de hacer es definir los objetivos de nuestro proyecto, es decir, que es lo que buscamos dar respuesta. Esta fase es fundamental ya que de no definir los objetivos de forma correcta podría darse el caso de no llegar a las correctas conclusiones.

Por lo tanto, en nuestro caso el cáncer de mama va a ser el caso de estudio, con el fin de saber si una persona padece cáncer o no a partir de las características de las células, gracias a esto podremos diagnósticar temprenamente la fase en la que se encuentra el cáncer y si es cáncer o no.

Anque a priori es un problema de clasificación, es decir, buscamos saber si una persona padece cáncer de mama o no, y vamos a tener constancia para cada persona si padece cáncer o no, podríamos aplicar otros algoritmos que no fueran de aprendizaje supervisado, como el clustering, sería interesante el ver cómo un algoritmo agrupa los elementos más parecidos sin el conocimiento necesario para clasificar si es beningno o maligno el cáncer de mama, es decir, buscar que un algoritmo nos determine qué es lo que caracteriza al cáncer sin entrar a saber si una persona tiene cáncer o no.

En resumen, el problema al que hacemos frente es el saber cómo es el cáncer de mama, es decir, que le caracteriza y por otro lado, diagnosticar si una persona padece cáncer de mama o no los más pronto posible para aumentar las probabilidades de vida.

Como vemos los objetivos son claros, lo que necesitamos ahora es obtener los datos.

### Origen de los datos

Tal y como vimos en la etapa anterior lo primero que debemos hacer es definir los objetivos, y una vez que están claros hay que buscar los datos.

Los datos son necesarios para poder aplicar cualquier algoritmo de minería de datos, por lo que al no tener datos sobre el cáncer de mama a mano, hemos obtado por buscar en internet datasets que contuvieran la información necesaria para poder alcanzar los objetivos.

Por lo que, Machine Learning Respositry nos ofrece el dataset que estamos buscando sobre el cáncer de mama [https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Original%29]

### Preparación de los datos

Una vez que ya tenemos los datos necesitmos construir el modelo, pero para que éste funcione correctamente debemos pasarle los mismos con la mayor calidad posible, esto se debe a que nos podemos encotrar problemas como: hay observaciones sin algún valor, observaciones duplicadas...

Por lo tanto, el objetivo de esta fase es hacer la limpieza de todo el dataset para que los resultados obtenidos sean los de mayor calidad posible.

Dentro de esta fase, siempre y cuando tengamos determinados problemas, debemos hacer: la limpieza de datos innesarios o redundantes, transformar algunos datos, reducidir la dimensionalidad del dataset.

### Construcción del modelo

Cuando ya tenemos todos los datos limpios debemos construir el modelo, como bien hemos mencionado, este problema junto con su dataset se identifica mejor como un problema de clasificación, por lo que hacer uso de los árboles de decisión nos va a permitir ver según que parámetros y bajo qué valores una persona puede padecer cáncer o no.

Aunque inicialmente sea un problema más acorde con la clasificación, esto no significa que no se puedan usar otros algoritmos, ya que por ejemplo podemos hacer uso del clustering, para saber cómo se agrupan las células, aunque sabemos que hay solo dos tipos (benignas y malignas), al hacer uso del clustering dejamos a manos de un algoritmo que agrupe sin nostros indicarle nada, gracias a esto podemos saber qué caracteriza a un paciente con cáncer de mama respecto a un paciente que no padece de dicha enfermedad.

En resumen, podemos hacer uso de árboles de decisión y algoritmos de clustering para alcanzar los objetivos de nuestro proyecto que son dos: saber si una persona padece cáncer de mama o no, y saber qué le caracteriza al cáncer, es decir, cómo es el cáncer de mama.

### Evaluación e interpretación del modelo

Una vez que ya hemos construido los diferentes modelos, tenemos que evaluar cómo de buenos son, es decir, si realmente nos sirven para alcanzar los objetivos y responder a las preguntas que nos hemos hecho, en caso de que no, tendremos que buscar otros modelos que nos den mejores resultados.

Para evaluar el modelo de clasificación, podemos dividir el dataset original en dos, uno para el entrenamiento y otro de testing para validar los resultados obtenidos y calcular el error, de tal forma que a menor error mejor es el modelo. Respecto al uso de árboles de decisión podemos asignar un peso/porcentaje a cada posible resultado de tal forma que máximice la identificación de pacientes con cáncer de mama y a los que no tienen cáncer, es decir, será mejor el modelo cuanto menos falsos positivos y falsos negativos haya.

Para evaluar el modelo de clustering, podemos calcular la distancia que hay entre los puntos de un clúster al centro de su propio clúster, por lo que a menor distancia más compacto/mejor definido está el clúster, pero también podemos calcular la distancia entre los centros de todos los clústers, por lo que a mayor distancia más separación entre clústers y características más diferenciadas hay.

### Integración de los resultados

Una vez que hemos evaluado la calidad del modelo y si éste da respuestas a las preguntas que nos hacemos, tenemos que hacer uso de esta información para mejorar la situación actual sobre el cáncer de mama, ya sea informando a los médicos, a los pacientes directamente...

Cabe destacar que esto es un proceso iterativo, es decir, que podemos llegar a esta fase y volver a empazar de cero porque nos hacemos nuevas preguntas, o porque hay que seguir mejorando el modelo.

## Selección del dataset

Tal y como hemos mencionado en el apartado anterior, el dataset elegido para dar respuestas a las preguntas que nos hemos hecho es el de Breast Cancer Wisconsin (Original) Data Set de Machine Learning Repository [https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Original%29]

Hemos elegido dicho dataset porque nos proporciona toda la información necesaria para dar respuesta a las preguntas que nos hacemos, a partir de datos como el tamaño de la célula, la forma de la célula...

Es verdad que hay datasets similares a este pero con más atributos, es decir, aquí solo tenemos un campo para el tamaño de la célula, mientras que en otros datasets ese campo podía venir representado por tres atributos, pero este dataset consigue mantener la misma información reduciendo ya la dimensionalidad de los atributos. Por otro lado, los valores numéricos en este conjunto de datos van del 1 al 10, es decir, [1-10], estos valores no son aleatorios sino que un grupo de expertos ha "normalizado" dichos valores para representar la misma información pero de una forma más sencilla.

Finalmente, a continuación se indica los atributos que tiene este dataset:

**Id**
    integer - identificador de la observación.
    
**Thickness**
    integer [1-10] - espesor/grosor del tumor.
    
**Cell_Size**
    integer [1-10] - uniformidad del tamaño celular.
    
**Cell_Shape**
    integer [1-10] - uniformidad de la forma celular.
    
**Adhesion**
    integer [1-10] - adherencia celular.
    
**Epithelial_Cell_Size**
    integer [1-10] - tamaño de una sola célula epitelial.
    
**Bare_Nuclei**
    integer [1-10] - núcleo desnudo.
    
**Bland_Chromatin**
    integer [1-10] - textura del núcleo.
    
**Normal_Nucleoli**
    integer [1-10] - nucléolos normales.
    
**Mitoses**
    integer [1-10] - mitosis.
    
**Class**
    integer - clase si es beningno 2, si es maligno 4.
    
Aunque algun concepto es fácil de entender los demás no, es por ello que vamos a definir cada concepto:

- Thickness: hace referencia al espesor/grosor de la masa mamaria que se estudia, es decir, del tumor.

- Cell_Size: tamaño de las células que se estudian, las células cancerígenas suelen cambiar de tamaño.

- Cell_Shape: forma de las células que se estudian, las células cancerígenas suelen cambiar de forma.

- Adhesion: las células que son cancerígenas tienden a separarse unas de las otras, mientras que en las células normales sucede todo lo contrario.

- Epithelial_Cell_Size: las células que son significativamente grandes suelen ser cancerígenas.

- Bare_Nuclei: nos indica si el núcleo de las células está rodeado por el citoplasma (células normales), en caso contrario es probable que sean células cancerígenas.

- Bland_Chromatin: textura de los núcleos de las células, cuanto más tosco sea más probabiliades de que la célula sea cancerígena.

- Normal_Nucleoli: los nucleólos son pequeñas estructuras que se encuentran en los núcleos, en células benignas suelen ser estructuras pequeñas mientras que en las malignas son más grandes.

- Mitoses: proceso en el cual las células eucariotas se dividen.

Toda esta información se ha obtenido de la siguiente página [https://core.ac.uk/download/pdf/77274625.pdf], cabe destacar que a mayor valor de cada atributo más probable es que la célula sea anormal y dentro de esta anormalidad sea cancerígena.

Por último, tenemos 699 observaciones y 11 atributos.


******
# Rúbrica
******
* 30% Se plantea un problema propio de minería de datos, se detallan los objetivos analíticos y se explica detalladamente el procedimiento para darles solución.
* 10%. Justificación de la elección del juego de datos donde se detalle el potencial analítico que se intuye. El estudiante deberá visitar los siguientes portales de datos abiertos para seleccionar su juego de datos:
  + [Datos.gob.es](https://datos.gob.es/es/catalogo?q=&frequency=%7B"type"%3A+"months"%2C+"value"%3A+"1"%7D&sort=score+desc%2C+metadata_modified+desc)
  + [UCI Machine Learning](https://archive.ics.uci.edu/ml/datasets.php)
  + [Datasets Wikipedia](https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research)
  + [Datos abiertos Madrid](https://datos.madrid.es/portal/site/egob/)
  + [Datos abiertos Barcelona](https://opendata-ajuntament.barcelona.cat/es/)
  + [London Datastore](https://data.london.gov.uk/)
  + [NYC OpenData](https://opendata.cityofnewyork.us/)
* 20%. Información extraída del análisis exploratorio. Distribuciones, correlaciones, anomalías,... 
* 20%. Explicación clara de cualquier tarea de limpieza o acondicionado que se realiza. Justificando el motivo y mencionando las ventajas de la acción tomada.
* 20%. Se realiza un proceso de PCA o SVD donde se aprecia mediante explicaciones y comentarios que el estudiante entiende todos los pasos y se Scomenta extensamente el resultado final obtenido.


******
# Recursos de programación
******
* Incluimos en este apartado una lista de recursos de programación para minería de datos donde podréis encontrar ejemplos, ideas e inspiración:
  + [Material adicional del libro: Minería de datos Modelos y Algoritmos](http://oer.uoc.edu/libroMD/)
  + [Espacio de recursos UOC para ciencia de datos](http://datascience.recursos.uoc.edu/es/)
  + [Buscador de código R](https://rseek.org/)  
  + [Colección de cheatsheets en R](https://rstudio.com/resources/cheatsheets/)  
  

