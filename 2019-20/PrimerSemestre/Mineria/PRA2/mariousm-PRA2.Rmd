---
title: 'Minería de datos: PRA2 - Modelado de un juego de datos'
author: "Autor: Mario Ubierna San Mamés"
date: "Mayo 2021"
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
    includes:
      in_header: 75.584-PEC-header.html
  word_document: default
  pdf_document:
    highlight: zenburn
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
******
# Introducción
******
## Presentación
Esta práctica cubre de forma transversal la asignatura.

Las Prácticas 1 y 2 de la asignatura se plantean de una forma conjunta de modo que la Práctica 2 será continuación de la 1.

El objetivo global de la **Práctica 2** es de extraer conocimientos y de comparar las diferentes soluciones aplicando todo lo aprendido mediante los algoritmos de clustering, asociación y clasificación.

## Competencias
Las competencias que se trabajan en esta prueba son:  

* Uso y aplicación de las TIC en el ámbito académico y profesional.
* Capacidad para innovar y generar nuevas ideas.
* Capacidad para evaluar soluciones tecnológicas y elaborar propuestas de proyectos teniendo en cuenta los recursos, las alternativas disponibles y las condiciones de mercado.
* Conocer las tecnologías de comunicaciones actuales y emergentes así como saberlas aplicar convenientemente para diseñar y desarrollar soluciones basadas en sistemas y tecnologías de la información.
* Aplicación de las técnicas específicas de ingeniería del software en las diferentes etapas del ciclo de vida de un proyecto.
* Capacidad para aplicar las técnicas específicas de tratamiento, almacenamiento y administración de datos.
* Capacidad para proponer y evaluar diferentes alternativas tecnológicas para resolver un problema concreto.

## Objetivos
La correcta asimilación de todos los aspectos trabajados durante el semestre.  
En esta práctica abordamos un caso real de minería de datos donde tenemos que poner en juego todos los conceptos trabajados.
Hay que trabajar todo el ciclo de vida del proyecto. Desde el objetivo del proyecto hasta la implementación del conocimiento encontrado pasando por la preparación, limpieza de los datos, conocimiento de los datos, generación del modelo, interpretación y evaluación.

## Descripción de la PRA a realizar
La práctica consta de ejercicios en los cuales el estudiante aplicará algunos de los métodos supervisados y no supervisados aprendidos durante el semestre.

## Recursos Básicos
Material docente proporcionado por la UOC. 

## Criterios de valoración

**Ejercicios prácticos** 

Para todas las PRA es necesario documentar en cada apartado del ejercicio práctico que se ha hecho y como se ha hecho.

## Formato y fecha de entrega
El formato de entrega es: **usernameestudiante-PRA2** *.Rmd* y el **output generado** en uno de estos formatos *html/doc/docx/odt/pdf*.

Fecha de entrega: **16/06/2021**  

Se debe entregar la PRA en el buzón de entregas del aula en formato comprimido que incluye los ficheros:
- ejecutable
- output
- el dataset seleccionado o en su defecto indicar la ruta para su descarga en el ejecutable.  

## Nota: Propiedad intelectual 

> A menudo es inevitable, al producir una obra multimedia, hacer uso de recursos creados por terceras personas. Es por lo tanto comprensible hacerlo en el marco de una práctica de los estudios de Informática, Multimedia y Telecomunicación de la UOC, siempre y cuando esto se documente claramente y no suponga plagio en la práctica. 

> Por lo tanto, al presentar una práctica que haga uso de recursos ajenos, se debe presentar junto con ella un documento en que se detallen todos ellos, especificando el nombre de cada recurso, su autor, el lugar donde se obtuvo y su estatus legal: si la obra esta protegida por el copyright o se acoge a alguna otra licencia de uso (Creative Commons, licencia GNU, GPL ...). 
El estudiante deberá asegurarse de que la licencia no impide específicamente su uso en el marco de la práctica. En caso de no encontrar la información correspondiente tendrá que asumir que la obra esta protegida por copyright. 

> Deberéis, además, adjuntar los ficheros originales cuando las obras utilizadas sean digitales, y su código fuente si corresponde.  

******
# Enunciado
******
Como continuación del estudio iniciado en la práctica 1, procedemos en **aplicar modelos analíticos** sobre el juego de datos seleccionado y preparado.  En esta práctica 2 se aconseja de adjuntar los “chunks” de la parte de preparación previa, ejemplo (limpieza, discretización, normalización, PCA/SVD etc.), o en su defecto cargar solo los datos ya preparadados.

De este modo se pide al estudiante que complete los siguientes pasos:

1. Aplicar un modelo **no supervisado** y basado en el concepto de distancia, sobre el juego de datos.

2. Aplicar de nuevo el modelo anterior, pero usando una **métrica distinta** y comparar los resultados.

3. Razonar si tiene sentido aplicar al dataset seleccionado, un método de **generación de reglas de asociaciones**. En caso afirmativo, realizar tal proceso y explicar los resultados. En caso contrario, reformula el problema para que sí lo tenga.

4. Aplicar un modelo de generación de reglas a partir de **árboles de decisión** sin y con opciones de poda y comparar los resultados.

5. Aplicar una mejora con **técnicas de boosting** y comparar el resultado con el anterior.
	
6. Identificar eventuales **limitaciones** del dataset seleccionado y **analizar los riesgos** para el caso de uso.

7. (Punto común para todos los ejercicios) - 
En todos los puntos anteriores se pide al estudiante, además de aplicar los diferentes métodos, de analizar correctamente el problema, **detallar de manera exhaustiva** resaltando el porque y como se ha realizado, incluyendo elementos visuales, explicando los resultados, realizar las comparativas oportunas con sus conclusiones.


******
# Solución
******

## Librerías

En este apartado adjuntamos todas las cargas de librerías necesarias para la resolución de la práctica:
```{r}
library(scales)
library(cluster)
library(dplyr)
library(arules)
library(arulesViz)
library(rpart)
library(rpart.plot)
library(caret)
library(C50)
```

## Resumen del dataset

El dataset elegido para dar respuestas a las preguntas que nos hemos hecho en la práctica uno es el de Breast Cancer Wisconsin (Original) Data Set de Machine Learning Repository [https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Original%29]

Hemos elegido dicho dataset porque nos proporciona toda la información necesaria, a partir de datos como el tamaño de la célula, la forma de la célula...

Es verdad que hay datasets similares a este pero con más atributos, es decir, aquí solo tenemos un campo para el tamaño de la célula, mientras que en otros datasets ese campo podía venir representado por tres atributos, pero este dataset consigue mantener la misma información reduciendo ya la dimensionalidad de los atributos. Por otro lado, los valores numéricos en este conjunto de datos van del 1 al 10, es decir, [1-10], estos valores no son aleatorios sino que un grupo de expertos ha "normalizado" dichos valores para representar la misma información pero de una forma más sencilla.

Finalmente, a continuación se indica los atributos que tiene este dataset:

**Id**
    integer - identificador de la observación.
    
**Thickness**
    integer [1-10] - espesor/grosor del tumor.
    
**Cell_Size**
    integer [1-10] - uniformidad del tamaño celular.
    
**Cell_Shape**
    integer [1-10] - uniformidad de la forma celular.
    
**Adhesion**
    integer [1-10] - adherencia celular.
    
**Epithelial_Cell_Size**
    integer [1-10] - tamaño de una sola célula epitelial.
    
**Bare_Nuclei**
    integer [1-10] - núcleo desnudo.
    
**Bland_Chromatin**
    integer [1-10] - textura del núcleo.
    
**Normal_Nucleoli**
    integer [1-10] - nucléolos normales.
    
**Mitoses**
    integer [1-10] - mitosis.
    
**Class**
    integer - clase si es beningno 2, si es maligno 4.
    
Aunque algun concepto es fácil de entender los demás no, es por ello que vamos a definir cada concepto:

- Thickness: hace referencia al espesor/grosor de la masa mamaria que se estudia, es decir, del tumor.

- Cell_Size: tamaño de las células que se estudian, las células cancerígenas suelen cambiar de tamaño.

- Cell_Shape: forma de las células que se estudian, las células cancerígenas suelen cambiar de forma.

- Adhesion: las células que son cancerígenas tienden a separarse unas de las otras, mientras que en las células normales sucede todo lo contrario.

- Epithelial_Cell_Size: las células que son significativamente grandes suelen ser cancerígenas.

- Bare_Nuclei: nos indica si el núcleo de las células está rodeado por el citoplasma (células normales), en caso contrario es probable que sean células cancerígenas.

- Bland_Chromatin: textura de los núcleos de las células, cuanto más tosco sea más probabiliades de que la célula sea cancerígena.

- Normal_Nucleoli: los nucleólos son pequeñas estructuras que se encuentran en los núcleos, en células benignas suelen ser estructuras pequeñas mientras que en las malignas son más grandes.

- Mitoses: proceso en el cual las células eucariotas se dividen.

Toda esta información se ha obtenido de la siguiente página [https://core.ac.uk/download/pdf/77274625.pdf], cabe destacar que a mayor valor de cada atributo más probable es que la célula sea anormal y dentro de esta anormalidad sea cancerígena.

Por último, tenemos 699 observaciones y 11 atributos en el dataset original, pero se han creado tambien el dataset normalizado con 699 observaciones y 11 atributos, y el discretizado con 699 observaciones y 21 variables.

## Preparación de los datos

En este primer apartado vamos a preparar el conjunto de datos para así poder aplicar modelos analíticos. Cabe destacar que esta limpieza ya se hizo en la práctica uno, por lo que vamos a adjuntar el código necesario para generar el dataset final sin entrar en la explicación del mismo ni en el análisis de los datos.

```{r}
# CARGAMOS
df = read.table(file="./data/breast-cancer-wisconsin.data", fileEncoding="UTF-8", sep=",", na.strings = "NA")

# Cambiamos el nombre de las columnas tal y como se llaman según la página web
colnames(df) = c("Id", "Thickness", "Cell_Size", "Cell_Shape", "Adhesion", "Epithelial_Cell_Size", "Bare_Nuclei", "Bland_Chromatin", "Normal_Nucleoli", "Mitoses", "Class")

# Creamos una copia del dataframe, ya que va a ser la copia sobre la que vamos a realizar las modificaciones
df_copy = df

# IMPUTAMOS
df_copy[df_copy$Bare_Nuclei == "?", "Bare_Nuclei"] = NA
df_copy$Bare_Nuclei = as.integer(df_copy$Bare_Nuclei)

nMediana = median(df_copy$Bare_Nuclei, na.rm = TRUE)
df_copy$Bare_Nuclei[is.na(df_copy$Bare_Nuclei)] = nMediana

# nORMALIZAMOS
df_normalizado = scale(df_copy)

# Generamos el dataset normalizado
write.csv(df_normalizado, file = "./data/breast-cancer-clean-normalized.csv", row.names = FALSE)

# DISCRETIZAMOS

df_discretizado = df_copy

# Dicretización del grosor
df_discretizado["d-Thickness"] = ordered(cut(df_discretizado[["Thickness"]], breaks = c(0,4,7,10), labels = c("Delgado", "Mediano", "Grueso")))

# Dicretización del tamaño
df_discretizado["d-Cell_Size"] = ordered(cut(df_discretizado[["Cell_Size"]], breaks = c(0,4,7,10), labels = c("Pequeño", "Mediano", "Grande")))

# Dicretización del forma
df_discretizado["d-Cell_Shape"] = ordered(cut(df_discretizado[["Cell_Shape"]], breaks = c(0,4,7,10), labels = c("Clase1", "Clase2", "Clase3")))

# Dicretización a la adhesión marginal
df_discretizado["d-Adhesion"] = factor(cut(df_discretizado[["Adhesion"]], breaks = c(0,5,10), labels = c("Alta", "Baja")))

# Dicretización del tamaño de las células epiteliales
df_discretizado["d-Epithelial_Cell_Size"] = ordered(cut(df_discretizado[["Epithelial_Cell_Size"]], breaks = c(0,4,7,10), labels = c("Pequeño", "Mediano", "Grande")))

# Dicretización los núcleos desnudos
df_discretizado["d-Bare_Nuclei"] = factor(cut(df_discretizado[["Bare_Nuclei"]], breaks = c(0,4,7,10), labels = c("Presente", "Presente/Ausente", "Ausente")))

# Dicretización de la textura de la núcleos
df_discretizado["d-Bland_Chromatin"] = factor(cut(df_discretizado[["Bland_Chromatin"]], breaks = c(0,4,7,10), labels = c("Uniforme", "Uniforme/Burda", "Burda")))

# Dicretización de la estructoras de los nucleólis
df_discretizado["d-Normal_Nucleoli"] = ordered(cut(df_discretizado[["Normal_Nucleoli"]], breaks = c(0,4,7,10), labels = c("Pequeño", "Mediano", "Grande")))

# Dicretización de la mitosis
df_discretizado["d-Mitoses"] = ordered(cut(df_discretizado[["Mitoses"]], breaks = c(0,4,7,10), labels = c("Mitosis1", "Mitosis2", "Mitosis3")))

# Creamos una columna respecto a la clase, aunque no es discretización como tal, es más fácil ver si un cáncer es benigno respecto a su nombre que no respecto a su valor.
df_discretizado$`d-Class`[df_discretizado$Class == 2] = "Benigno" 
df_discretizado$`d-Class`[df_discretizado$Class == 4] = "Maligno"
df_discretizado$`d-Class` = as.factor(df_discretizado$`d-Class`)

# Generamos el dataset discretizado
write.csv(df_discretizado, file = "./data/breast-cancer-clean-discretized.csv", row.names = FALSE)

```

## Ejercicio 1

En este primer apartado lo que buscamos es aplicar un algoritmo de aprendizaje no supervisado para saber el cómo se agrupa el cáncer, es decir, aunque en nuestro dataset tenemos etiquetadas para cada observación si es cáncer o no, vamos a ignorar este hecho y se va a aplicar un algoritmo de clustering para saber qué hace de especial a los grupos identificados.

### Generación del modelo

Lo primero de todo es observar el dataframe que vamos a usar para este ejercicio:

```{r}
str(df_copy)
```

En este caso, vemos que tenemos información innecesaria ya que los atributos ID y Class no hacen falta, el primero porque sirve para identificar en exclusiva un punto y en este caso no queremos analizar un punto buscamos el análisis de un grupo, y el segundo nos indica el grupo en sí ya que el dataset original estaba pensado para un problema de clasificación, nosotros queremos descubrir qué observaciones representan el cáncer si necesidad de indicarle al algorítmo cuáles son cáncer y cuáles no.

Debido a lo comentado en el párrafo anterior, eliminamos dichas variables:
```{r}
df_ejer1 = df_copy[,2:10]
str(df_ejer1)
```

Comprobamos que tenemos la información correcta. El siguiente paso es hacer un breve análisis de dichos datos:
```{r}
summary(df_ejer1)
```

Como podemos observar todas las variables están acotadas entre los valores 1 y 10, esto se debe a que un grupo experto "normalizó" el dataset con dichos valores.

El significado de este dataset para una variable en específico sería el siguiente, si estudiamos el tamaño de la célula (Cell_Size), a mayor valor más riesgo de que sea un cáncer maligno.

Si se necestia más información sobre el significado de las variables, análisis de las mismas, análisis del dataset en general, se puede hacer la lectura de la práctica uno.

Una vez que tenemos todo preparado podemos generar el modelo de clustering, pero antes debemos hacer una explicación de los grupos que vamos a indicar al algortimo kmeans.

Por norma general, cuando tenemos un problema de clustering que buscamos resolver a partir de la minería de datos, se realiza un estudio sobre cuántos grupos son los ideales para dicho problema, esto tiene toda la lógica ya que a priori desconocemos los mismos, pero en nuestro caso estamos analizando si los datos sobre las células son sobre células benignas o malignas, es decir, desde un principio ya sabemos que los grupos van a ser dos, o tenemos cáncer o no lo tenemos. Por lo tanto, podríamos crear el modelo directamente con los dos grupos, pero por mera curiosidad, vamos a realizar el estudio de grupos para ver cuántos serían lo ideal (aunque sabemos que solo podemos tener dos).

Vamos a calcular el número de clústers ideales para poder realizar nuestro modelo, cabe destacar que calculamos el valor de la silueta x veces para cada modelo, esto es así porque dicho valor cambia todo el rato, al calcularlo x veces podemos hacer una media y que los “mejores clusters” se mantengan independientemente de las veces que se ejecute:
```{r}
kmeans_silhouette = function(df, minCluster = 2, maxCluster = 10, maxIterations = 10) {
  
  if (minCluster <= maxCluster & minCluster > 1) {
    resultados = rep(0, maxCluster)
    
    for (i in c(minCluster:maxCluster)) {
      resultado = rep(0, maxIterations)
      
      for (j in c(1:maxIterations)) {
        fit = kmeans(df, i)
        y_cluster = fit$cluster
        sk = silhouette(y_cluster, daisy(df))
      
        # Como el valor de la silueta puede cambiar de una iteración a otra, calculamos su valor medio
        resultado[j] = mean(sk[,3])
      }
      resultados[i] = mean(resultado)
    }
    return(resultados)
    
  } else {
    print("ERROR: minCluster debe ser menor que maxCluster y mayor que 1")
  }
}
```

Ejecutamos la función anterior, indicándole que el número de grupos mínimo es 2, el máximo 10 y se va a ejecutar 50 veces para cada modelo:
```{r}
minCluster = 2
maxCluster = 10
maxIterations = 50

mean_silhouette = kmeans_silhouette(df_ejer1, minCluster, maxCluster, maxIterations)

plot(minCluster:maxCluster, mean_silhouette[minCluster:maxCluster],type="o",col="blue",pch=0,xlab="Número de clusters",ylab="Silueta")
```

Como podemos apreciar en el anterior gráfico, el número de clústers ideal es cuando tenemos dos grupos, lo cual vemos que coincide con nuestro problema real, es decir, tenemos el grupo de si el tumor es benigno o no.

Por lo tanto, vamos a crear el modelo con dos grupos:
```{r}
set.seed(0)

modelo_ejer1 = kmeans(df_ejer1, 2)
```

### Análisis y muestra de las medidas del modelo generado

Antes de realizar el análisis de los clústers que nos ha generado el modelo y qué caracteriza a cada grupo, vamos a ver cómo de bueno es el modelo que hemos creado.

Lo primero que vamos a hacer es saber cómo de bueno son los agrupamientos, ésto también nos va a definir el número ideal de clústers para nuestro problema, aunque como venimos diciendo van a ser dos. Sabemos que tenemos dos grupos, pero por mera curiosidad vamos a ver si es verdad que el mejor modelo es cuando tenemos dos clústers.

Para ver cómo de bueno es el modelo podemos hacer dos cosas:

- Fijarnos en la menor suma de los cuadrados de las distancias de los puntos de cada grupo con respecto a su centro (withinss).

- Y obtener la mayor separación posible entre los centros de cada grupo (betweenss).

Por lo tanto, primero observamos la withinss, es decir, ver qué clústers hacen que la mínima suma de los cuadrados de las distancias de los punto de cada grupo con su centro:
```{r}
# Método que nos devuelve el valor medio del tot.withinss para un rango de clústers y de iteraciones sobre el mismo clúster
kmeans_totWithinss = function(df, minCluster = 2, maxCluster = 10, maxIterations = 10) {
  
  if (minCluster <= maxCluster & minCluster > 1) {
    resultados = rep(0, maxCluster)
    
    for (i in c(minCluster:maxCluster))
    {
      resultado = rep(0, maxIterations)
      
      for (j in c(1:maxIterations)) {
        fit = kmeans(df, i)
        resultado[j] = fit$tot.withinss
      }
      
      resultados[i] = mean(resultado)
    }
    return(resultados)
    
  } else {
     print("ERROR: minCluster debe ser menor que maxCluster y mayor que 1")
  }
}
```

Obtenemos las métricas de la withinss para cada modelo de 2 clústers a 10:
```{r}
mean_totWithinss = kmeans_totWithinss(df_ejer1, minCluster, maxCluster, maxIterations)

plot(minCluster:maxCluster,mean_totWithinss[minCluster:maxCluster],type="o",col="blue",pch=0,xlab="Número de clusters",ylab="tot.tot.withinss")
```

Como podemos apreciar, a mayor número de clústers menor es el error, pero esto no es lo correcto porque nos generaría un modelo muy específico, y lo que buscamos generalizar. Para nuestro problema seguimos considerando que lo mejor son dos clústers, ya que buscamos saber si el tumor es benigno o no, aunque a la vista de la anterio gráfica es en este caso cuando obtenemos una mayor separación entre los puntos de cada grupo y su centro.

Continuando con la calidad del modelo, vamos a ver cómo es la betweenss, es decir, cuanto más separados estén los grupos mejor:
```{r}
# Método que nos devuelve el valor medio de la betweenss para un rango de clústers y de iteraciones sobre el mismo clúster
kmeans_betweenss = function(df, minCluster = 2, maxCluster = 10, maxIterations = 10) {
  
  if (minCluster <= maxCluster & minCluster > 1) {
    resultados = rep(0, maxCluster)
    
    for (i in c(minCluster:maxCluster))
    {
      resultado = rep(0, maxIterations)
      
      for (j in c(1:maxIterations)) {
        fit = kmeans(df, i)
        resultado[j] = fit$betweenss
      }
      
      resultados[i] = mean(resultado)
    }
    return(resultados)
    
  } else {
     print("ERROR: minCluster debe ser menor que maxCluster y mayor que 1")
  }
}
```

Una vez definida la función la llamamos:
```{r}
mean_betweenss = kmeans_betweenss(df_ejer1, minCluster, maxCluster, maxIterations)

plot(minCluster:maxCluster,mean_betweenss[minCluster:maxCluster],type="o",col="blue",pch=0,xlab="Número de clusters",ylab="betweenss")
```

Aunque de la gráfica anterior un modelo con 4, 5 o 6 clústeres obtendríamos una mejor betweenss y un modelo más general, el caso que estamos abordando no se vería representado, es decir, no podemos categorizar el cáncer de seis formas distintas, es decir, o tienes cáncer o no.

Debido a esto vamos a analizar para el modelo creado, es decir, un modelo con dos clústers, cómo es la silueta, cómo es su withinss, y su betweenss.

Respecto a la silueta:
```{r}
set.seed(0)
cat("La silueta del modelo con 2 grupos es: ", kmeans_silhouette(df_ejer1, 2, 2, 1)[2])
```

La silueta nos indica cómo de similar es un elemento con los de su propio grupo y cómo de diferente respecto a los demás, su valor va entre -1 y 1, cuanto más próximo esté el valor a uno mejor es el modelo, ya que esto significa que un elemento está bien emparejado con los de su gurpo (es muy similar) y a su vez es muy diferente respecto a los demás grupos.

En nuestro caso, obtenemos un valor de silueta de casi el 0.60, por lo que el modelo está bastante bien aunque podría estar mejor, pero como primera aproximación el modelo se comporta bien.

Lo siguiente que vamos a hacer es ver si withinss:
```{r}
cat("El withinss del modelo con 2 grupos es: ", modelo_ejer1$tot.withinss)
```

En este caso vemos que obtenemos una withinss muy elevada, esto significa que la suma de las distancias de cada punto respecto al centro de su grupo es mayor, lógicamente como ya hemos visto antes, a mayor número de clústers menor es la withinss, pero en nuestro caso tenemos que tener dos clústers sí o sí, por lo tanto aunque tenemos una elevada withinss esto se debe al número bajo de clústers no porque el modelo sea malo en sí, como vimos la siuelta es elevada por lo que el modelo es bueno.

La última medida a analizar es la betweenss:
```{r}
cat("La betweenss del modelo con 2 grupos es: ", modelo_ejer1$betweenss)
```

Respecto a la betweenss no tenemos un valor suficientemente alto, como ya vimos esto también es lógico, a mayor número de clústers más centros dando lugar a una mayor betweenss, pero al igual que antes estamos "condenados" a dos grupos.

En resumen, aunque la métricas withinss y betweens no son las mejores, respecto a cambiar el número de clústers no podemos hacer nada, ya que el tumor es benigno o maligno, solo hay dos clases. Sin embargo, nos podemos fiar de la silueta del modelo cuando tenemos dos clústers, y hemos visto que este valor es elevado, por lo que tenemos un buen modelo para analizar el cómo se agrupan los tumores y ver si hay cáncer o no.

### Conclusiones

En este apartado vamos a realizar el análisis del modelo, es decir, cómo agrupa los tumores según su características principales: el tamaño de la célula, la forma, el grosor del tumor...

Lo primero que vamos a analizar es el grosor del tumor, el ver cómo el tamaño de la célula, la adhesión (las células que son cancerígenas tienden a separarse unas de las otras, mientras que en las células normales sucede todo lo contrario), y si presenta núcleos desnudos (si el núcleo de las células está rodeado por el citoplasma (células normales), en caso contrario es probable que sean células cancerígenas).

Por lo tanto, mostramos el grosdor del tumor y el tamaño de la célula y vemos cómmo lo agrupa el modelo:
```{r}
plot(df_ejer1[,c("Thickness", "Cell_Size")], col=modelo_ejer1$cluster, main="Grosor de la célula respecto al tamaño")
```

Lo primero de todo es identificar los grupos que nos genera, podemos ver claramente que los grupos vienen determinados por el tamaño de la célula y no tanto por el grosor, es decir, a mayor tamaño de la célula más riesgo de que el tumor sea maligno (grupo negro) y menor tamaño de que sea benigno (grupo rojo).

Algo curioso del anterior gráfico es que podemos tenemos un grosor muy elevado, pero que la célula sea muy pequeña y esto no significa para nada que tengamos cáncer, es decir, es muy influyente el cómo es el tamaño de la célula para dictaminar si ésta es cancerígena o no.

El siguiente análisis es comprobar el cómo influye el grosor a la adhesión de las células:
```{r}
plot(df_ejer1[,c("Thickness", "Adhesion")], col=modelo_ejer1$cluster, main="Grosor de la célula respecto a la adhesión de las mismas")
```

En este caso vemos que ya no están tan bien definidos los clústers, es decir, hay casos especiales. Por norma general, un mayor grosor lleva implícito una peor adhesión, es decir, cuánto más gruesa sea la célula más probabilidades hay de que sea cancerígena y tienda a serparase unas de otras más fácilmente. Sin embargo, a menor grosor más probable que la célula sea benigna y no se separe las unas de las otras.

Por último respecsto al grosor, vamos a comporar si Bare_Nuclei afecta, es decir, si las células que están rodeadas de citoplasma y las que no dependen del grosor o no:
```{r}
plot(df_ejer1[,c("Thickness", "Bare_Nuclei")], col=modelo_ejer1$cluster, main="Grosor de la célula respecto a las células con citoplasma")
```

En este caso vemos que el grosor de la célula también influye, es decir, cuanto mayor sea el grosor más probabilidades de que la célula no tenga citoplasma o éste esté presente en bajas cantidades, esto significaría cáncer. En caso contrario, estaríamos ante un tumor benigno.

El siguiente paso es analizar el tamaño de la célula, el ver cómo influye ésta respecto a la forma de la misma, al tamaño de las células epiteliales, y a la textura de los núcleos. Todo esto nos sirve para determinar en qué casos tenemos un cáncer benigno o maligno.

Por lo tanto, analizamos el tamaño de la célula respecto a la forma de la misma:
```{r}
plot(df_ejer1[,c("Cell_Size", "Cell_Shape")], col=modelo_ejer1$cluster, main="Tamaño de la célula respecto a la forma")
```

Como podemos observar, a mayor tamaño de célula mayor es su forma y esto lleva implícito un mayor riesgo de cáncer. Cabe destacar, que los tumores beningnos tienen un tamaño y una forma pequeña, es decir, el normal es moverse entre un tamaño de 1 y 3, a nada que nos movamos de dicho tamaño el riesgo aumenta muchísmo.

El siguiente análisis es el tamaño respecto al tamaño de las célula epiteliales:
```{r}
plot(df_ejer1[,c("Cell_Size", "Epithelial_Cell_Size")], col=modelo_ejer1$cluster, main="Tamaño de la célula respecto al tamaño de las células epiteliales")
```

En este caso, podemos apreciar que tener un tamaño de célula epitelial muy elevado no significa cáncer, pero a medida que aumenta el tamaño de las células, al igual que en el caso anterior, sí que aumenta el riesgo de que el tumor seas maligno.

Finalmente, analizamos el tamaño respecto a la textura de los núcleos:
```{r}
plot(df_ejer1[,c("Cell_Size", "Bland_Chromatin")], col=modelo_ejer1$cluster, main="Tamaño de la célula respecto a la textura del núcleo")
```

En este caso, vemos que si tenemos una textura muy tosca, es decir, un valor elevado de la variable Bland_Chromatin, podemos estar hablando de un caso de cáncer, es decir, esta variable es significativa para dictaminar si el tumor es benigno o no. También, como hemos ido estudiando, al aumentar el tamaño de la célula esto sigue suponiendo un mayor riesgo de cáncer.

El siguiente análisis que vamos a hacer es relativo al tamaño epitelial de las células, vamos a comprobar si dicho tamaño es afectado por si hay nucleólos pequeños o grandes y el proceso de mitosis.

Por lo tanto, mostramos el tamaño epitelial frente a la nuclólos:
```{r}
plot(df_ejer1[,c("Epithelial_Cell_Size", "Normal_Nucleoli")], col=modelo_ejer1$cluster, main="Tamaño de las células epiteliales respecto al tamaño de los nucleólos")
```

Podemos concluir que no por tener una estructura de nucleólos grande significa que vaya a tener cáncer, sin embargo, a medida que aumenta el tamaño de las células epiteliales, y la estructura de los nucleólos aumenta, vemos que sí que hay una ligera relación, esto supone un mayor riesgo de que el tumor se maligno.

Analizamos el tamaño de las células epiteliales frente a la mitosis:
```{r}
plot(df_ejer1[,c("Epithelial_Cell_Size", "Mitoses")], col=modelo_ejer1$cluster, main="Tamaño de las células epiteliales respecto a la mitosis")
```

En este caso vemos que no hay relación, es decir, no por tener una mejor mitosis tenemos mayor riesgo, sino que el riesgo viene determinado por el tamaño de la célula epitelial.

El siguiente elemento a estudiar va a ser si el núcleo de las células está rodeado de citoplasma (signnifica un menor riesgo de cáncer) o no (mayor riesgo), respecto a la forma de la célula, la capacidad de separarse de otras células y si la textura del núcleo influye.

Por lo tanto, analizamos primero si el citoplasma se ve afectado por la forma de la célula:
```{r}
plot(df_ejer1[,c("Bare_Nuclei", "Cell_Shape")], col=modelo_ejer1$cluster, main="La presencia de citoplasma respecto a la forma de la célula")
```

Podemos apreciar que hay una relación, cuando aumenta la forma de la célula lo hace también Bare_Nuclei (menos presencia de citoplasma), esto supone un mayor riesgo de cáncer. De primeras podríamos intuir que al aumentar la forma hay más espacio para más citoplasma, pero vemos que es todo lo contrario, ya que al aumentar la forma la célula va tomando las característias de una célula cancerígena y esto suele suponer reducir el citoplasma de la misma.

Analizamos la capacidad que tiene la célula de separarse:
```{r}
plot(df_ejer1[,c("Bare_Nuclei", "Adhesion")], col=modelo_ejer1$cluster, main="La presencia de citoplasma respecto a la adhesión")
```

En este caso, vemos que también está relacionado, al reducirse el citoplasma de las células (aumenta Bare_Nuclei) éstas tienden a separase más, por lo tanto, incrementa el riesgo de padecer cáncer.

Otro aspecto a analizar, es si al reducir el citoplasma se ve afectado la textura del núcleo:
```{r}
plot(df_ejer1[,c("Bare_Nuclei", "Bland_Chromatin")], col=modelo_ejer1$cluster, main="La presencia de citoplasma respecto a la textura del núcleo")
```

En este caso vemos que no hay una relación tan fuerte, pero es verdad que cuando aumenta la textura del núcleo de por sí ya tenemos un mayor riesgo de cáncer, lo mismo sucede con el citoplasma, cuando se reduce éste aumenta el riesgo de que el tumor sea maligno.

Para terminar con el análisis de este ejercicio, vamos a analizar si el tamaño de las estructuras de los nucleólos se ve afectado o no por el tamaño de la célula y la mitosis, y si esto significa un mayor riesgo de cáncer o no.

Por lo tanto, analizamos las estructuras de los nucleólos frente al tamaño de las células:
```{r}
plot(df_ejer1[,c("Normal_Nucleoli", "Cell_Size")], col=modelo_ejer1$cluster, main="Tamaño de los nucleólos respecto al tamaño de la célula")
```

Apenas podemos apreciar una relación, vemos que el tamaño de la célula de por sí es muy influyente, es decir, el tamaño de los nucleólos tiene que ser muy elevado con un valor de 9 o 10 para que sea significativo el aumento en esta variable, ya que para valores más pequeños presentamos prácticamente la misma relación respecto al tamaño de la célula.

El otro aspecto a analizar es si la estructura de los nucleólos se ve afectado por el proceso de mitosis:
```{r}
plot(df_ejer1[,c("Normal_Nucleoli", "Mitoses")], col=modelo_ejer1$cluster, main="Tamaño de los nucleólos respecto a la mitosis")
```

En este caso, aunque en la primera parte de la práctica veíamos una ligera correlación, al analizar los grupos vemos que no hay relación, es decir, el cáncer no se ve afectado por la mitosis, sin embargo, sí que presentamos un mayor riesgo cuando el tamaño de los nucleólos es mayor.

#### Resumen

El primer análisis que hemos hecho ha sido respecto al grosor de la célula, y hemos visto que en cuanto al tamaño de la célula tener un grosor mayor no implicaba un tamaño mayor y por lo tanto no podíamos garantizar que fuera cáncer, es decir, influía más en el cáncer el tamaño de la célula que el grosor en sí mismo. También hemos analizado el grosor respecto a la capacidad de separarse la células, y hemos visto  que sí que hay relación, a mayor grosor más se separan las células unas de otras y esto supone cáncer. Finalmente, se ha estudiado el cómo afectaba el grosor a si las células tenían citoplasma o no, y hemos visto que también está relacionado, es decir, a mayor grosor las células tienen menos citoplasma o no tienen y esto supone que el tumor sea maligno.

El segundo análisis ha sido respecto al tamaño de la célula, hemos estudiado si la forma de la misma se veía afectada por el tamaño y hemos visto que sí, a mayor tamaño mayor forma y mayor riesgo de cáncer. Después hemos comprobado si el tamaño de las células epiteliales se veían afectadas, y hemos visto que no del todo, es verdad que a mayor tamaño mayor riesgo de cáncer, pero si el tamaño de las células epiteliales es elevado y tamaño de las células "normales" es pequeño podemos garantizar que es un tumor benigno. Finalmente, hemos comprobado que la textura del núcleo se ve afectada por el tamaño, ya que el núcleo es más tosco y esto supone un mayor riesgo de un tumor maligno.

El siguente análisis ha sido el tamaño de las células epiteliales, hemos estudiado si el tamaño de los nucleólos estaba relacionado, y hemos visto que sí pero de una forma muy ligera, es decir, no podíamos garantizar al 100% de que hubiera riesgo de cáncer si aumentaba el tamaño de la estructura de los nucleólos. Por otro lado, hemos analaizado el proceso de mitosis según el tamaño de las células epiteliales, y en este caso hemos visto que no había relación, por tanto no podíamos garantizar que al tener un mayor o menor proceso de mitosis hubiera un peligro en si el tumor era benigno o no.

El cuarto análisis ha sido el citoplasma presente en las células, hemos comprobado si la forma de la célula afectaba al citoplasma y hemos visto que sí, que cuando aumenta la forma de la célula, ésta va adquiriendo las características de las células cancerígenas, y por tanto reduce el citoplasma de las misma. También hemos estudiado la capacidad de separación de estas células, y también están relacionadas, es decir, cuando el citoplasma es menor la célula tiende a separarse más unas de otras, lo que origina el cáncer. Finalemnte, hemos analizado si afectaba la textura del núcleo, y hemos comprobado que no hay una relación muy fuerte entre a menor citoplasma que los núcleos sean más toscos.

El último análisis ha sido el tamaño de los nucleólos, hemos comprobado si se veía afectado por el tamaño de las células, y hemos apreciado que apenas hay una relación, es decir, un mayor tamaño de la célula implica ya de por sí un mayor riesgo de cáncer, sin embargo, para que el nucleólo sea significativo éste tiene que tener un tamaño grande respecto al tamaño de la célula. También hemos estudiado si se veía afectado por la mitosis, hemos comprobado que no, no había relación.

## Ejercicio 2

## Ejercicio 3

En este caso se nos pide identificar si tiene sentido un modelo de generación de reglas de asociación y de ser casi afirmativo crear el proceso y explicar los resultados.

### Identificación del problema

En nuestro caso sí que tiene sentido aplicar un método de generación de reglas asociadas. Recapitulando, tenemos un dataset sobre el cáncer de mamá, en él hay variables como el tamaño de las células, su forma, si hay citoplasma o no dentro de la célula... Todas estas variables nos permiten saber si el tumor que estamos analizando es benigno o maligno, en otras palabras, si es cáncer o no.

Como vemos, en el dataset tenemos la variable objetivo que es la clase de tumor, cuyo valor es 2 si es benigno o 4 maligno.

Si aplicamos un método que nos permita obtener las reglas de asociación podríamos ver qué condiciones son las más frecuentes para dictaminar si un cáncer es benigno o no, sin entrar a predecir, es decir, con la información que tenemos ver qué variables y qué valores para dichas variables influyen en el cáncer.

Para ponernos en situación podríamos tener una regla del tipo:

- Tamaño de la célula es grande => Cáncer maligno.

La anterior regla la podemos interpretar como, si el tamaño de la célula es grande, ésto suele conllevar que el tumor es maligno. Cabe mencionar que una regla no tiene porque cumplirse siempre, es decir, nos da una idea de lo que puede pasar porque hay más probabilidades, pero esto no significa que tenga que suceder siempre.

Como vemos, nuestro dataset sí que tiene sentido aplicarle reglas de asociación, pero ya no solo para dictaminar si es cáncer o no, sino que también nos puede hacer una idea de cómo se relacionan las variables entre sí, por ejemplo:

- Tamaño de la célula es grande => la forma de la célula es grande.

En este caso nos aporta información de cómo se relacionan las variables entre sí, sin tener que estar relacionadas directamente con saber si es cáncer o no.

Una vez aclarado el sentido de las reglas de asociación, vamos a crear un modelo para obtener aquellas reglas más representativas, cabe destacar que la realización de este ejercicio ha estado basado en un artículo de internet (https://danielredondo.com/posts/20200405_reglas_asociacion/), se ha usado la guía de este artíuclo para resolver el ejercicio.

### Conjunto de datos

Lo primero de todo es que al usar el algoritmo a priori, todas las variables tienen que ser categóricas, en otras palabras factores. Para ello, en la primera parte de la práctica se creó un dataset discretizado, dicho dataset contenía tanto las variables del dataset original más las discretizadas, es por ello que solo nos vamos a quedar con las discretizadas:
```{r}
df_ejer3 = df_discretizado[, c(12:21)]

str(df_ejer3)
```

Puesto que tanto en la práctica uno, como en el comienzo de esta práctica hemos visto que la variable Mitoses no proporciona mucha información sobre el tipo de cáncer, vamos a eliminarla para obtener reglas que realmente sean interesantes:
```{r}
df_ejer3 = df_ejer3[, -c(9)]

str(df_ejer3)
```

Una vez que ya tenemos la información deseada, convertimos el datset al conjunto de tipo transacciones para poder aplicar el método a priori:
```{r}
transacciones_ejer3 = as(df_ejer3, "transactions")
```

Para hacernos una primera idea de qué reglas tiene un soporte (el soporte indica cuantas veces se ha encontrado dicha regla en el dataset) mayor o igual al 50%, mostramos el siguiente gráfico:
```{r}
itemFrequencyPlot(transacciones_ejer3, support = 0.5)
```

Como podemos apreciar, los anteriores items son los más frecuentes en el dataset, es decir, que la adhesión sea alta, que el tamaño de la célula sea pequeño, que la célula sea delgada...

Algo a mencionar en el anterior gráfico es que suele ser frecuente que la clase de tumor sea benigno, esto puedo hacernos una idea de que a lo mejor el dataset original no está del todo balanceado, o que por norma general los tumores son benignos.

### Creación del modelo a priori

Antes de crear el modelo, tenemos que definir dos parámetros fundamentales, uno es el soporte y otro la confianza:

- El soporte nos indica cuantas veces se ha encontrado la regla (lsh => rhs) en el dataset. A mayor soporte más aparece la regla por lo que más evidente es, es decir, mejor.

- La confianza indica la probabilidad de que rhs dependa de lsh. A mayor confianza más relación hay entre lsh y rsh, es decir, mejor.

Una vez aclarado esto vamos a hacer uso del método apriori para obtener las reglas, como no se indica qué parámetros hacer uso vamos a usar para el soporte un 0.1 y para la confianza un 0.8. Se han elegido estos parámetros ya que son los que usa por defecto el método apriori:
```{r}
reglas = apriori(transacciones_ejer3, parameter = list(support = 0.1, confidence = 0.8))
```

Lo siguiente que vamos a hacer es ordenar la reglas según la confianza, para posteriormente comprobar si hay reglas redundates o no:
```{r}
reglas_ordenadas = sort(reglas, by="confidence")
```

Eliminamos las reglas redundates, es decir, reglas que están incluidas unas dentro de otras:
```{r}
# Comprobamos para cada regla qué elementos son subconjutos
conjunto = is.subset(reglas_ordenadas, reglas_ordenadas)

# Obtenemos las reglas redundantes, es decir, aquellas que están contenidas en 2 o más reglas
reglas_redundates = colSums(conjunto, na.rm = TRUE) >= 2

# Eliminamos las reglas redundantes
reglas_no_redundantes = reglas_ordenadas[!reglas_redundates]
```

Ahora eliminamos las reglas con una confianza igual a 1, este tipo de reglas pueden no proporcionarnos información relevante, ya que son obviedades:
```{r}
reglas_seleccionadas = subset(reglas_no_redundantes, subset = confidence < 1)
```

Otro atributo a destacar es lift, éste nos indica cuanta aleatoriedad hay en cada una de las reglas, un lift de 1 o menor significa que hay aleatoriedad, ésto no nos interesa ya que buscamos reglas que no sean aleatorias, es decir, que realmente estén relacionadas y sean influyentes. Debido a esto, filtramos de nuevo las reglas seleccionadas para un lift mayor que 1:
```{r}
reglas_seleccionadas = subset(reglas_seleccionadas, subset = lift > 1)
```

### Análisis de las reglas

Una vez que ya tenemos las reglas seleccionadas las vamos a analizar las reglas cuando rhs sea la clase del tumor:
```{r}
reglas_clase_tumor = subset(reglas_seleccionadas, subset = rhs %pin% "d-Class")

inspect(head(reglas_clase_tumor))
```

Una vez que hemos usado el algoritmo apriori con un soporte de 0.1 y una confianza del 0.8, y su respectivo filtrado para eliminar aquellas reglas redundates y triviales, llegamos a que los factores más determinantes para dictaminar si un tumor es maligno son los siguientes:

- La forma de la célula, tener una forma grande, es decir, de Clase3 suele implicar que el tumor es maligno, con un nivel de confianza del 98%, es decir, que sí que hay una relación entre ambas variables.

- El tamaño de la célula, tanto si es Grande como si es Mediano significa que prácticamente el tumor es maligno. Si el tamaño es grande obtenemos un nivel de confianza del 98%, mientras que si es mediano del 96%, esto nos lleva a la conclusión de que es más determinante un tamaño grande de célula para un tumor maligno.

- Otro aspecto es la cantidad de citoplasma que hay en la célula, y vemos que si es Ausente, es decir, no hay o apenas hay citplasma, suele indicar que tenemos cáncer.

- El grosor de la célula también está implicito en si el tumor es maligno o no, ya que si el grosor es Grueso es más probable que tengamos un cáncer.

- Finalmente, otro factor determinante es saber si la estructura de los nucleólos es grande tiene a indicarnos que el tumor es maligno.

Otro análisis que podemos hacer es ver qué variables están relacionadas entre sí, independientemente del la clase del tumor:
```{r}
inspect(reglas_seleccionadas)
```

Como vemos de la anterior ejecución, un grosor delgado de la célula lleva implícito que el tamaño de las células epiteliales es pequeño, el tamaño de las células también, la forma de la misma suele ser de Clase1 (forma normal), la estructura de los nucleólos es pequeño, el núcleo tiene una estructura uniforme y sí que presenta citoplasma las células.

Todo lo descrito anteriomente nos indica que el tumor es benigno, es decir, sabemos perfectamente cuando el tumor es benigno o maligno.

### Conclusiones

Las conclusiones obtenidas son las siguientes:

- Cuando hablamos de un tumor maligno, presente características como una forma de la célula mayor, un tamaño de la misma mayor, no hay o apenas hay citoplasma en la célula, suelen tener un grosor mayor, y los nucleólos suelen ser grandes.

- Sin embargo si el tumor es beningno, la forma suele ser menor, el tamaño de la misma también, presentan citoplasma en las células, suelen tener un grosor delgado, el núcleo tiene estructura uniforme y los nucleólos son pequeños.

## Ejercicio 4

En este ejercicio se plantea la problemática de clasificar el tumor a partir de árboles de decisión, pero en este caso no vamos a tener solo un modelo, sino que dos, uno va a ser sin poda y otro podado, es decir, en el primero no vamos a acotar el árbol mientras que en el segundo sí.

Por lo tanto, el objetivo de este ejercicio es analizar y comparar qué modelo funciona mejor, si el árbol de decisión sin podar o podado.

### Preparación de los datos

Antes de crear los modelos tenemos que preparar los datos, es decir, ver qué variables vamos a introducir y generar tanto los datos de entrenamiento como de test.

Para que sea más fácil de interpretar el árbol vamos a hacer uso del dataframe con las variables discretizadas:
```{r}
df_ejer4 = df_discretizado[, c(12:21)]

str(df_ejer4)
```

Tal y como hemos visto en anteriores ejercicio, la variable Mitoses no proporciona información determinante para clasificar si un tumor es benigno o no, por lo que vamos a eliminarla:
```{r}
df_ejer4 = df_ejer4[, -c(9)]

str(df_ejer4)
```

Una vez que tenemos el dataset, pasasmos a dividir el mismo en dos conjuntos, uno para el entrenamiento y otro para el test. Caba destacar que para el entrenamiento vamos a usar 2/3 de los datos, y para el test 1/3:
```{r}
set.seed(0)

# Dividimos los datos para train y test
separacion = 3

indexes = sample(1:nrow(df_ejer4), size=floor(((separacion-1)/separacion)*nrow(df_ejer4)))
df_ejer4_train = df_ejer4[indexes,]
df_ejer4_test = df_ejer4[-indexes,]
```

Una vez que se nos ha generado los conjuntos comprobamos su información:
```{r}
summary(df_ejer4_train)
summary(df_ejer4_test)
```

De la anterior ejecución vemos que no hay mucha diferencia en cuanto a los conjuntos de datos en sí, es decir, dejando de lado que en test hay menos datos que en train, vemos que la prporción para cada variable se mantiene más o menos, es decir, no sesgamos la información.

### Creación de los modelos

Una vez que ya tenemos el dataset tanto para el entrenamiento como para el test, podemos crear los modelos. Recordamos que va a haber dos: un modelo que no se va a podar y otro en el que sí.

Creación del árbol de decisión sin opción de poda:
```{r}
modelo_ejer4_sin_podar = rpart(formula = `d-Class` ~ ., data = df_ejer4_train, method = "class")
```

El segundo modelo se basa en la poda, es por ello que hemos usado la librería rpart, hay un parámetro denominado "cp" que nos permite optimizar la poda para el árbol.

Como a priori no sabes cuál es el subárbol óptimo, vamos a generar el árbol más detallado y a partir de éste haremos la poda. Para ello, vamos a crear un modelo base cuyo cp va a ser igual a 0, ya que a medida que aumenta este cp el error va a ser mayor, al tener un cp igual a cero vamos a tener un modelo sobreajustado, pero de esta forma luego podemos analizar cuál es el valor óptimo para hacer la poda.

Generamos el modelo base:
```{r}
modelo_ejer4_podado = rpart(formula = `d-Class` ~ ., 
                            data = df_ejer4_train, 
                            method = "class", 
                            control = rpart.control(cp = 0))
```

Una vez generado el modelo, comprobamos cómo evoluciona el valor cp respecto al error:
```{r}
plotcp(modelo_ejer4_podado)
```

En este caso como es lógico cuanto más proóximo a cero sea el valor cp, menos error vamos a tener porque el modelo está sobreajustado, pero nosotros no queremos un modelo sobreajustado sino que el modelo tiene que ser capaz de generalizar. Por lo tanto, de la anterior gráfica vemos que valor ideal para el cp es 0.31, ya que es aquí donde empieza el "codo" de la gráfica.

Creamos el modelo con el cp para este caso:
```{r}
modelo_ejer4_podado = prune(modelo_ejer4_podado, cp = 0.31)
```

Una vez que hemos creado los modelos, vamos a ver qué reglas tenemos junto con su análisis visual.

### Análisis de reglas e interpretación visual

Lo primero de todo es analizar las reglas que nos ha generado los dos modelos que tenemos, como es lógico en el modelo que no está podado vamos a tener más reglas que en el modelo podado.

Respecto al modelo no podado obtenemos las siguientes reglas:
```{r}
rpart.rules(modelo_ejer4_sin_podar)
```

Respecto a este modelo obtenemos las siguientes reglas:

- Cuando la forma de la célula es clase1 (célula normal), el citoplasma que hay dentro de ella está presente o hay una pequeña cantidad, y el tamaño de la célula epitelial es pequeño, este es el único caso en el que el tumor es benigno. Por lo que esta información es muy valiosa, ya que sabemos perfectamente lo que define a un tumor "bueno" con un 2%.

- Cuando la forma de la célula es clase1, el citoplasma está presente o hay poca cantidad, y el tamaño de la célula epitelial es mediano o grande, estamos en un caso de tumor maligno, es decir, de cáncer con un 64%.

- Si la forma de la célula es clase1, y no hay citoplasma dentro de ella, estamos en una situación de cáncer con un 89%.

- Y si la forma de la célula es de clase2, o clase3, ambas son tamaños grandes respecto a lo que suele ser una célula, estamos directamente en un caso de cáncer con un 93%.

Estas reglas las podemos representar también de forma visual:
```{r}
rpart.plot(modelo_ejer4_sin_podar,
           box.palette = c( "green","red"),
           main = "Cáncer de mama")
```

Cabe destacar que el único caso en el que una hoja presenta un tumor benigno, éste se ve reflejado en el 63% de los datos del dataset de entramiento. Sin embargo, cuando el tumor es maligno, representa el 37% de los casos del dataset de entrenamiento.

Con el análisis anterior podemos ver que hay más casos de que el cáncer sea benigno a que sea maligno.

Por último, nos falta analizar las reglas del modelo que hemos podado:
```{r}
rpart.rules(modelo_ejer4_podado)
```
En este caso, vemos que tenemos un modelo muy general respecto al anterior, esto se debe a que en el primer modelo sin podar, de por sí ya nos generaba un árbol muy pequeño, entonces al hacer la poda es aún más pequeño y por lo tanto más general. Las dos reglas que nos genera son:

- Si la forma de la célula es del tipo clase1, estamos en un caso en el que el tumor es benigno con un 11%.

- Si la forma de la célula es del tipo clase2 o clase3, en este caso es tumor es maligno con un 0.93%.

Finalmente, vamos a hacer la representación visual de las reglas generadas por este modelo:
```{r}
rpart.plot(modelo_ejer4_podado,
           box.palette = c( "green","red"),
           main = "Cáncer de mama árbol podado")
```

En este caso vamos que solo la forma de la célula nos va a dictaminar el tipo de tumor que estamos analizando, como podemos apreciar es un modelo muy general, en el que el 71% de los datos del entramiento representan a casos benignos, mientras que el 29% son tumores malignos.

### Evaluación de los modelos

En este apartado vamos a evaluar cada unos de los modelos según ciertos parámetros, y su vez vamos a ir haciendo comparaciones entre ambos para ver cuáles son los resultados, y qué ventajas o desventajas presenta uno respecto al otro.

El primer parámetro que vamos a analizar es la comprensibilidad, es decir, qué modelo es más fácil de interpretar. Tal y como hemos visto en el apartado anterior, ambos modelos son muy fáciles de interpretar ya que no nos generan demasiadas reglas, es decir, para nuestro conjunto de datos los árboles obtenidos son muy sencillos.

Es verdad, que por norma general el árbol podado es más fácil de interpretar que un árbol no podado, ya que cuando podamos lo que buscamos es crear un subárbol, y que éste sea capaz de generalizar muy bien pero teniendo en cuenta menos reglas. En nuestro caso, esto se sigue cumpliendo, es decir, el subárbol creado es más fácil de interpretar porque solo tiene dos reglas, sin embargo, el modelo no podado tiene cuatro reglas.

En resumen, repecto a la compresnibilidad ambos modelos son idóneos, ya que el dataset que tenemos genera árboles sencillos, no se aprecia una gran diferencia entre un modelo u otro en este aspecto.

Otro punto a analizar es ver la capacidad predictiva de cada modelo, para ello lo idóneo es calcular la matriz de confusión, ésta nos permite saber si el valor que se ha predicho coincide con el valor real o no.

Para ello, creamos la matriz de confusión para el modelo sin podar, pero antes hay que calcular las predicciones:
```{r}
predicciones_modelo_sin_podar = predict(modelo_ejer4_sin_podar, newdata = df_ejer4_test, type = "class")

confusionMatrix(predicciones_modelo_sin_podar, df_ejer4_test$`d-Class`, positive="Maligno")
```

Como podemos apreciar de la anterior ejecución, el modelo del árbol sin podar es muy bueno. Tiene una precisión del 95% para nuevas observaciones, es decir, que el 95% de los datos nuevos ha sido capaz de clasificarlos correctamente.

Este método nos devuelve métricas interesantes, como por ejemplo:

- La sensibilidad no es más que la tasa de verdaderos positivos, es decir, la proporción de casos positivos que el modelo ha sido capaz de clasificar, en nuestro caso, un 87% de los casos cuando el tumor es maligno lo sabe clasificar.

- La especificidad es la tasa de verdaderos negativos, la proporción de casos negativos que el modelo ha sido capaz de clasificar, en nuestro caso, un 99% de los casos en los que el tumor es benigno los ha sabido clasificar correctamente.

A la vista de los datos anteriores, vemos que el modelo en líneas generales es muy bueno para nuevos datos, y suele tener una tasa de éxito mayor cuando el tumor es benigno a cuando es maligno.

Realizamos lo mismo para el modelo podado, para ver así qué modelo se comporta mejor:
```{r}
predicciones_modelo_podado = predict(modelo_ejer4_podado, newdata = df_ejer4_test, type = "class")

confusionMatrix(predicciones_modelo_podado, df_ejer4_test$`d-Class`, positive="Maligno")
```

En este caso conseguimos una menor precisión, antes teníamos un accuracy del 95% y ahora del 89%, a priori sobre un modelo podado tendríamos que tener un mejor modelo en sí, ya que sería capaz de generalizar perfectamente, pero nuestro dataset es simple y el modelo sin podar se ajusta mejor que este modelo.

Aunque el árbol de decisión podado ofrezca una menor precisión, aún así ésta sigue siendo muy elevada, por lo que el modelo sigue siendo muy bueno.

Por otro lado, vemos que la sensibilidad de este modelo es peor, es decir, no clasifica del todo bien los positivos, en nuestro caso solo el 68% es clasificado correctamente.

Respecto a la especificidad, este modelo se comporta mejor que el anterior, clasifica mejor los casos negativos, ya que conseguimos que el 100% de los tumores benignos sean clasificados correctamente.

En resumen, este modelo en líneas generales se comporta peor que el anterior, pero es verdad que a la hora de clasificar los tumores benignos éste nos da una mayor fiabilidad.

Finalmente, para terminar con la evaluación de los modelos, vamos a ver el error que se genera en cada uno de los niveles en cada modelo. Para ello, mostramos el error generado cuando el modelo no es podado, es decir, el número incorrecto de clasificaciones respecto al número de observaciones:
```{r}
rpart.plot(modelo_ejer4_sin_podar,
           box.palette = c( "green","red"),
           main = "Cáncer de mama",
           extra = 3)
```

Del anterior gráfico, podemos ver que el mayor error se comete en el nodo hoja cuando el tamaño epitelial de la célula no es pequeño, ya que nos está generando un error en dicha hoja del 36%, en el resto de los casos se clasifca mal un pequeño número de observaciones respecto a las observaciones del nodo.

En resumen, apreciamos que el modelo anterior es bastante bueno ya que apenas se produce error a la hora de clasificar mal las observaciones.

Realizamos lo mismo pero para el árbol podado:
```{r}
rpart.plot(modelo_ejer4_podado,
           box.palette = c( "green","red"),
           main = "Cáncer de mama árbol podado",
           extra = 3)
```

En este árbol obtenemos el mismo error que en el modelo anterior, por lo que podemos seguir asumiendo que el modelo es bastante bueno, aunque como vimos el árbol no podado tiene una mejor precisión que el árbol podado.

### Conclusiones

Este ejercicio nos ha permitido saber el cómo de bueno es capaz de clasificar un modelo cuando tenemos un problema de aprendizaje supervisado.

Para ello hemos creado dos modelos, un árbol sin podar y otro árbol podado, este último se ha establecido el corte según el atributo cp idóneo que se ha calculado, en nuestro caso dicho valor fue de 0.31.

Cabe destacar que las ventajas que presenta un modelo podado frente a otro sin podar es que tiene una mayor comprensibilidad, es decir, es más fácil de interpretar, esto tiene todo el sentido del mundo, ya que un árbol podado no es más que un subárbol del árbol "completo". Además, un árbol podado es capaz de generalizar mejor que si no es podado, esto se debe a que al tener menos reglas el modelo se las tiene que "apañar" para conseguir clasificar de forma correcta teniendo menos información.

En nuestro caso, el árbol sin podar presentaba unas mejores características, es decir, era mejor modelo que el modelo podado, básicamente conseguía clasificar mejor, tenía una precisión del 95% mientras que el árbol podado del 89%. Sin embargo, hemos visto que el modelo podado se comportaba mejor a la hora de detectar los tumores benignos, ya que en este caso clasificaba las nuevas observaciones de forma correcta sin fallo.

Respecto a los resultados que hemos obtenido al aplicar a nuestro problema un árbol de decisión no podado son los siguientes:

- Cuando la forma de la célula es clase1 (célula normal), el citoplasma que hay dentro de ella está presente o hay una pequeña cantidad, y el tamaño de la célula epitelial es pequeño, estamos en un caso en el que el tumor es benigno.

- Cuando la forma de la célula es clase1, el citoplasma está presente o hay poca cantidad, y el tamaño de la célula epitelial es mediano o grande, estamos en un caso de tumor maligno, es decir, de cáncer.

- Si la forma de la célula es clase1, y no hay citoplasma dentro de ella, estamos en una situación de un tumor maligno.

- Y si la forma de la célula es de clase2, o clase3, ambas son tamaños grandes respecto a lo que suele ser una célula, por lo que estamos en un caso de cáncer.

Respecto a los resultados obtenidos al aplicar un árbol de decisión podado son los siguientes:

- Si la forma de la célula es del tipo clase1, estamos en un caso en el que el tumor es benigno.

- Si la forma de la célula es del tipo clase2 o clase3, en este caso es tumor es maligno.

En resumen, ambos modelos son muy buenos, pero en líneas general el modelo cuyo árbol de decisión no está podado se comporta mejor.

## Ejercicio 5

En este ejercicio tenemos como objetivo seguir usando un algoritmo de clasificación, pero en el que podamos hacer una técnica de boosting. De esta forma, vamos a ver si el nuevo modelo que vamos a crear se comporta mejor o igual o peor, que el modelo sin podar del ejercicio anterior.

Lo primero de todo es decicir qué técnica de boosting vamos a hacer, nos hemos decantado por usar la librería C50, y con el algoritmo C5.0 vamos a hacer uso del adaptive boosting (https://fhernanb.github.io/libro_mod_pred/adaboost.html), esta técnica tiene como objetivo crear diferentes clasificadores para que lo que el primero no fue capaz de clasificar bien, el segundo clasificador lo haga y así sucesivamente, para ello se le da un peso a cada clasificador y finalmente se suma todo para determinar a qué clase pertenece la nueva observación.

### Preparación de los datos

En este caso, vamos a usar el mismo dataset que se usó en el ejercicio 4, pero para mantener la lógica de un dataframe por ejercicio, creamos uno nuevo. Cabe destacar que vamos a seguir teniendo un conjunto para el entreamiento, y otro para el test, de esta forma conseguimos saber cómo de bueno es prediciendo el modelo a partir del entrenamiento:
```{r}
df_ejer5_train = df_ejer4_train
df_ejer5_test = df_ejer4_test
```

Comprobamos que la estrucutra de ambos conjuntos es la correcta y no hay datos sesgados:
```{r}
summary(df_ejer5_train)
summary(df_ejer5_test)
```

De la anterior ejecución vemos que no hay mucha diferencia en cuanto a los conjuntos de datos en sí, es decir, dejando de lado que en test hay menos datos que en train, vemos que la prporción para cada variable se mantiene más o menos, es decir, no sesgamos la información.

### Creación del modelo

El siguiente paso es crear el modelo, para ello le pasamos el conjunto de entrenamiento con las variables independientes (todas menos la variable objetivo) y la variable objetivo (d-Class), por último le indicamos el trials, este parámatro nos indica cuantas iteraciones de boosting tiene que ejecutar el algoritmo, en nuestro caso le hemos indicado 3 iteraciones (para así poder hacer un análisis de las reglas obtenidas), por defecto este valor es 1:
```{r}
set.seed(0)

modelo_ejer5 = C5.0(df_ejer5_train[, -c(9)], df_ejer5_train$`d-Class`, trials = 3, rules = TRUE)
```

Comrobamos cómo se ha definido el modelo:
```{r}
summary(modelo_ejer5)
```

Vemos que el modelo no es perfecto del todo, ya que contiene errores, para ser más exactos ha clasificado mal 11 registros, pero solo 11 registros de 466 observaciones, por lo que el error que está cometiendo este modelo es de un 2.4%, esto es muy poco, es decir, el modelo se comporta muy bien en el entrenamiento.

De los registros que clasifica mal, vemos que 8 los ha clasificado como benigno cuando realmente son malignos, y 3 los ha clasificado como maligno cuando realmente es benigno, es decir, el modelo ajusta bien los datos.

A priori podríamos decir que este modelo es el mejor de todos los que hemos hecho, pero esto lo evaluaremos más adelante, para saber si a la hora de predecir también es bueno o no.

### Análisis de reglas

Una vez que hemos creado el modelo, podemos realizar la interpretación de las reglas que nos ha generado. En nuestro caso, obtenemos las siguientes reglas:
```{r}
summary(modelo_ejer5)
```

Para el primer árbol de clasificación obtenemos las siguientes reglas:

- Si el tamaño de la célula es pequeño, hay citoplasma en la célula y la textura del núcleo es uniforme => es un tumor benigno con un 98% probabilidad.

- Si el tamaño de la célula es pequeño y la la forma es de clase1 (forma normal) => el tumor es benigno con un 93% probabilidad.

- Si la textura del núcleo es burda => tumo maligno con 97%.

- Si la forma es clase2 o clase3 (formas anormales) y tiene poco citoplasma o no está presente => el tumor es maligno con un 97%.

- Si el grosor de la célula es grueso y la textura del núcleo está tirando a burgos => tumor maligno con un 95% de probabilidad.

- Si el tamaño de la célula es grande o mediano => el tumor es maligno con un 95%.

- Si no hay citoplasma en la célula => el tumor es maligno con un 95%.

El segundo árbol que nos genera al hacer boosting presenta las siguientes reglas:

- Si la textura del núcleo es uniforme => el tumor es benigno con un 77% de probabilidades.

- Si el grosor de la célula es grueso y al textura del núcleo es uniforme => tumor maligno con 87%.

- Si el grosor es mediano o grueso, la capacidad de separarse las células es alta, el tamaño de las células epiteliales es mediano o grande, y hay citoplasma => el tumor es maligno con un 87%.

- Si la textura del núcleo es burda o tira a ser burda => el tumor es maligno con un 80%.

- Si la capacidad de separarse la células es baja => el tumor es malingo con un 79% de probabilidades.

Por último, analizamos las reglas del tercer árbol de clasificación:

- Si la célula es pequeña y la forma es normal => el tumor es benigno con un 91%.

- Si la capacidad de separarse la células es alta pero la textura del núcleo uniforme => el tumor es benigno con un 83% de probabilidad.

- Si la forma de la célula no es normal y la textura del núcleo tira a ser burda => el tumor es maligno con un 98% de probabilidad.

- Si la forma no es normal y la capacidad de separarse la célula es baja => tumor maligno con un 98%.

- Si el grosor de la célula es delgado y la forma no es normal => tumor maligno con un 94%.

- Si el tamaño de la cálula es mediano o grande y la forma es normal => el tumor es maligno con un 92% de probabilidad.

En resumen, analizando las reglas vemos que sigue la tendencia de todos los ejercicios anteriores, es decir, si tenemos valores normales el tumor es benigno, pero a nada que haya un par de variables fuera de lo normal, como el tamaño de la célula, la forma, el grosor de la misma... Estas variables influyen altamente en cómo es un tumor, por lo que tener valores "normales" en dichas variables nos va a garantizar que el tumor es benigno, en caso contrario estaríamos hablando de cáncer.

### Evaluación del modelo

En este apartado vamos a realizar la evaluación de este modelo y vamos a compararlo con el mejor modelo del apartado anterior, cabe recordar que dicho modelo fue el árbol no podado.

El análisis lo vamos a hacer dependiendo de varios parámetros, el primero de ellos es la comprensibilidad.

Tal y como se comentó en el ejercicio anterior, entendemos por comprensibilidad aquellos modelos que son más fáciles de interpretar, ya sea a nivel visual o de reglas. En este caso, el modelo generado en este ejercicio presenta una técnia de boosting, es decir, una técnica para mejorar el rendimiento del modelo. Hemos elegido como técnica de boosting, el generar varios modelos clasificatorios para un mismo modelo, es decir, buscamos que lo que no sea capaz de clasificar bien el primer modelo lo haga el seguno y así sucesivamente.

Por lo tanto, en este ejercicio no tenemos un modelo en sí, sino que tenemos varios modelos que de forma conjunta forman un único modelo, es por ello que la compresibilidad de este modelo es peor que el árbol sin podar del ejercicio anterior, es decir, al tener más modelos hay más reglas y es más difícil de interpretar.

El siguiente parámetro a analizar es ver cómo es la capacidad predictiva del modelo, para ello calculamos la matriz de confusión:
```{r}
predicciones_modelo_boosting = predict(modelo_ejer5, newdata = df_ejer5_test, type = "class")

confusionMatrix(predicciones_modelo_boosting, df_ejer5_test$`d-Class`, positive = "Maligno")
```

Tal y como podemos ver, este modelo es muy bueno, tiene una precisión del 94%, es decir, va a clasificar correctamente por norma general el 94% de los datos nuevos que se le introducen. ¿Pero es sufuciente como para decir si es mejor que el modelo creado en el ejercicio anterior?

Recordando la precisión que teníamos en el árbol no podado era de un 94.5%, por lo que por norma general el modelo anterior se comporta mejor que el modelo con boosting, pero puede ser que un modelo se comporte mejor que otro en determinados aspectos así que vamos a analizar la sensibilidad y la especificidad.

- La sensibilidad nos determina cómo es de bueno el modelo clasificando los casos positivos, en el modelo con boosting presentamos una sensibilidad del 82% mientras que en el modelo del ejercicio anterior tenemos un valor del 87%, es decir, vemos que cuando hay un caso positivo (el tumor es maligno) el modelo sin boosting se comporta mejor que el de boosting. Por lo tanto, respecto a este punto sigue siendo el árbol no podado el mejor modelo.

- La especificidad indica cómo de bien clasifica el modelo los casos negativos, en el modelo con boosting presentamos un 100% mientras que en el árbol no podado su especificidad es del 99%, por lo tanto el modelo con boosting presenta una mejora al clasificar los tumores benignos, pero vemos que esta mejora no es muy grande respecto al modelo del árbol sin podar.

En resumen, vemos que tenemos dos modelos muy buenos, ambos tienen una elevada precisión, sin embargo, el modelo del árbol sin podar se comporta un pelín mejor, sobre todo cuando los datos a clasificar son tumores malignos, mientras que el modelo con boosting es mejor para clasificar los tumores benignos.

Por lo tanto, podríamos hacer uso de ambos modelos dependiendo de qué datos vayamos a utilizar, es decir, si queremos tener un mayor éxsito para clasificar el tumor como beningno o como maligno.

### Conclusiones

Para realizar este ejercicio se ha creado un modelo con una mejora de boosting, y para ello hemos usado la librería C50 que con el parámetro trials, dicho parámetro lo hemos establecido a 3 para así crear tres modelos de clasificación y poder analizarlos correctamente.

Tal y como hemos visto en la evaluación del modelo, se consigue generar un modelo muy bueno, pero no lo suficiente como para mejorar el árbol de decisión no podado del ejercicio anterior.

Nos hemos basado en diferentes parámetros para dictaminar qué modelo es mejor:

- La precisión, el modelo con boosting tiene una precisión del 94% mientras que el árbol no podado su precisión es del 94.5%.

- El modelo con boosting clasifica peor cuando los casos son tumores malignos, ya que presenta una sensbilidad del 82%, mientras que el árbol de decisión sin podar clasifica correctamente el 87% de los tumores malignos.

- Respecto a la especificidad, el modelo con boosting se comporta mejor, es decir, es capaz de clasificar correctamente 100% de los tumores benignos, mientras que el árbol sin podar clasifica el 99% de forma correcta.

En resumidas palabras, ambos modelos son muy buenos, es verdad que si el modelo con boosting tuvierna más iteraciones sería aún mejor modelo, pero esto nos generaría muchas reglas para cada iteración y para poder analizarlas se ha considerado lo óptimo 3 iteraciones.

Respecto a la información que obtenemos, sigue la línea de todos los ejercicios anteriores, es decir, si tenemos valores normales el tumor es benigno, pero a nada que haya un par de variables fuera de lo normal, como el tamaño de la célula, la forma, el grosor de la misma... Estas variables influyen altamente en cómo es un tumor, por lo que tener valores "normales" en dichas variables nos va a garantizar que el tumor es benigno, en caso contrario estaríamos hablando de cáncer.


******
# Criterios de evaluación
******

* Ejercicio 1 (25%)
	- Se genera un modelo no supervisado.
	- Se analizan, muestran y comentan las medidas de calidad del modelo generado.
	- Se comentan las conclusiones.

* Ejercicio 2 (10%)
	- Se genera de nuevo el modelo no supervisado anterior, pero usando una métrica de distancia distinta.
	- Se muestran y comentan las medidas de calidad del modelo generado.
	- Adicionalmente se comparan los dos modelos no supervisados con métricas de distancia distintas.
	- Se comentan las conclusiones. 
	
* Ejercicio 3 (10%)
	- Se representa, analiza y comenta un ejemplo de reglas de asociaciones aplicado al dataset seleccionado, o en su defecto se reformula el problema (mínimo de 250 palabras).
	- Se comentan las conclusiones.

* Ejercicio 4 (25%)
	- Se generan reglas y se comentan e interpretan las más significativas.
	- Extraemos las reglas del modelo en formato texto y gráfico.
	- Adicionalmente se genera matriz de confusión para medir la capacidad predictiva del algoritmo.
	- Se comparan e interpretan los resultados sin y con opciones de poda, explicando las ventajas e inconvenientes del modelo generado respecto a otro método de construcción.
	- Se evalúa la tasa de error en cada nivel de árbol, la eficiencia en clasificación (en las fases de training, validación y test) y la comprensibilidad.
	- Se comentan las conclusiones.

* Ejercicio 5 (10%)
	- Se aplica una mejora con técnica de boosting. 
	- Se detalla, comenta y evalúa la calidad de clasificación.
	- Se comparan y comentan los resultados de manera exhaustiva con el anterior método de construcción.

* Ejercicio 6 (10%)
  - Identifica qué posibles limitaciones tienen los datos que has seleccionado para obtener conclusiones con los modelos (supervisado y no supervisado)
  - Se identifican posibles riesgos del uso del modelo  (mínimo 250 palabras).
  
* Consideración general (10%) 
  - Se presenta el código y es fácilmente reproducible.
  - Se detalla cada pregunta de manera correcta, mostrando el código, comentando como se ha hecho y porque se ha hecho, comparando los resultados y/o indicando otras alternativas al problema indicado.
  - Se muestran las conclusiones en cada apartado
  - Se indican eventuales citaciones bibliográficas, fuentes internas/externas y materiales de investigación.


******
# Recursos de programación
******
* Incluimos en este apartado una lista de recursos de programación para minería de datos donde podréis encontrar ejemplos, ideas e inspiración:
  + [Material adicional del libro: Minería de datos Modelos y Algoritmos](http://oer.uoc.edu/libroMD/)
  + [Espacio de recursos UOC para ciencia de datos](http://datascience.recursos.uoc.edu/es/)
  + [Buscador de código R](https://rseek.org/)  
  + [Colección de cheatsheets en R](https://rstudio.com/resources/cheatsheets/)  
  

******

******






