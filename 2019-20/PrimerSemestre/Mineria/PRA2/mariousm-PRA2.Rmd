---
title: 'Minería de datos: PRA2 - Modelado de un juego de datos'
author: "Autor: Mario Ubierna San Mamés"
date: "Mayo 2021"
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
    includes:
      in_header: 75.584-PEC-header.html
  word_document: default
  pdf_document:
    highlight: zenburn
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
******
# Introducción
******
## Presentación
Esta práctica cubre de forma transversal la asignatura.

Las Prácticas 1 y 2 de la asignatura se plantean de una forma conjunta de modo que la Práctica 2 será continuación de la 1.

El objetivo global de la **Práctica 2** es de extraer conocimientos y de comparar las diferentes soluciones aplicando todo lo aprendido mediante los algoritmos de clustering, asociación y clasificación.

## Competencias
Las competencias que se trabajan en esta prueba son:  

* Uso y aplicación de las TIC en el ámbito académico y profesional.
* Capacidad para innovar y generar nuevas ideas.
* Capacidad para evaluar soluciones tecnológicas y elaborar propuestas de proyectos teniendo en cuenta los recursos, las alternativas disponibles y las condiciones de mercado.
* Conocer las tecnologías de comunicaciones actuales y emergentes así como saberlas aplicar convenientemente para diseñar y desarrollar soluciones basadas en sistemas y tecnologías de la información.
* Aplicación de las técnicas específicas de ingeniería del software en las diferentes etapas del ciclo de vida de un proyecto.
* Capacidad para aplicar las técnicas específicas de tratamiento, almacenamiento y administración de datos.
* Capacidad para proponer y evaluar diferentes alternativas tecnológicas para resolver un problema concreto.

## Objetivos
La correcta asimilación de todos los aspectos trabajados durante el semestre.  
En esta práctica abordamos un caso real de minería de datos donde tenemos que poner en juego todos los conceptos trabajados.
Hay que trabajar todo el ciclo de vida del proyecto. Desde el objetivo del proyecto hasta la implementación del conocimiento encontrado pasando por la preparación, limpieza de los datos, conocimiento de los datos, generación del modelo, interpretación y evaluación.

## Descripción de la PRA a realizar
La práctica consta de ejercicios en los cuales el estudiante aplicará algunos de los métodos supervisados y no supervisados aprendidos durante el semestre.

## Recursos Básicos
Material docente proporcionado por la UOC. 

## Criterios de valoración

**Ejercicios prácticos** 

Para todas las PRA es necesario documentar en cada apartado del ejercicio práctico que se ha hecho y como se ha hecho.

## Formato y fecha de entrega
El formato de entrega es: **usernameestudiante-PRA2** *.Rmd* y el **output generado** en uno de estos formatos *html/doc/docx/odt/pdf*.

Fecha de entrega: **16/06/2021**  

Se debe entregar la PRA en el buzón de entregas del aula en formato comprimido que incluye los ficheros:
- ejecutable
- output
- el dataset seleccionado o en su defecto indicar la ruta para su descarga en el ejecutable.  

## Nota: Propiedad intelectual 

> A menudo es inevitable, al producir una obra multimedia, hacer uso de recursos creados por terceras personas. Es por lo tanto comprensible hacerlo en el marco de una práctica de los estudios de Informática, Multimedia y Telecomunicación de la UOC, siempre y cuando esto se documente claramente y no suponga plagio en la práctica. 

> Por lo tanto, al presentar una práctica que haga uso de recursos ajenos, se debe presentar junto con ella un documento en que se detallen todos ellos, especificando el nombre de cada recurso, su autor, el lugar donde se obtuvo y su estatus legal: si la obra esta protegida por el copyright o se acoge a alguna otra licencia de uso (Creative Commons, licencia GNU, GPL ...). 
El estudiante deberá asegurarse de que la licencia no impide específicamente su uso en el marco de la práctica. En caso de no encontrar la información correspondiente tendrá que asumir que la obra esta protegida por copyright. 

> Deberéis, además, adjuntar los ficheros originales cuando las obras utilizadas sean digitales, y su código fuente si corresponde.  

******
# Enunciado
******
Como continuación del estudio iniciado en la práctica 1, procedemos en **aplicar modelos analíticos** sobre el juego de datos seleccionado y preparado.  En esta práctica 2 se aconseja de adjuntar los “chunks” de la parte de preparación previa, ejemplo (limpieza, discretización, normalización, PCA/SVD etc.), o en su defecto cargar solo los datos ya preparadados.

De este modo se pide al estudiante que complete los siguientes pasos:

1. Aplicar un modelo **no supervisado** y basado en el concepto de distancia, sobre el juego de datos.

2. Aplicar de nuevo el modelo anterior, pero usando una **métrica distinta** y comparar los resultados.

3. Razonar si tiene sentido aplicar al dataset seleccionado, un método de **generación de reglas de asociaciones**. En caso afirmativo, realizar tal proceso y explicar los resultados. En caso contrario, reformula el problema para que sí lo tenga.

4. Aplicar un modelo de generación de reglas a partir de **árboles de decisión** sin y con opciones de poda y comparar los resultados.

5. Aplicar una mejora con **técnicas de boosting** y comparar el resultado con el anterior.
	
6. Identificar eventuales **limitaciones** del dataset seleccionado y **analizar los riesgos** para el caso de uso.

7. (Punto común para todos los ejercicios) - 
En todos los puntos anteriores se pide al estudiante, además de aplicar los diferentes métodos, de analizar correctamente el problema, **detallar de manera exhaustiva** resaltando el porque y como se ha realizado, incluyendo elementos visuales, explicando los resultados, realizar las comparativas oportunas con sus conclusiones.


******
# Solución
******

## Librerías

En este apartado adjuntamos todas las cargas de librerías necesarias para la resolución de la práctica:
```{r}
library(scales)
library(cluster)
library(dplyr)
library(arules)
library(arulesViz)
```

## Resumen del dataset

El dataset elegido para dar respuestas a las preguntas que nos hemos hecho en la práctica uno es el de Breast Cancer Wisconsin (Original) Data Set de Machine Learning Repository [https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Original%29]

Hemos elegido dicho dataset porque nos proporciona toda la información necesaria, a partir de datos como el tamaño de la célula, la forma de la célula...

Es verdad que hay datasets similares a este pero con más atributos, es decir, aquí solo tenemos un campo para el tamaño de la célula, mientras que en otros datasets ese campo podía venir representado por tres atributos, pero este dataset consigue mantener la misma información reduciendo ya la dimensionalidad de los atributos. Por otro lado, los valores numéricos en este conjunto de datos van del 1 al 10, es decir, [1-10], estos valores no son aleatorios sino que un grupo de expertos ha "normalizado" dichos valores para representar la misma información pero de una forma más sencilla.

Finalmente, a continuación se indica los atributos que tiene este dataset:

**Id**
    integer - identificador de la observación.
    
**Thickness**
    integer [1-10] - espesor/grosor del tumor.
    
**Cell_Size**
    integer [1-10] - uniformidad del tamaño celular.
    
**Cell_Shape**
    integer [1-10] - uniformidad de la forma celular.
    
**Adhesion**
    integer [1-10] - adherencia celular.
    
**Epithelial_Cell_Size**
    integer [1-10] - tamaño de una sola célula epitelial.
    
**Bare_Nuclei**
    integer [1-10] - núcleo desnudo.
    
**Bland_Chromatin**
    integer [1-10] - textura del núcleo.
    
**Normal_Nucleoli**
    integer [1-10] - nucléolos normales.
    
**Mitoses**
    integer [1-10] - mitosis.
    
**Class**
    integer - clase si es beningno 2, si es maligno 4.
    
Aunque algun concepto es fácil de entender los demás no, es por ello que vamos a definir cada concepto:

- Thickness: hace referencia al espesor/grosor de la masa mamaria que se estudia, es decir, del tumor.

- Cell_Size: tamaño de las células que se estudian, las células cancerígenas suelen cambiar de tamaño.

- Cell_Shape: forma de las células que se estudian, las células cancerígenas suelen cambiar de forma.

- Adhesion: las células que son cancerígenas tienden a separarse unas de las otras, mientras que en las células normales sucede todo lo contrario.

- Epithelial_Cell_Size: las células que son significativamente grandes suelen ser cancerígenas.

- Bare_Nuclei: nos indica si el núcleo de las células está rodeado por el citoplasma (células normales), en caso contrario es probable que sean células cancerígenas.

- Bland_Chromatin: textura de los núcleos de las células, cuanto más tosco sea más probabiliades de que la célula sea cancerígena.

- Normal_Nucleoli: los nucleólos son pequeñas estructuras que se encuentran en los núcleos, en células benignas suelen ser estructuras pequeñas mientras que en las malignas son más grandes.

- Mitoses: proceso en el cual las células eucariotas se dividen.

Toda esta información se ha obtenido de la siguiente página [https://core.ac.uk/download/pdf/77274625.pdf], cabe destacar que a mayor valor de cada atributo más probable es que la célula sea anormal y dentro de esta anormalidad sea cancerígena.

Por último, tenemos 699 observaciones y 11 atributos en el dataset original, pero se han creado tambien el dataset normalizado con 699 observaciones y 11 atributos, y el discretizado con 699 observaciones y 21 variables.

## Preparación de los datos

En este primer apartado vamos a preparar el conjunto de datos para así poder aplicar modelos analíticos. Cabe destacar que esta limpieza ya se hizo en la práctica uno, por lo que vamos a adjuntar el código necesario para generar el dataset final sin entrar en la explicación del mismo ni en el análisis de los datos.

```{r}
# CARGAMOS
df = read.table(file="./data/breast-cancer-wisconsin.data", fileEncoding="UTF-8", sep=",", na.strings = "NA")

# Cambiamos el nombre de las columnas tal y como se llaman según la página web
colnames(df) = c("Id", "Thickness", "Cell_Size", "Cell_Shape", "Adhesion", "Epithelial_Cell_Size", "Bare_Nuclei", "Bland_Chromatin", "Normal_Nucleoli", "Mitoses", "Class")

# Creamos una copia del dataframe, ya que va a ser la copia sobre la que vamos a realizar las modificaciones
df_copy = df

# IMPUTAMOS
df_copy[df_copy$Bare_Nuclei == "?", "Bare_Nuclei"] = NA
df_copy$Bare_Nuclei = as.integer(df_copy$Bare_Nuclei)

nMediana = median(df_copy$Bare_Nuclei, na.rm = TRUE)
df_copy$Bare_Nuclei[is.na(df_copy$Bare_Nuclei)] = nMediana

# nORMALIZAMOS
df_normalizado = scale(df_copy)

# Generamos el dataset normalizado
write.csv(df_normalizado, file = "./data/breast-cancer-clean-normalized.csv", row.names = FALSE)

# DISCRETIZAMOS

df_discretizado = df_copy

# Dicretización del grosor
df_discretizado["d-Thickness"] = ordered(cut(df_discretizado[["Thickness"]], breaks = c(0,4,7,10), labels = c("Delgado", "Mediano", "Grueso")))

# Dicretización del tamaño
df_discretizado["d-Cell_Size"] = ordered(cut(df_discretizado[["Cell_Size"]], breaks = c(0,4,7,10), labels = c("Pequeño", "Mediano", "Grande")))

# Dicretización del forma
df_discretizado["d-Cell_Shape"] = ordered(cut(df_discretizado[["Cell_Shape"]], breaks = c(0,4,7,10), labels = c("Clase1", "Clase2", "Clase3")))

# Dicretización a la adhesión marginal
df_discretizado["d-Adhesion"] = factor(cut(df_discretizado[["Adhesion"]], breaks = c(0,5,10), labels = c("Alta", "Baja")))

# Dicretización del tamaño de las células epiteliales
df_discretizado["d-Epithelial_Cell_Size"] = ordered(cut(df_discretizado[["Epithelial_Cell_Size"]], breaks = c(0,4,7,10), labels = c("Pequeño", "Mediano", "Grande")))

# Dicretización los núcleos desnudos
df_discretizado["d-Bare_Nuclei"] = factor(cut(df_discretizado[["Bare_Nuclei"]], breaks = c(0,4,7,10), labels = c("Presente", "Presente/Ausente", "Ausente")))

# Dicretización de la textura de la núcleos
df_discretizado["d-Bland_Chromatin"] = factor(cut(df_discretizado[["Bland_Chromatin"]], breaks = c(0,4,7,10), labels = c("Uniforme", "Uniforme/Burda", "Burda")))

# Dicretización de la estructoras de los nucleólis
df_discretizado["d-Normal_Nucleoli"] = ordered(cut(df_discretizado[["Normal_Nucleoli"]], breaks = c(0,4,7,10), labels = c("Pequeño", "Mediano", "Grande")))

# Dicretización de la mitosis
df_discretizado["d-Mitoses"] = ordered(cut(df_discretizado[["Mitoses"]], breaks = c(0,4,7,10), labels = c("Mitosis1", "Mitosis2", "Mitosis3")))

# Creamos una columna respecto a la clase, aunque no es discretización como tal, es más fácil ver si un cáncer es benigno respecto a su nombre que no respecto a su valor.
df_discretizado$`d-Class`[df_discretizado$Class == 2] = "Benigno" 
df_discretizado$`d-Class`[df_discretizado$Class == 4] = "Maligno"
df_discretizado$`d-Class` = as.factor(df_discretizado$`d-Class`)

# Generamos el dataset discretizado
write.csv(df_discretizado, file = "./data/breast-cancer-clean-discretized.csv", row.names = FALSE)

```

## Ejercicio 1

En este primer apartado lo que buscamos es aplicar un algoritmo de aprendizaje no supervisado para saber el cómo se agrupa el cáncer, es decir, aunque en nuestro dataset tenemos etiquetadas para cada observación si es cáncer o no, vamos a ignorar este hecho y se va a aplicar un algoritmo de clustering para saber qué hace de especial a los grupos identificados.

### Generación del modelo

Lo primero de todo es observar el dataframe que vamos a usar para este ejercicio:

```{r}
str(df_copy)
```

En este caso, vemos que tenemos información innecesaria ya que los atributos ID y Class no hacen falta, el primero porque sirve para identificar en exclusiva un punto y en este caso no queremos analizar un punto buscamos el análisis de un grupo, y el segundo nos indica el grupo en sí ya que el dataset original estaba pensado para un problema de clasificación, nosotros queremos descubrir qué observaciones representan el cáncer si necesidad de indicarle al algorítmo cuáles son cáncer y cuáles no.

Debido a lo comentado en el párrafo anterior, eliminamos dichas variables:
```{r}
df_ejer1 = df_copy[,2:10]
str(df_ejer1)
```

Comprobamos que tenemos la información correcta. El siguiente paso es hacer un breve análisis de dichos datos:
```{r}
summary(df_ejer1)
```

Como podemos observar todas las variables están acotadas entre los valores 1 y 10, esto se debe a que un grupo experto "normalizó" el dataset con dichos valores.

El significado de este dataset para una variable en específico sería el siguiente, si estudiamos el tamaño de la célula (Cell_Size), a mayor valor más riesgo de que sea un cáncer maligno.

Si se necestia más información sobre el significado de las variables, análisis de las mismas, análisis del dataset en general, se puede hacer la lectura de la práctica uno.

Una vez que tenemos todo preparado podemos generar el modelo de clustering, pero antes debemos hacer una explicación de los grupos que vamos a indicar al algortimo kmeans.

Por norma general, cuando tenemos un problema de clustering que buscamos resolver a partir de la minería de datos, se realiza un estudio sobre cuántos grupos son los ideales para dicho problema, esto tiene toda la lógica ya que a priori desconocemos los mismos, pero en nuestro caso estamos analizando si los datos sobre las células son sobre células benignas o malignas, es decir, desde un principio ya sabemos que los grupos van a ser dos, o tenemos cáncer o no lo tenemos. Por lo tanto, podríamos crear el modelo directamente con los dos grupos, pero por mera curiosidad, vamos a realizar el estudio de grupos para ver cuántos serían lo ideal (aunque sabemos que solo podemos tener dos).

Vamos a calcular el número de clústers ideales para poder realizar nuestro modelo, cabe destacar que calculamos el valor de la silueta x veces para cada modelo, esto es así porque dicho valor cambia todo el rato, al calcularlo x veces podemos hacer una media y que los “mejores clusters” se mantengan independientemente de las veces que se ejecute:
```{r}
kmeans_silhouette = function(df, minCluster = 2, maxCluster = 10, maxIterations = 10) {
  
  if (minCluster <= maxCluster & minCluster > 1) {
    resultados = rep(0, maxCluster)
    
    for (i in c(minCluster:maxCluster)) {
      resultado = rep(0, maxIterations)
      
      for (j in c(1:maxIterations)) {
        fit = kmeans(df, i)
        y_cluster = fit$cluster
        sk = silhouette(y_cluster, daisy(df))
      
        # Como el valor de la silueta puede cambiar de una iteración a otra, calculamos su valor medio
        resultado[j] = mean(sk[,3])
      }
      resultados[i] = mean(resultado)
    }
    return(resultados)
    
  } else {
    print("ERROR: minCluster debe ser menor que maxCluster y mayor que 1")
  }
}
```

Ejecutamos la función anterior, indicándole que el número de grupos mínimo es 2, el máximo 10 y se va a ejecutar 50 veces para cada modelo:
```{r}
minCluster = 2
maxCluster = 10
maxIterations = 50

mean_silhouette = kmeans_silhouette(df_ejer1, minCluster, maxCluster, maxIterations)

plot(minCluster:maxCluster, mean_silhouette[minCluster:maxCluster],type="o",col="blue",pch=0,xlab="Número de clusters",ylab="Silueta")
```

Como podemos apreciar en el anterior gráfico, el número de clústers ideal es cuando tenemos dos grupos, lo cual vemos que coincide con nuestro problema real, es decir, tenemos el grupo de si el tumor es benigno o no.

Por lo tanto, vamos a crear el modelo con dos grupos:
```{r}
set.seed(0)

modelo_ejer1 = kmeans(df_ejer1, 2)
```

### Análisis y muestra de las medidas del modelo generado

Antes de realizar el análisis de los clústers que nos ha generado el modelo y qué caracteriza a cada grupo, vamos a ver cómo de bueno es el modelo que hemos creado.

Lo primero que vamos a hacer es saber cómo de bueno son los agrupamientos, ésto también nos va a definir el número ideal de clústers para nuestro problema, aunque como venimos diciendo van a ser dos. Sabemos que tenemos dos grupos, pero por mera curiosidad vamos a ver si es verdad que el mejor modelo es cuando tenemos dos clústers.

Para ver cómo de bueno es el modelo podemos hacer dos cosas:

- Fijarnos en la menor suma de los cuadrados de las distancias de los puntos de cada grupo con respecto a su centro (withinss).

- Y obtener la mayor separación posible entre los centros de cada grupo (betweenss).

Por lo tanto, primero observamos la withinss, es decir, ver qué clústers hacen que la mínima suma de los cuadrados de las distancias de los punto de cada grupo con su centro:
```{r}
# Método que nos devuelve el valor medio del tot.withinss para un rango de clústers y de iteraciones sobre el mismo clúster
kmeans_totWithinss = function(df, minCluster = 2, maxCluster = 10, maxIterations = 10) {
  
  if (minCluster <= maxCluster & minCluster > 1) {
    resultados = rep(0, maxCluster)
    
    for (i in c(minCluster:maxCluster))
    {
      resultado = rep(0, maxIterations)
      
      for (j in c(1:maxIterations)) {
        fit = kmeans(df, i)
        resultado[j] = fit$tot.withinss
      }
      
      resultados[i] = mean(resultado)
    }
    return(resultados)
    
  } else {
     print("ERROR: minCluster debe ser menor que maxCluster y mayor que 1")
  }
}
```

Obtenemos las métricas de la withinss para cada modelo de 2 clústers a 10:
```{r}
mean_totWithinss = kmeans_totWithinss(df_ejer1, minCluster, maxCluster, maxIterations)

plot(minCluster:maxCluster,mean_totWithinss[minCluster:maxCluster],type="o",col="blue",pch=0,xlab="Número de clusters",ylab="tot.tot.withinss")
```

Como podemos apreciar, a mayor número de clústers menor es el error, pero esto no es lo correcto porque nos generaría un modelo muy específico, y lo que buscamos generalizar. Para nuestro problema seguimos considerando que lo mejor son dos clústers, ya que buscamos saber si el tumor es benigno o no, aunque a la vista de la anterio gráfica es en este caso cuando obtenemos una mayor separación entre los puntos de cada grupo y su centro.

Continuando con la calidad del modelo, vamos a ver cómo es la betweenss, es decir, cuanto más separados estén los grupos mejor:
```{r}
# Método que nos devuelve el valor medio de la betweenss para un rango de clústers y de iteraciones sobre el mismo clúster
kmeans_betweenss = function(df, minCluster = 2, maxCluster = 10, maxIterations = 10) {
  
  if (minCluster <= maxCluster & minCluster > 1) {
    resultados = rep(0, maxCluster)
    
    for (i in c(minCluster:maxCluster))
    {
      resultado = rep(0, maxIterations)
      
      for (j in c(1:maxIterations)) {
        fit = kmeans(df, i)
        resultado[j] = fit$betweenss
      }
      
      resultados[i] = mean(resultado)
    }
    return(resultados)
    
  } else {
     print("ERROR: minCluster debe ser menor que maxCluster y mayor que 1")
  }
}
```

Una vez definida la función la llamamos:
```{r}
mean_betweenss = kmeans_betweenss(df_ejer1, minCluster, maxCluster, maxIterations)

plot(minCluster:maxCluster,mean_betweenss[minCluster:maxCluster],type="o",col="blue",pch=0,xlab="Número de clusters",ylab="betweenss")
```

Aunque de la gráfica anterior un modelo con 4, 5 o 6 clústeres obtendríamos una mejor betweenss y un modelo más general, el caso que estamos abordando no se vería representado, es decir, no podemos categorizar el cáncer de seis formas distintas, es decir, o tienes cáncer o no.

Debido a esto vamos a analizar para el modelo creado, es decir, un modelo con dos clústers, cómo es la silueta, cómo es su withinss, y su betweenss.

Respecto a la silueta:
```{r}
set.seed(0)
cat("La silueta del modelo con 2 grupos es: ", kmeans_silhouette(df_ejer1, 2, 2, 1)[2])
```

La silueta nos indica cómo de similar es un elemento con los de su propio grupo y cómo de diferente respecto a los demás, su valor va entre -1 y 1, cuanto más próximo esté el valor a uno mejor es el modelo, ya que esto significa que un elemento está bien emparejado con los de su gurpo (es muy similar) y a su vez es muy diferente respecto a los demás grupos.

En nuestro caso, obtenemos un valor de silueta de casi el 0.60, por lo que el modelo está bastante bien aunque podría estar mejor, pero como primera aproximación el modelo se comporta bien.

Lo siguiente que vamos a hacer es ver si withinss:
```{r}
cat("El withinss del modelo con 2 grupos es: ", modelo_ejer1$tot.withinss)
```

En este caso vemos que obtenemos una withinss muy elevada, esto significa que la suma de las distancias de cada punto respecto al centro de su grupo es mayor, lógicamente como ya hemos visto antes, a mayor número de clústers menor es la withinss, pero en nuestro caso tenemos que tener dos clústers sí o sí, por lo tanto aunque tenemos una elevada withinss esto se debe al número bajo de clústers no porque el modelo sea malo en sí, como vimos la siuelta es elevada por lo que el modelo es bueno.

La última medida a analizar es la betweenss:
```{r}
cat("La betweenss del modelo con 2 grupos es: ", modelo_ejer1$betweenss)
```

Respecto a la betweenss no tenemos un valor suficientemente alto, como ya vimos esto también es lógico, a mayor número de clústers más centros dando lugar a una mayor betweenss, pero al igual que antes estamos "condenados" a dos grupos.

En resumen, aunque la métricas withinss y betweens no son las mejores, respecto a cambiar el número de clústers no podemos hacer nada, ya que el tumor es benigno o maligno, solo hay dos clases. Sin embargo, nos podemos fiar de la silueta del modelo cuando tenemos dos clústers, y hemos visto que este valor es elevado, por lo que tenemos un buen modelo para analizar el cómo se agrupan los tumores y ver si hay cáncer o no.

### Conclusiones

En este apartado vamos a realizar el análisis del modelo, es decir, cómo agrupa los tumores según su características principales: el tamaño de la célula, la forma, el grosor del tumor...

Lo primero que vamos a analizar es el grosor del tumor, el ver cómo el tamaño de la célula, la adhesión (las células que son cancerígenas tienden a separarse unas de las otras, mientras que en las células normales sucede todo lo contrario), y si presenta núcleos desnudos (si el núcleo de las células está rodeado por el citoplasma (células normales), en caso contrario es probable que sean células cancerígenas).

Por lo tanto, mostramos el grosdor del tumor y el tamaño de la célula y vemos cómmo lo agrupa el modelo:
```{r}
plot(df_ejer1[,c("Thickness", "Cell_Size")], col=modelo_ejer1$cluster, main="Grosor de la célula respecto al tamaño")
```

Lo primero de todo es identificar los grupos que nos genera, podemos ver claramente que los grupos vienen determinados por el tamaño de la célula y no tanto por el grosor, es decir, a mayor tamaño de la célula más riesgo de que el tumor sea maligno (grupo negro) y menor tamaño de que sea benigno (grupo rojo).

Algo curioso del anterior gráfico es que podemos tenemos un grosor muy elevado, pero que la célula sea muy pequeña y esto no significa para nada que tengamos cáncer, es decir, es muy influyente el cómo es el tamaño de la célula para dictaminar si ésta es cancerígena o no.

El siguiente análisis es comprobar el cómo influye el grosor a la adhesión de las células:
```{r}
plot(df_ejer1[,c("Thickness", "Adhesion")], col=modelo_ejer1$cluster, main="Grosor de la célula respecto a la adhesión de las mismas")
```

En este caso vemos que ya no están tan bien definidos los clústers, es decir, hay casos especiales. Por norma general, un mayor grosor lleva implícito una peor adhesión, es decir, cuánto más gruesa sea la célula más probabilidades hay de que sea cancerígena y tienda a serparase unas de otras más fácilmente. Sin embargo, a menor grosor más probable que la célula sea benigna y no se separe las unas de las otras.

Por último respecsto al grosor, vamos a comporar si Bare_Nuclei afecta, es decir, si las células que están rodeadas de citoplasma y las que no dependen del grosor o no:
```{r}
plot(df_ejer1[,c("Thickness", "Bare_Nuclei")], col=modelo_ejer1$cluster, main="Grosor de la célula respecto a las células con citoplasma")
```

En este caso vemos que el grosor de la célula también influye, es decir, cuanto mayor sea el grosor más probabilidades de que la célula no tenga citoplasma o éste esté presente en bajas cantidades, esto significaría cáncer. En caso contrario, estaríamos ante un tumor benigno.

El siguiente paso es analizar el tamaño de la célula, el ver cómo influye ésta respecto a la forma de la misma, al tamaño de las células epiteliales, y a la textura de los núcleos. Todo esto nos sirve para determinar en qué casos tenemos un cáncer benigno o maligno.

Por lo tanto, analizamos el tamaño de la célula respecto a la forma de la misma:
```{r}
plot(df_ejer1[,c("Cell_Size", "Cell_Shape")], col=modelo_ejer1$cluster, main="Tamaño de la célula respecto a la forma")
```

Como podemos observar, a mayor tamaño de célula mayor es su forma y esto lleva implícito un mayor riesgo de cáncer. Cabe destacar, que los tumores beningnos tienen un tamaño y una forma pequeña, es decir, el normal es moverse entre un tamaño de 1 y 3, a nada que nos movamos de dicho tamaño el riesgo aumenta muchísmo.

El siguiente análisis es el tamaño respecto al tamaño de las célula epiteliales:
```{r}
plot(df_ejer1[,c("Cell_Size", "Epithelial_Cell_Size")], col=modelo_ejer1$cluster, main="Tamaño de la célula respecto al tamaño de las células epiteliales")
```

En este caso, podemos apreciar que tener un tamaño de célula epitelial muy elevado no significa cáncer, pero a medida que aumenta el tamaño de las células, al igual que en el caso anterior, sí que aumenta el riesgo de que el tumor seas maligno.

Finalmente, analizamos el tamaño respecto a la textura de los núcleos:
```{r}
plot(df_ejer1[,c("Cell_Size", "Bland_Chromatin")], col=modelo_ejer1$cluster, main="Tamaño de la célula respecto a la textura del núcleo")
```

En este caso, vemos que si tenemos una textura muy tosca, es decir, un valor elevado de la variable Bland_Chromatin, podemos estar hablando de un caso de cáncer, es decir, esta variable es significativa para dictaminar si el tumor es benigno o no. También, como hemos ido estudiando, al aumentar el tamaño de la célula esto sigue suponiendo un mayor riesgo de cáncer.

El siguiente análisis que vamos a hacer es relativo al tamaño epitelial de las células, vamos a comprobar si dicho tamaño es afectado por si hay nucleólos pequeños o grandes y el proceso de mitosis.

Por lo tanto, mostramos el tamaño epitelial frente a la nuclólos:
```{r}
plot(df_ejer1[,c("Epithelial_Cell_Size", "Normal_Nucleoli")], col=modelo_ejer1$cluster, main="Tamaño de las células epiteliales respecto al tamaño de los nucleólos")
```

Podemos concluir que no por tener una estructura de nucleólos grande significa que vaya a tener cáncer, sin embargo, a medida que aumenta el tamaño de las células epiteliales, y la estructura de los nucleólos aumenta, vemos que sí que hay una ligera relación, esto supone un mayor riesgo de que el tumor se maligno.

Analizamos el tamaño de las células epiteliales frente a la mitosis:
```{r}
plot(df_ejer1[,c("Epithelial_Cell_Size", "Mitoses")], col=modelo_ejer1$cluster, main="Tamaño de las células epiteliales respecto a la mitosis")
```

En este caso vemos que no hay relación, es decir, no por tener una mejor mitosis tenemos mayor riesgo, sino que el riesgo viene determinado por el tamaño de la célula epitelial.

El siguiente elemento a estudiar va a ser si el núcleo de las células está rodeado de citoplasma (signnifica un menor riesgo de cáncer) o no (mayor riesgo), respecto a la forma de la célula, la capacidad de separarse de otras células y si la textura del núcleo influye.

Por lo tanto, analizamos primero si el citoplasma se ve afectado por la forma de la célula:
```{r}
plot(df_ejer1[,c("Bare_Nuclei", "Cell_Shape")], col=modelo_ejer1$cluster, main="La presencia de citoplasma respecto a la forma de la célula")
```

Podemos apreciar que hay una relación, cuando aumenta la forma de la célula lo hace también Bare_Nuclei (menos presencia de citoplasma), esto supone un mayor riesgo de cáncer. De primeras podríamos intuir que al aumentar la forma hay más espacio para más citoplasma, pero vemos que es todo lo contrario, ya que al aumentar la forma la célula va tomando las característias de una célula cancerígena y esto suele suponer reducir el citoplasma de la misma.

Analizamos la capacidad que tiene la célula de separarse:
```{r}
plot(df_ejer1[,c("Bare_Nuclei", "Adhesion")], col=modelo_ejer1$cluster, main="La presencia de citoplasma respecto a la adhesión")
```

En este caso, vemos que también está relacionado, al reducirse el citoplasma de las células (aumenta Bare_Nuclei) éstas tienden a separase más, por lo tanto, incrementa el riesgo de padecer cáncer.

Otro aspecto a analizar, es si al reducir el citoplasma se ve afectado la textura del núcleo:
```{r}
plot(df_ejer1[,c("Bare_Nuclei", "Bland_Chromatin")], col=modelo_ejer1$cluster, main="La presencia de citoplasma respecto a la textura del núcleo")
```

En este caso vemos que no hay una relación tan fuerte, pero es verdad que cuando aumenta la textura del núcleo de por sí ya tenemos un mayor riesgo de cáncer, lo mismo sucede con el citoplasma, cuando se reduce éste aumenta el riesgo de que el tumor sea maligno.

Para terminar con el análisis de este ejercicio, vamos a analizar si el tamaño de las estructuras de los nucleólos se ve afectado o no por el tamaño de la célula y la mitosis, y si esto significa un mayor riesgo de cáncer o no.

Por lo tanto, analizamos las estructuras de los nucleólos frente al tamaño de las células:
```{r}
plot(df_ejer1[,c("Normal_Nucleoli", "Cell_Size")], col=modelo_ejer1$cluster, main="Tamaño de los nucleólos respecto al tamaño de la célula")
```

Apenas podemos apreciar una relación, vemos que el tamaño de la célula de por sí es muy influyente, es decir, el tamaño de los nucleólos tiene que ser muy elevado con un valor de 9 o 10 para que sea significativo el aumento en esta variable, ya que para valores más pequeños presentamos prácticamente la misma relación respecto al tamaño de la célula.

El otro aspecto a analizar es si la estructura de los nucleólos se ve afectado por el proceso de mitosis:
```{r}
plot(df_ejer1[,c("Normal_Nucleoli", "Mitoses")], col=modelo_ejer1$cluster, main="Tamaño de los nucleólos respecto a la mitosis")
```

En este caso, aunque en la primera parte de la práctica veíamos una ligera correlación, al analizar los grupos vemos que no hay relación, es decir, el cáncer no se ve afectado por la mitosis, sin embargo, sí que presentamos un mayor riesgo cuando el tamaño de los nucleólos es mayor.

#### Resumen

El primer análisis que hemos hecho ha sido respecto al grosor de la célula, y hemos visto que en cuanto al tamaño de la célula tener un grosor mayor no implicaba un tamaño mayor y por lo tanto no podíamos garantizar que fuera cáncer, es decir, influía más en el cáncer el tamaño de la célula que el grosor en sí mismo. También hemos analizado el grosor respecto a la capacidad de separarse la células, y hemos visto  que sí que hay relación, a mayor grosor más se separan las células unas de otras y esto supone cáncer. Finalmente, se ha estudiado el cómo afectaba el grosor a si las células tenían citoplasma o no, y hemos visto que también está relacionado, es decir, a mayor grosor las células tienen menos citoplasma o no tienen y esto supone que el tumor sea maligno.

El segundo análisis ha sido respecto al tamaño de la célula, hemos estudiado si la forma de la misma se veía afectada por el tamaño y hemos visto que sí, a mayor tamaño mayor forma y mayor riesgo de cáncer. Después hemos comprobado si el tamaño de las células epiteliales se veían afectadas, y hemos visto que no del todo, es verdad que a mayor tamaño mayor riesgo de cáncer, pero si el tamaño de las células epiteliales es elevado y tamaño de las células "normales" es pequeño podemos garantizar que es un tumor benigno. Finalmente, hemos comprobado que la textura del núcleo se ve afectada por el tamaño, ya que el núcleo es más tosco y esto supone un mayor riesgo de un tumor maligno.

El siguente análisis ha sido el tamaño de las células epiteliales, hemos estudiado si el tamaño de los nucleólos estaba relacionado, y hemos visto que sí pero de una forma muy ligera, es decir, no podíamos garantizar al 100% de que hubiera riesgo de cáncer si aumentaba el tamaño de la estructura de los nucleólos. Por otro lado, hemos analaizado el proceso de mitosis según el tamaño de las células epiteliales, y en este caso hemos visto que no había relación, por tanto no podíamos garantizar que al tener un mayor o menor proceso de mitosis hubiera un peligro en si el tumor era benigno o no.

El cuarto análisis ha sido el citoplasma presente en las células, hemos comprobado si la forma de la célula afectaba al citoplasma y hemos visto que sí, que cuando aumenta la forma de la célula, ésta va adquiriendo las características de las células cancerígenas, y por tanto reduce el citoplasma de las misma. También hemos estudiado la capacidad de separación de estas células, y también están relacionadas, es decir, cuando el citoplasma es menor la célula tiende a separarse más unas de otras, lo que origina el cáncer. Finalemnte, hemos analizado si afectaba la textura del núcleo, y hemos comprobado que no hay una relación muy fuerte entre a menor citoplasma que los núcleos sean más toscos.

El último análisis ha sido el tamaño de los nucleólos, hemos comprobado si se veía afectado por el tamaño de las células, y hemos apreciado que apenas hay una relación, es decir, un mayor tamaño de la célula implica ya de por sí un mayor riesgo de cáncer, sin embargo, para que el nucleólo sea significativo éste tiene que tener un tamaño grande respecto al tamaño de la célula. También hemos estudiado si se veía afectado por la mitosis, hemos comprobado que no, no había relación.

## Ejercicio 2

## Ejercicio 3

En este caso se nos pide identificar si tiene sentido un modelo de generación de reglas de asociación y de ser casi afirmativo crear el proceso y explicar los resultados.

### Identificación del problema

En nuestro caso sí que tiene sentido aplicar un método de generación de reglas asociadas. Recapitulando, tenemos un dataset sobre el cáncer de mamá, en él hay variables como el tamaño de las células, su forma, si hay citoplasma o no dentro de la célula... Todas estas variables nos permiten saber si el tumor que estamos analizando es benigno o maligno, en otras palabras, si es cáncer o no.

Como vemos, en el dataset tenemos la variable objetivo que es la clase de tumor, cuyo valor es 2 si es benigno o 4 maligno.

Si aplicamos un método que nos permita obtener las reglas de asociación podríamos ver qué condiciones son las más frecuentes para dictaminar si un cáncer es benigno o no, sin entrar a predecir, es decir, con la información que tenemos ver qué variables y qué valores para dichas variables influyen en el cáncer.

Para ponernos en situación podríamos tener una regla del tipo:

- Tamaño de la célula es grande => Cáncer maligno.

La anterior regla la podemos interpretar como, si el tamaño de la célula es grande, ésto suele conllevar que el tumor es maligno. Cabe mencionar que una regla no tiene porque cumplirse siempre, es decir, nos da una idea de lo que puede pasar porque hay más probabilidades, pero esto no significa que tenga que suceder siempre.

Como vemos, nuestro dataset sí que tiene sentido aplicarle reglas de asociación, pero ya no solo para dictaminar si es cáncer o no, sino que también nos puede hacer una idea de cómo se relacionan las variables entre sí, por ejemplo:

- Tamaño de la célula es grande => la forma de la célula es grande.

En este caso nos aporta información de cómo se relacionan las variables entre sí, sin tener que estar relacionadas directamente con saber si es cáncer o no.

Una vez aclarado el sentido de las reglas de asociación, vamos a crear un modelo para obtener aquellas reglas más representativas, cabe destacar que la realización de este ejercicio ha estado basado en un artículo de internet (https://danielredondo.com/posts/20200405_reglas_asociacion/), se ha usado la guía de este artíuclo para resolver el ejercicio.

### Conjunto de datos

Lo primero de todo es que al usar el algoritmo a priori, todas las variables tienen que ser categóricas, en otras palabras factores. Para ello, en la primera parte de la práctica se creó un dataset discretizado, dicho dataset contenía tanto las variables del dataset original más las discretizadas, es por ello que solo nos vamos a quedar con las discretizadas:
```{r}
df_ejer3 = df_discretizado[, c(12:21)]

str(df_ejer3)
```

Puesto que tanto en la práctica uno, como en el comienzo de esta práctica hemos visto que la variable Mitoses no proporciona mucha información sobre el tipo de cáncer, vamos a eliminarla para obtener reglas que realmente sean interesantes:
```{r}
df_ejer3 = df_ejer3[, -c(9)]

str(df_ejer3)
```

Una vez que ya tenemos la información deseada, convertimos el datset al conjunto de tipo transacciones para poder aplicar el método a priori:
```{r}
transacciones_ejer3 = as(df_ejer3, "transactions")
```

Para hacernos una primera idea de qué reglas tiene un soporte (el soporte indica cuantas veces se ha encontrado dicha regla en el dataset) mayor o igual al 50%, mostramos el siguiente gráfico:
```{r}
itemFrequencyPlot(transacciones_ejer3, support = 0.5)
```

Como podemos apreciar, los anteriores items son los más frecuentes en el dataset, es decir, que la adhesión sea alta, que el tamaño de la célula sea pequeño, que la célula sea delgada...

Algo a mencionar en el anterior gráfico es que suele ser frecuente que la clase de tumor sea benigno, esto puedo hacernos una idea de que a lo mejor el dataset original no está del todo balanceado, o que por norma general los tumores son benignos.

### Creación del modelo a priori

Antes de crear el modelo, tenemos que definir dos parámetros fundamentales, uno es el soporte y otro la confianza:

- El soporte nos indica cuantas veces se ha encontrado la regla (lsh => rhs) en el dataset. A mayor soporte más aparece la regla por lo que más evidente es, es decir, mejor.

- La confianza indica la probabilidad de que rhs dependa de lsh. A mayor confianza más relación hay entre lsh y rsh, es decir, mejor.

Una vez aclarado esto vamos a hacer uso del método apriori para obtener las reglas, como no se indica qué parámetros hacer uso vamos a usar para el soporte un 0.1 y para la confianza un 0.8. Se han elegido estos parámetros ya que seon los que usa por defecto el método apriori:
```{r}
reglas = apriori(transacciones_ejer3, parameter = list(support = 0.1, confidence = 0.8))
```

Lo siguiente que vamos a hacer es ordenar la reglas según la confianza, para posteriormente comprobar si hay reglas redundates o no:
```{r}
reglas_ordenadas = sort(reglas, by="confidence")
```

Eliminamos las reglas redundates, es decir, reglas que están incluidas unas dentro de otras:
```{r}
# Comprobamos para cada regla qué elementos son subconjutos
conjunto = is.subset(reglas_ordenadas, reglas_ordenadas)

# Obtenemos las reglas redundantes, es decir, aquellas que están contenidas en 2 o más reglas
reglas_redundates = colSums(conjunto, na.rm = TRUE) >= 2

# Eliminamos las reglas redundantes
reglas_no_redundantes = reglas_ordenadas[!reglas_redundates]
```

Ahora eliminamos las reglas con una confianza igual a 1, este tipo de reglas pueden no proporcionarnos información relevante, ya que son obviedades:
```{r}
reglas_seleccionadas = subset(reglas_no_redundantes, subset = confidence < 1)
```

Otro atributo a destacar es lift, éste nos indica cuanta aleatoriedad hay en cada una de las reglas, un lift de 1 o menor significa que hay aleatoriedad, ésto no nos interesa ya que buscamos reglas que no sean aleatorias, es decir, que realmente estén relacionadas y sean influyentes. Debido a esto, filtramos de nuevo las reglas seleccionadas para un lift mayor que 1:
```{r}
reglas_seleccionadas = subset(reglas_seleccionadas, subset = lift > 1)
```

### Análisis de las reglas

Una vez que ya tenemos las reglas seleccionadas las vamos a analizar las reglas cuando rhs sea la clase del tumor:
```{r}
reglas_clase_tumor = subset(reglas_seleccionadas, subset = rhs %pin% "d-Class")

inspect(head(reglas_clase_tumor))
```

Una vez que hemos usado el algoritmo apriori con un soporte de 0.1 y una confianza del 0.8, y su respectivo filtrado para eliminar aquellas reglas redundates y triviales, llegamos a que los factores más determinantes para dictaminar si un tumor es maligno son los siguientes:

- La forma de la célula, tener una forma grande, es decir, de Clase3 suele implicar que el tumor es maligno, con un nivel de confianza del 98%, es decir, que sí que hay una relación entre ambas variables.

- El tamaño de la célula, tanto si es Grande como si es Mediano significa que prácticamente el tumor es maligno. Si el tamaño es grande obtenemos un nivel de confianza del 98%, mientras que si es mediano del 96%, esto nos lleva a la conclusión de que es más determinante un tamaño grande de célula para un tumor maligno.

- Otro aspecto es la cantidad de citoplasma que hay en la célula, y vemos que si es Ausente, es decir, no hay o apenas hay citplasma, suele indicar que tenemos cáncer.

- El grosor de la célula también está implicito en si el tumor es maligno o no, ya que si el grosor es Grueso es más probable que tengamos un cáncer.

- Finalmente, otro factor determinante es saber si la estructura de los nucleólos es grande tiene a indicarnos que el tumor es maligno.

Otro análisis que podemos hacer es ver qué variables están relacionadas entre sí, independientemente del la clase del tumor:
```{r}
inspect(reglas_seleccionadas)
```

Como vemos de la anterior ejecución, un grosor delgado de la célula lleva implícito que el tamaño de las células epiteliales es pequeño, el tamaño de las células también, la forma de la misma suele ser de Clase1 (forma normal), la estructura de los nucleólos es pequeño, el núcleo tiene una estructura uniforme y sí que presenta citoplasma las células.

Todo lo descrito anteriomente nos indica que el tumor es benigno, es decir, sabemos perfectamente cuando el tumor es benigno o maligno.

### Conclusiones

Las conclusiones obtenidas son las siguientes:

- Cuando hablamos de un tumor maligno, presente características como una forma de la célula mayor, un tamaño de la misma mayor, no hay o apenas hay citoplasma en la célula, suelen tener un grosor mayor, y los nucleólos suelen ser grandes.

- Sin embargo si el tumor es beningno, la forma suele ser menor, el tamaño de la misma también, presentan citoplasma en las células, suelen tener un grosor delgado, el núcleo tiene estructura uniforme y los nucleólos son pequeños.

******
# Criterios de evaluación
******

* Ejercicio 1 (25%)
	- Se genera un modelo no supervisado.
	- Se analizan, muestran y comentan las medidas de calidad del modelo generado.
	- Se comentan las conclusiones.

* Ejercicio 2 (10%)
	- Se genera de nuevo el modelo no supervisado anterior, pero usando una métrica de distancia distinta.
	- Se muestran y comentan las medidas de calidad del modelo generado.
	- Adicionalmente se comparan los dos modelos no supervisados con métricas de distancia distintas.
	- Se comentan las conclusiones. 
	
* Ejercicio 3 (10%)
	- Se representa, analiza y comenta un ejemplo de reglas de asociaciones aplicado al dataset seleccionado, o en su defecto se reformula el problema (mínimo de 250 palabras).
	- Se comentan las conclusiones.

* Ejercicio 4 (25%)
	- Se generan reglas y se comentan e interpretan las más significativas.
	- Extraemos las reglas del modelo en formato texto y gráfico.
	- Adicionalmente se genera matriz de confusión para medir la capacidad predictiva del algoritmo.
	- Se comparan e interpretan los resultados sin y con opciones de poda, explicando las ventajas e inconvenientes del modelo generado respecto a otro método de construcción.
	- Se evalúa la tasa de error en cada nivel de árbol, la eficiencia en clasificación (en las fases de training, validación y test) y la comprensibilidad.
	- Se comentan las conclusiones.

* Ejercicio 5 (10%)
	- Se aplica una mejora con técnica de boosting. 
	- Se detalla, comenta y evalúa la calidad de clasificación.
	- Se comparan y comentan los resultados de manera exhaustiva con el anterior método de construcción.

* Ejercicio 6 (10%)
  - Identifica qué posibles limitaciones tienen los datos que has seleccionado para obtener conclusiones con los modelos (supervisado y no supervisado)
  - Se identifican posibles riesgos del uso del modelo  (mínimo 250 palabras).
  
* Consideración general (10%) 
  - Se presenta el código y es fácilmente reproducible.
  - Se detalla cada pregunta de manera correcta, mostrando el código, comentando como se ha hecho y porque se ha hecho, comparando los resultados y/o indicando otras alternativas al problema indicado.
  - Se muestran las conclusiones en cada apartado
  - Se indican eventuales citaciones bibliográficas, fuentes internas/externas y materiales de investigación.


******
# Recursos de programación
******
* Incluimos en este apartado una lista de recursos de programación para minería de datos donde podréis encontrar ejemplos, ideas e inspiración:
  + [Material adicional del libro: Minería de datos Modelos y Algoritmos](http://oer.uoc.edu/libroMD/)
  + [Espacio de recursos UOC para ciencia de datos](http://datascience.recursos.uoc.edu/es/)
  + [Buscador de código R](https://rseek.org/)  
  + [Colección de cheatsheets en R](https://rstudio.com/resources/cheatsheets/)  
  

******

******






