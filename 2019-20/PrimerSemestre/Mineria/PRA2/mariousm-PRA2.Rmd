---
title: 'Minería de datos: PRA2 - Modelado de un juego de datos'
author: "Autor: Mario Ubierna San Mamés"
date: "Mayo 2021"
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
    includes:
      in_header: 75.584-PEC-header.html
  word_document: default
  pdf_document:
    highlight: zenburn
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
******
# Introducción
******
## Presentación
Esta práctica cubre de forma transversal la asignatura.

Las Prácticas 1 y 2 de la asignatura se plantean de una forma conjunta de modo que la Práctica 2 será continuación de la 1.

El objetivo global de la **Práctica 2** es de extraer conocimientos y de comparar las diferentes soluciones aplicando todo lo aprendido mediante los algoritmos de clustering, asociación y clasificación.

## Competencias
Las competencias que se trabajan en esta prueba son:  

* Uso y aplicación de las TIC en el ámbito académico y profesional.
* Capacidad para innovar y generar nuevas ideas.
* Capacidad para evaluar soluciones tecnológicas y elaborar propuestas de proyectos teniendo en cuenta los recursos, las alternativas disponibles y las condiciones de mercado.
* Conocer las tecnologías de comunicaciones actuales y emergentes así como saberlas aplicar convenientemente para diseñar y desarrollar soluciones basadas en sistemas y tecnologías de la información.
* Aplicación de las técnicas específicas de ingeniería del software en las diferentes etapas del ciclo de vida de un proyecto.
* Capacidad para aplicar las técnicas específicas de tratamiento, almacenamiento y administración de datos.
* Capacidad para proponer y evaluar diferentes alternativas tecnológicas para resolver un problema concreto.

## Objetivos
La correcta asimilación de todos los aspectos trabajados durante el semestre.  
En esta práctica abordamos un caso real de minería de datos donde tenemos que poner en juego todos los conceptos trabajados.
Hay que trabajar todo el ciclo de vida del proyecto. Desde el objetivo del proyecto hasta la implementación del conocimiento encontrado pasando por la preparación, limpieza de los datos, conocimiento de los datos, generación del modelo, interpretación y evaluación.

## Descripción de la PRA a realizar
La práctica consta de ejercicios en los cuales el estudiante aplicará algunos de los métodos supervisados y no supervisados aprendidos durante el semestre.

## Recursos Básicos
Material docente proporcionado por la UOC. 

## Criterios de valoración

**Ejercicios prácticos** 

Para todas las PRA es necesario documentar en cada apartado del ejercicio práctico que se ha hecho y como se ha hecho.

## Formato y fecha de entrega
El formato de entrega es: **usernameestudiante-PRA2** *.Rmd* y el **output generado** en uno de estos formatos *html/doc/docx/odt/pdf*.

Fecha de entrega: **16/06/2021**  

Se debe entregar la PRA en el buzón de entregas del aula en formato comprimido que incluye los ficheros:
- ejecutable
- output
- el dataset seleccionado o en su defecto indicar la ruta para su descarga en el ejecutable.  

## Nota: Propiedad intelectual 

> A menudo es inevitable, al producir una obra multimedia, hacer uso de recursos creados por terceras personas. Es por lo tanto comprensible hacerlo en el marco de una práctica de los estudios de Informática, Multimedia y Telecomunicación de la UOC, siempre y cuando esto se documente claramente y no suponga plagio en la práctica. 

> Por lo tanto, al presentar una práctica que haga uso de recursos ajenos, se debe presentar junto con ella un documento en que se detallen todos ellos, especificando el nombre de cada recurso, su autor, el lugar donde se obtuvo y su estatus legal: si la obra esta protegida por el copyright o se acoge a alguna otra licencia de uso (Creative Commons, licencia GNU, GPL ...). 
El estudiante deberá asegurarse de que la licencia no impide específicamente su uso en el marco de la práctica. En caso de no encontrar la información correspondiente tendrá que asumir que la obra esta protegida por copyright. 

> Deberéis, además, adjuntar los ficheros originales cuando las obras utilizadas sean digitales, y su código fuente si corresponde.  

******
# Enunciado
******
Como continuación del estudio iniciado en la práctica 1, procedemos en **aplicar modelos analíticos** sobre el juego de datos seleccionado y preparado.  En esta práctica 2 se aconseja de adjuntar los “chunks” de la parte de preparación previa, ejemplo (limpieza, discretización, normalización, PCA/SVD etc.), o en su defecto cargar solo los datos ya preparadados.

De este modo se pide al estudiante que complete los siguientes pasos:

1. Aplicar un modelo **no supervisado** y basado en el concepto de distancia, sobre el juego de datos.

2. Aplicar de nuevo el modelo anterior, pero usando una **métrica distinta** y comparar los resultados.

3. Razonar si tiene sentido aplicar al dataset seleccionado, un método de **generación de reglas de asociaciones**. En caso afirmativo, realizar tal proceso y explicar los resultados. En caso contrario, reformula el problema para que sí lo tenga.

4. Aplicar un modelo de generación de reglas a partir de **árboles de decisión** sin y con opciones de poda y comparar los resultados.

5. Aplicar una mejora con **técnicas de boosting** y comparar el resultado con el anterior.
	
6. Identificar eventuales **limitaciones** del dataset seleccionado y **analizar los riesgos** para el caso de uso.

7. (Punto común para todos los ejercicios) - 
En todos los puntos anteriores se pide al estudiante, además de aplicar los diferentes métodos, de analizar correctamente el problema, **detallar de manera exhaustiva** resaltando el porque y como se ha realizado, incluyendo elementos visuales, explicando los resultados, realizar las comparativas oportunas con sus conclusiones.


******
# Solución
******

## Librerías

En este apartado adjuntamos todas las cargas de librerías necesarias para la resolución de la práctica:
```{r}
library(scales)
library(cluster)
```

## Resumen del dataset

El dataset elegido para dar respuestas a las preguntas que nos hemos hecho en la práctica uno es el de Breast Cancer Wisconsin (Original) Data Set de Machine Learning Repository [https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Original%29]

Hemos elegido dicho dataset porque nos proporciona toda la información necesaria, a partir de datos como el tamaño de la célula, la forma de la célula...

Es verdad que hay datasets similares a este pero con más atributos, es decir, aquí solo tenemos un campo para el tamaño de la célula, mientras que en otros datasets ese campo podía venir representado por tres atributos, pero este dataset consigue mantener la misma información reduciendo ya la dimensionalidad de los atributos. Por otro lado, los valores numéricos en este conjunto de datos van del 1 al 10, es decir, [1-10], estos valores no son aleatorios sino que un grupo de expertos ha "normalizado" dichos valores para representar la misma información pero de una forma más sencilla.

Finalmente, a continuación se indica los atributos que tiene este dataset:

**Id**
    integer - identificador de la observación.
    
**Thickness**
    integer [1-10] - espesor/grosor del tumor.
    
**Cell_Size**
    integer [1-10] - uniformidad del tamaño celular.
    
**Cell_Shape**
    integer [1-10] - uniformidad de la forma celular.
    
**Adhesion**
    integer [1-10] - adherencia celular.
    
**Epithelial_Cell_Size**
    integer [1-10] - tamaño de una sola célula epitelial.
    
**Bare_Nuclei**
    integer [1-10] - núcleo desnudo.
    
**Bland_Chromatin**
    integer [1-10] - textura del núcleo.
    
**Normal_Nucleoli**
    integer [1-10] - nucléolos normales.
    
**Mitoses**
    integer [1-10] - mitosis.
    
**Class**
    integer - clase si es beningno 2, si es maligno 4.
    
Aunque algun concepto es fácil de entender los demás no, es por ello que vamos a definir cada concepto:

- Thickness: hace referencia al espesor/grosor de la masa mamaria que se estudia, es decir, del tumor.

- Cell_Size: tamaño de las células que se estudian, las células cancerígenas suelen cambiar de tamaño.

- Cell_Shape: forma de las células que se estudian, las células cancerígenas suelen cambiar de forma.

- Adhesion: las células que son cancerígenas tienden a separarse unas de las otras, mientras que en las células normales sucede todo lo contrario.

- Epithelial_Cell_Size: las células que son significativamente grandes suelen ser cancerígenas.

- Bare_Nuclei: nos indica si el núcleo de las células está rodeado por el citoplasma (células normales), en caso contrario es probable que sean células cancerígenas.

- Bland_Chromatin: textura de los núcleos de las células, cuanto más tosco sea más probabiliades de que la célula sea cancerígena.

- Normal_Nucleoli: los nucleólos son pequeñas estructuras que se encuentran en los núcleos, en células benignas suelen ser estructuras pequeñas mientras que en las malignas son más grandes.

- Mitoses: proceso en el cual las células eucariotas se dividen.

Toda esta información se ha obtenido de la siguiente página [https://core.ac.uk/download/pdf/77274625.pdf], cabe destacar que a mayor valor de cada atributo más probable es que la célula sea anormal y dentro de esta anormalidad sea cancerígena.

Por último, tenemos 699 observaciones y 11 atributos en el dataset original, pero se han creado tambien el dataset normalizado con 699 observaciones y 11 atributos, y el discretizado con 699 observaciones y 21 variables.

## Preparación de los datos

En este primer apartado vamos a preparar el conjunto de datos para así poder aplicar modelos analíticos. Cabe destacar que esta limpieza ya se hizo en la práctica uno, por lo que vamos a adjuntar el código necesario para generar el dataset final sin entrar en la explicación del mismo ni en el análisis de los datos.

```{r}
# CARGAMOS
df = read.table(file="./data/breast-cancer-wisconsin.data", fileEncoding="UTF-8", sep=",", na.strings = "NA")

# Cambiamos el nombre de las columnas tal y como se llaman según la página web
colnames(df) = c("Id", "Thickness", "Cell_Size", "Cell_Shape", "Adhesion", "Epithelial_Cell_Size", "Bare_Nuclei", "Bland_Chromatin", "Normal_Nucleoli", "Mitoses", "Class")

# Creamos una copia del dataframe, ya que va a ser la copia sobre la que vamos a realizar las modificaciones
df_copy = df

# IMPUTAMOS
df_copy[df_copy$Bare_Nuclei == "?", "Bare_Nuclei"] = NA
df_copy$Bare_Nuclei = as.integer(df_copy$Bare_Nuclei)

nMediana = median(df_copy$Bare_Nuclei, na.rm = TRUE)
df_copy$Bare_Nuclei[is.na(df_copy$Bare_Nuclei)] = nMediana

# nORMALIZAMOS
df_normalizado = scale(df_copy)

# Generamos el dataset normalizado
write.csv(df_normalizado, file = "./data/breast-cancer-clean-normalized.csv", row.names = FALSE)

# DISCRETIZAMOS

df_discretizado = df_copy

# Dicretización del grosor
df_discretizado["d-Thickness"] = ordered(cut(df_discretizado[["Thickness"]], breaks = c(0,4,7,10), labels = c("Delgado", "Mediano", "Grueso")))

# Dicretización del tamaño
df_discretizado["d-Cell_Size"] = ordered(cut(df_discretizado[["Cell_Size"]], breaks = c(0,4,7,10), labels = c("Pequeño", "Mediano", "Grande")))

# Dicretización del forma
df_discretizado["d-Cell_Shape"] = ordered(cut(df_discretizado[["Cell_Shape"]], breaks = c(0,4,7,10), labels = c("Clase1", "Clase2", "Clase3")))

# Dicretización a la adhesión marginal
df_discretizado["d-Adhesion"] = factor(cut(df_discretizado[["Adhesion"]], breaks = c(0,5,10), labels = c("Alta", "Baja")))

# Dicretización del tamaño de las células epiteliales
df_discretizado["d-Epithelial_Cell_Size"] = ordered(cut(df_discretizado[["Epithelial_Cell_Size"]], breaks = c(0,4,7,10), labels = c("Pequeño", "Mediano", "Grande")))

# Dicretización los núcleos desnudos
df_discretizado["d-Bare_Nuclei"] = factor(cut(df_discretizado[["Bare_Nuclei"]], breaks = c(0,4,7,10), labels = c("Presente", "Presente/Ausente", "Ausente")))

# Dicretización de la textura de la núcleos
df_discretizado["d-Bland_Chromatin"] = factor(cut(df_discretizado[["Bland_Chromatin"]], breaks = c(0,4,7,10), labels = c("Uniforme", "Uniforme/Burda", "Burda")))

# Dicretización de la estructoras de los nucleólis
df_discretizado["d-Normal_Nucleoli"] = ordered(cut(df_discretizado[["Normal_Nucleoli"]], breaks = c(0,4,7,10), labels = c("Pequeño", "Mediano", "Grande")))

# Dicretización de la mitosis
df_discretizado["d-Mitoses"] = ordered(cut(df_discretizado[["Mitoses"]], breaks = c(0,4,7,10), labels = c("Mitosis1", "Mitosis2", "Mitosis3")))

# Creamos una columna respecto a la clase, aunque no es discretización como tal, es más fácil ver si un cáncer es benigno respecto a su nombre que no respecto a su valor.
df_discretizado$`d-Class`[df_discretizado$Class == 2] = "Benigno" 
df_discretizado$`d-Class`[df_discretizado$Class == 4] = "Maligno"
df_discretizado$`d-Class` = as.factor(df_discretizado$`d-Class`)

# Generamos el dataset discretizado
write.csv(df_discretizado, file = "./data/breast-cancer-clean-discretized.csv", row.names = FALSE)

```

## Ejercicio 1

En este primer apartado lo que buscamos es aplicar un algoritmo de aprendizaje no supervisado para saber el cómo se agrupa el cáncer, es decir, aunque en nuestro dataset tenemos etiquetadas para cada observación si es cáncer o no, vamos a ignorar este hecho y se va a aplicar un algoritmo de clustering para saber qué hace de especial a los grupos identificados.

### Generación del modelo

Lo primero de todo es observar el dataframe que vamos a usar para este ejercicio:

```{r}
str(df_copy)
```

En este caso, vemos que tenemos información innecesaria ya que los atributos ID y Class no hacen falta, el primero porque sirve para identificar en exclusiva un punto y en este caso no queremos analizar un punto buscamos el análisis de un grupo, y el segundo nos indica el grupo en sí ya que el dataset original estaba pensado para un problema de clasificación, nosotros queremos descubrir qué observaciones representan el cáncer si necesidad de indicarle al algorítmo cuáles son cáncer y cuáles no.

Debido a lo comentado en el párrafo anterior, eliminamos dichas variables:
```{r}
df_ejer1 = df_copy[,2:10]
str(df_ejer1)
```

Comprobamos que tenemos la información correcta. El siguiente paso es hacer un breve análisis de dichos datos:
```{r}
summary(df_ejer1)
```

Como podemos observar todas las variables están acotadas entre los valores 1 y 10, esto se debe a que un grupo experto "normalizó" el dataset con dichos valores.

El significado de este dataset para una variable en específico sería el siguiente, si estudiamos el tamaño de la célula (Cell_Size), a mayor valor más riesgo de que sea un cáncer maligno.

Si se necestia más información sobre el significado de las variables, análisis de las mismas, análisis del dataset en general, se puede hacer la lectura de la práctica uno.

Una vez que tenemos todo preparado podemos generar el modelo de clustering, pero antes debemos hacer una explicación de los grupos que vamos a indicar al algortimo kmeans.

Por norma general, cuando tenemos un problema de clustering que buscamos resolver a partir de la minería de datos, se realiza un estudio sobre cuántos grupos son los ideales para dicho problema, esto tiene toda la lógica ya que a priori desconocemos los mismos, pero en nuestro caso estamos analizando si los datos sobre las células son sobre células benignas o malignas, es decir, desde un principio ya sabemos que los grupos van a ser dos, o tenemos cáncer o no lo tenemos. Por lo tanto, podríamos crear el modelo directamente con los dos grupos, pero por mera curiosidad, vamos a realizar el estudio de grupos para ver cuántos serían lo ideal (aunque sabemos que solo podemos tener dos).

Vamos a calcular el número de clústers ideales para poder realizar nuestro modelo, cabe destacar que calculamos el valor de la silueta x veces para cada modelo, esto es así porque dicho valor cambia todo el rato, al calcularlo x veces podemos hacer una media y que los “mejores clusters” se mantengan independientemente de las veces que se ejecute:
```{r}
kmeans_silhouette = function(df, minCluster = 2, maxCluster = 10, maxIterations = 10) {
  
  if (minCluster <= maxCluster & minCluster > 1) {
    resultados = rep(0, maxCluster)
    
    for (i in c(minCluster:maxCluster)) {
      resultado = rep(0, maxIterations)
      
      for (j in c(1:maxIterations)) {
        fit = kmeans(df, i)
        y_cluster = fit$cluster
        sk = silhouette(y_cluster, daisy(df))
      
        # Como el valor de la silueta puede cambiar de una iteración a otra, calculamos su valor medio
        resultado[j] = mean(sk[,3])
      }
      resultados[i] = mean(resultado)
    }
    return(resultados)
    
  } else {
    print("ERROR: minCluster debe ser menor que maxCluster y mayor que 1")
  }
}
```

Ejecutamos la función anterior, indicándole que el número de grupos mínimo es 2, el máximo 10 y se va a ejecutar 50 veces para cada modelo:
```{r}
minCluster = 2
maxCluster = 10
maxIterations = 50

mean_silhouette = kmeans_silhouette(df_ejer1, minCluster, maxCluster, maxIterations)

plot(minCluster:maxCluster, mean_silhouette[minCluster:maxCluster],type="o",col="blue",pch=0,xlab="Número de clusters",ylab="Silueta")
```

Como podemos apreciar en el anterior gráfico, el número de clústers ideal es cuando tenemos dos grupos, lo cual vemos que coincide con nuestro problema real, es decir, tenemos el grupo de si el tumor es benigno o no.

Por lo tanto, vamos a crear el modelo con dos grupos:
```{r}
set.seed(0)

modelo_ejer1 = kmeans(df_ejer1, 2)
```

### Análisis y muestra de las medidas del modelo generado



******
# Criterios de evaluación
******

* Ejercicio 1 (25%)
	- Se genera un modelo no supervisado.
	- Se analizan, muestran y comentan las medidas de calidad del modelo generado.
	- Se comentan las conclusiones.

* Ejercicio 2 (10%)
	- Se genera de nuevo el modelo no supervisado anterior, pero usando una métrica de distancia distinta.
	- Se muestran y comentan las medidas de calidad del modelo generado.
	- Adicionalmente se comparan los dos modelos no supervisados con métricas de distancia distintas.
	- Se comentan las conclusiones. 
	
* Ejercicio 3 (10%)
	- Se representa, analiza y comenta un ejemplo de reglas de asociaciones aplicado al dataset seleccionado, o en su defecto se reformula el problema (mínimo de 250 palabras).
	- Se comentan las conclusiones.

* Ejercicio 4 (25%)
	- Se generan reglas y se comentan e interpretan las más significativas.
	- Extraemos las reglas del modelo en formato texto y gráfico.
	- Adicionalmente se genera matriz de confusión para medir la capacidad predictiva del algoritmo.
	- Se comparan e interpretan los resultados sin y con opciones de poda, explicando las ventajas e inconvenientes del modelo generado respecto a otro método de construcción.
	- Se evalúa la tasa de error en cada nivel de árbol, la eficiencia en clasificación (en las fases de training, validación y test) y la comprensibilidad.
	- Se comentan las conclusiones.

* Ejercicio 5 (10%)
	- Se aplica una mejora con técnica de boosting. 
	- Se detalla, comenta y evalúa la calidad de clasificación.
	- Se comparan y comentan los resultados de manera exhaustiva con el anterior método de construcción.

* Ejercicio 6 (10%)
  - Identifica qué posibles limitaciones tienen los datos que has seleccionado para obtener conclusiones con los modelos (supervisado y no supervisado)
  - Se identifican posibles riesgos del uso del modelo  (mínimo 250 palabras).
  
* Consideración general (10%) 
  - Se presenta el código y es fácilmente reproducible.
  - Se detalla cada pregunta de manera correcta, mostrando el código, comentando como se ha hecho y porque se ha hecho, comparando los resultados y/o indicando otras alternativas al problema indicado.
  - Se muestran las conclusiones en cada apartado
  - Se indican eventuales citaciones bibliográficas, fuentes internas/externas y materiales de investigación.


******
# Recursos de programación
******
* Incluimos en este apartado una lista de recursos de programación para minería de datos donde podréis encontrar ejemplos, ideas e inspiración:
  + [Material adicional del libro: Minería de datos Modelos y Algoritmos](http://oer.uoc.edu/libroMD/)
  + [Espacio de recursos UOC para ciencia de datos](http://datascience.recursos.uoc.edu/es/)
  + [Buscador de código R](https://rseek.org/)  
  + [Colección de cheatsheets en R](https://rstudio.com/resources/cheatsheets/)  
  

******

******






