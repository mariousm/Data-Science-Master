---
title: "A2 - Analítica descriptiva e inferencial"
author: "Mario Ubierna San Mamés"
date: '`r format(Sys.Date(),"%e de %B, %Y")`'
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Lectura del fichero

Leer el fichero fifa_clean.csv. Validar que los datos leídos son correctos. Si no es así, realizar las conversiones
oportunas.

Lo primero que debemos realizar es la carga del fichero y visualizamos que se ha cargado:
```{r}
df = read.csv(file = "./data/fifa_clean.csv", sep = ",", stringsAsFactors = TRUE)

head(df)
```
A priori los datos se han cargado correctamene, pero vamos a comprobar si cada variable tiene el tipo de variable correcto:
```{r}
str(df)
```

Tal y como podemos apreciar, prácticamente todas las variables tienen su tipo de variable correcto, pero hay un par de excepciones, tanto la variable Club_Joining como Birth_Date son variables de tipo Date y las ha categorizado como Factor, por lo que vamos a hacer dicha transformación:
```{r}
df_copy = df # Creamos una copia del dataframe

df_copy$Club_Joining = as.Date(df_copy$Club_Joining, format = "%m/%d/%Y")
df_copy$Birth_Date = as.Date(df_copy$Birth_Date, format = "%m/%d/%Y")
```

Comprobamos que se han realizado los cambios de forma correcta:
```{r}
str(df_copy$Club_Joining)
str(df_copy$Birth_Date)
```

# Rating de los jugadores

Nos interesa investigar los valores que toma la variable Rating en la población. Para ello, realizad un primer
análisis visual de esta variable a partir de la muestra. Posteriormente, calculad el intervalo de confianza de la
variable Rating de los jugadores. Seguid los pasos que se indican a continuación.

## Análisis visual

Mostrad visualmente la distribución de la variable Rating. Usad el gráfico o gráficos que creáis más oportunos.
Describid brevemente lo que se observa en los gráficos que representáis.

En el siguiente gráfico podemos ver el cómo es la distribución del rating:
```{r}
library(ggplot2) # Importamos la librería ggplot2

ggplot(mapping = aes(x=df_copy$Rating)) + geom_density()
```

Tal y como podemos apreciar, la distribución parace seguir una distribución normal, lógicamente no es una distribución perfecta pero si tenemos en mente la distribución normal estándar se asemeja. Este primer gráfico nos permite hacernos una idea de cómo es la distribución, dónde puede estar la media, si hay más datos a la izquierda de la función o a la derecha...

Para ser más técnicos podríamos hacer un diagrama boxplot:
```{r}
boxplot(x = df_copy$Rating,
        main = "Raiting de los jugadores",
        ylab = "Valor de Rating"
        )
```

Este tipo de gráficos nos proporciona mucha información:

- Podemos ver que la mediana está entorno al 66, lo cual nos indica que por norma general los jugadores profesionales recogidos en el FIFA tienen una calidad media-baja.

- Nos da información sobre el primer cuartil, es decir, el punto en el que el 25% de los datos está por debajo a ese valor, el valor de este cuartil es entorno a 63.

- Apreciamos el tercer cuartil, el punto en el que el 75% de los datos son menores o iguales a ese valor, este valor es más o menos 71.

- Con el primer y tercer cuartil sacamos el rango intercuartílico, en este caso, podemos ver que es pequeño dicho rango lo que nos da a entender que muchos de los datos, para ser más exactos el 50%, se mueven entre 63 y 71, es decir, los jugadores de media son regulares.

- También observamos tanto el límite inferior como superior, gracias a ellos podemos identificar outliers, valores fuera de lo común, y vemos que esto tiene un significado positivo y negativo al mismo tiempo, ya que hay jugadores muy malos  (aunque son pocos) y jugadores muy buenos.

## Intervalo de confianza

Calculad el intervalo de confianza de la variable Rating. A continuación, explicad el resultado y cómo se debe
interpretar el resultado obtenido.

Nota: Los cálculos se deben realizar manualmente. No se pueden usar funciones de R que calculen directamente
el intervalo de confianza. En cambio, sí se pueden usar funciones como mean, sd, qnorm, pnorm, qt y pt

Al realizar este ejercicio no se nos proporciona la varianza poblacional por lo que tenemos que calcular la varianza o la desviación de la muestra, esto lógicamente supone más incertidumbre ya que calculamos la desviación a partir de la muestra no de la población, es por ello que se recomienda hacer el cálculo a partir de la distribución t-student.

Aunque podríamos aplicar el teorema del límite central, asumiendo que al calcular la media de la muestra y tener una muestra lo suficientemente grande seguimos una distribución normal, vamos a realizar los cálculos como si el teorema del límite central no existiera. 

Por otro lado, consideramos que el nivel de confianza es del 95%. Para calcular el intervalo de confianza, primero calculamos el alfa (nivel de significancia), junto con la desviación de la muestra y el tamaño de la muestra:
```{r}
alfa = 1 - 0.95
tam_muestra = length(df_copy$Rating)
desviacion = sd(df_copy$Rating)
```

Una vez tenemos los valores anteriores, calculamos el estadístico y el valor z para esta distribución:
```{r}
estadistico = desviacion / sqrt(tam_muestra)
z = qt(alfa/2, tam_muestra - 1, lower.tail = FALSE)
```

Finalmente, calculamos el límite inferior y superior:
```{r}
lim_inferior = round(mean(df_copy$Rating) - (z * estadistico), 2)
lim_superior = round(mean(df_copy$Rating) + (z * estadistico), 2)

cat("El límite inferior del intervalo de confianza (L) es igual a: ", lim_inferior)
cat("El límite superior del intervalo de confianza (U) es igual a: ", lim_superior)
```

Tal y como podemos apreciar en la anterior ejecución tenemos el siguiente intervalo de confianza [66.06, 66.27]. Cuando calculamos el intervalo de confianza no podemos afirmar que cualquier valor de la población esté dentro del intervalo, lo que conseguimos establecer al calcular el intervalo de confianza es asegurarnos, en nuestro caso a un 95%, del procedimiento, es decir, que el nivel de confianza en el procedimiento de cualquier muestra esté garantizado dando lugar a un intervalo que contenga el valor. 

En resumen, de lo que nos garantizamos es que el 95% de los intervalos de confianza calculados a partir de cada meustra contengan el valor medio del rating.

# Diferencias entre jugadores

Existe una creencia que los jugadores zurdos tienen mejor control de la pelota que los diestros. Vamos a
comprobar qué dicen los datos al respecto. Nos preguntamos si los jugadores zurdos tienen mejor control
de pelota (Ball_Control), valoración (Rating) y mejor Dribbling que los diestros. Para ello, primero
seleccionad los jugadores que no son porteros (los porteros tienen el valor GK -Goal Keeper- en Club_Position).
Entonces, debéis obtener dos muestras. La primera muestra contiene todos los jugadores de campo (no
porteros) zurdos (Preffered_Foot igual a Left). La segunda muestra contiene todos los jugadores de campo
(no porteros) diestros (Preffered_Foot Right). Usad un nivel de confianza del 95 %.

## Pregunta de investigación

Formulad la/s pregunta/s de investigación que se plantea/n en este apartado.

En este ejercicio nos podemos hacer tres preguntas:

- ¿El control de la pelota de los jugadores zurdos es mejor que el control de pelota de los jugadores diestros?

- ¿La valoración de los jugadores zurdos es mejor que la valoración de los jugadores diestros?

- ¿El dribbling de los jugadores zurdos es mejor que el dribbling de los jugadores diestros?

## Representación visual

Representad visualmente, mediante el gráfico que sea más apropiado el valor de estas variables en jugadores
de campo (no porteros) diestros y zurdos. Se deben mostrar los valores de forma comparativa entre zurdos y
diestros. Interpretad los gráficos.

Antes de visualizar los datos entre zurdos y diestros, tenemos que quedarnos con los jugadores de campo que no son porteros, y vamos a crear dos dataframes uno para los zurdos y otro para los diestros :
```{r}
df_copy_players = df_copy[df_copy$Club_Position != "GK",]
df_copy_players_left = df_copy_players[df_copy_players$Preffered_Foot == "Left",]
df_copy_players_right = df_copy_players[df_copy_players$Preffered_Foot == "Right",]
```

Una vez que ya tenemos filtrado los jugadores de campo, vamos a mostrar una visualización por cada variable a analizar (Ball_control, Rating, Dribbling).

Analizamos la variable Ball_Control respecto a zurdos y diestros:
```{r}
boxplot(df_copy_players_left$Ball_Control, 
        df_copy_players_right$Ball_Control, 
        main = "Control de balón de zurdos respecto a diestros",
        xlab = "Zurdos - Diestros",
        ylab = "Valor de Ball_Control"
        )
```

Tal y como podemos apreciar en la anterior gráfica la mediana de los jugadores zurdos es un poco más alta que la de diestros, además el primer cuartil de los zurdos es mayor que el de los diestros (esto significa que el 25% de los datos ordenados de menor a mayor tienen un mejor control de balón los zurdos respecto a los diestros).

Por otro lado, el nivel mínimo de los zurdos es algo mayor, por lo que a priori son menos malos, aunque el nivel máximo es un poco menor respecto a los diestros.

En resumen, dado el control de balón a priori podemos ver que la calidad media de los jugadores zurdos es un poco mejor, pero esto lo tendremos que confirmar con el contraste de hipóstesis.

Analizamos la variable Rating respecto a zurdos y diestros:
```{r}
boxplot(df_copy_players_left$Rating, 
        df_copy_players_right$Rating, 
        main = "Rating de zurdos respecto a diestros",
        xlab = "Zurdos - Diestros",
        ylab = "Valor de Rating"
        )
```

Al igual que sucedía en el gráfico anterior, la mediana de los zurdos es un poco mayor respecto a la de diestros. Su primer cuartil también es algo mayor junto con el nivel mínimo.

A primera vista sucede lo mismo que en el anterior gráfico, la calidad media del rating de los zurdos respecto a los diestros es algo mayor, pero tendremos que hacer un contraste de hipótisis para ver si es significativa dicha diferencia o no.

Analizamos la variable Dribbling respecto a zurdos y diestros:
```{r}
boxplot(df_copy_players_left$Dribbling, 
        df_copy_players_right$Dribbling, 
        main = "Dribbling de zurdos respecto a diestros",
        xlab = "Zurdos - Diestros",
        ylab = "Valor de Dribbling"
        )
```

De los tres gráficos analizados, este es el más representativo. Hay más diferencia entre la mediana de los zurdos respecto a los diestros y también en su primer cuartil. Además, de que el nivel mínimo de los zurdos es muchísimo mayor que el de diestros.

Por lo tanto, a priori sí que parece que respecto al dribbling los zurdos son mejores que los diestros, pero lo tenemos que analizar más detenidamente.

En resumen, en las tres variables que hemos analizado hay una ventaja en que los zurdos son mejores que los diestros, pero esto lo que vamos a comprobar a continuación, si es verdad o no.

## Hipótesis nula y alternativa

Escribid la/s hipótesis nula/s y la/s hipótesis alternativa/s.

En este ejercicio se plantean tres preguntas, por lo que vamos a tener tres hipótesis nulas y tres hipótesis alternativas.

Respecto al control del balón presentamos las siguientes hipótesis:

- H0 (hipótesis nula): Ball_Control de zurdos = Ball_Control de diestros.

- H1 (hipótesis alternativa): Ball_Control de zurdos > Ball_Control de diestros.

Respecto al rating presentamos las siguientes hipótesis:

- H0 (hipótesis nula): Rating de zurdos = Rating de diestros.

- H1 (hipótesis alternativa): Rating de zurdos > Rating de diestros.

Respecto al dribbling presentamos las siguientes hipótesis:

- H0 (hipótesis nula): Dribbling de zurdos = Dribbling de diestros.

- H1 (hipótesis alternativa): Dribbling de zurdos > Dribbling de diestros.

## Método

En función de las características de la muestra, decidid qué método aplicar para validar la hipótesis planteada.
Para ello, debéis especificar como mínimo: a) si es un contraste de una muestra o de dos muestras (en caso
de dos muestras, si éstas son independientes o están relacionadas), b) si podéis asumir normalidad y por
qué, c) si el test es paramétrico o no paramétrico, d) si el test es bilateral o unilateral, e) si se puede asumir
homocedasticidad o heterocedasticidad.

Justificad vuestras elecciones.

En este problema tenemos tres hipótesis planteadas, y todas ellas son iguales:

- El contraste son de dos muestras, es decir, por un lado tenemos la muestra de zurdos y por otro lado tenemos la muestra de diestros. Estas muestras son independientes ya que no hay una relación entre muestras, es decir, no hay un hermano diestro para cada zurdo por ejemplo, no tenemos una relación para poder asociar a los elementos de cada muestra.

- Sí que podríamos asumir normalidad, para asumir normalidad podemos aplicar el teorema del límite central, el cual nos indica que la media de una muestra que sea lo suficientemente grande (mayor de 30 observaciones) sigue una distribución normal. Al poder calcular la media de ambas muestras esto lo cumplimos, solo nos hace falta comprobar que tenemos el número de observaciones mínimas, pero tal y como vemos a continuación esto también se cumple:
```{r}
cat("El número de observaciones de zurdos es: ", nrow(df_copy_players_left))
cat("El número de observaciones de diestros es: ", nrow(df_copy_players_right))
```

- El test es paramétrico, esto se debe a que los tests paramétricos son aquellos contrastes que trabajan con la asunción de que los datos siguen una determinada distribución, siendo la más habitual la normalidad de los datos, como bien hemos mencionado en el punto anterior sí que podríamos asumir normalidad de los datos por lo tanto es paramétrico.

- Para saber si el bilateral o unilateral nos podemos fijar en cómo está definida la hipótesis alternativa, en nuestro caso está definida con el símbolo mayor ">", por lo que solo vamos a aceptar la hipótesis alternativa si el valor observado es mayor que el valor crítico, en ese caso rechazaríamos la hipótesis nula. Por lo tanto, este caso se trata de un problema unilateral por la derecha.

- Respecto a si es homocedasticidad o heterocedasticidad hacemos uso de la función var.test y comprobamos si el p-valor es menor que alfa (nivel de signifancia), en nuestro caso si p-valor < alfa (0.05) rechazamos la hipótesis nula siendo ésta que las varianzas son iguales, tal y como podemos ver a continuación en todas las variables el p-valor es menor que alfa, por lo que rechazamos la hipótesis nula, lo cual significa que estamos en un caso de heterocedasticidad: 
```{r}
var.test(df_copy_players_left$Ball_Control, df_copy_players_right$Ball_Control , conf.level = 0.95)
var.test(df_copy_players_left$Rating, df_copy_players_right$Rating, conf.level = 0.95)
var.test(df_copy_players_left$Dribbling, df_copy_players_right$Dribbling, conf.level = 0.95)
```

## Cálculos

Calcular el estadístico de contraste, el valor crítico y el valor p.

Definimos la función que nos va a realizar los cálculos del estadístico de contraste, el valor crítico y el p-valor:
```{r}

muestrasIndependientes_varianzasDesconocidas = function(valores_left, valores_right, alfa) {
  
  # Calculamos el estadístico de contraste
  sd_left = sd(valores_left)
  sd_right = sd(valores_right)
  n_left = length(valores_left) 
  n_right = length(valores_right)
  
  numerador = mean(valores_left) - mean(valores_right)
  denominador = sqrt(((sd_left)^2/n_left) + ((sd_right)^2/n_right))
  
  z_obs = numerador / denominador
  
  # Calculamos los grados de libertad
  numerador = (((sd_left)^2/n_left) + ((sd_right)^2/n_right))^2
  denominador = (((sd_left)^2/n_left)^2 / (n_left - 1)) + (((sd_right)^2/n_right)^2 / (n_right - 1))
  grados_libertad = as.integer(numerador / denominador)
  
  # Calculamos el punto crítico
  z_cri = qt(alfa, df = grados_libertad, lower.tail = FALSE)
  
  # Calculamos el p-valor
  p_value = pt(z_obs, df = grados_libertad, lower.tail = FALSE)
  
  # Devolvemos los valores
  return(data.frame(L = "-INF", U = z_cri, Estadistico_Contraste = z_obs, P_Valor = p_value, Grados_Libertad = grados_libertad))
}
```

Hacemos uso de la función anterior para calcular los campos relativos a la variable Ball_Control:
```{r}
contraste_hipotesis_Ball_Control = muestrasIndependientes_varianzasDesconocidas(df_copy_players_left$Ball_Control, df_copy_players_right$Ball_Control, 0.05)

contraste_hipotesis_Ball_Control
```

```{r}
t.test(df_copy_players_left$Ball_Control,
       df_copy_players_right$Ball_Control,
       alternative="greater", 
       var.equal=FALSE)
```

Realizamos lo mismo para la variable Rating:
```{r}
contraste_hipotesis_Rating = muestrasIndependientes_varianzasDesconocidas(df_copy_players_left$Rating, df_copy_players_right$Rating, 0.05)

contraste_hipotesis_Rating
```

```{r}
t.test(df_copy_players_left$Rating,
       df_copy_players_right$Rating,
       alternative="greater", 
       var.equal=FALSE)
```

Finalmente, volvemos a llamar al mismo método para realizar los cálculos sobre la variable Dribbling:
```{r}
contraste_hipotesis_Dribbling = muestrasIndependientes_varianzasDesconocidas(df_copy_players_left$Dribbling, df_copy_players_right$Dribbling, 0.05)

contraste_hipotesis_Dribbling
```

```{r}
t.test(df_copy_players_left$Dribbling,
       df_copy_players_right$Dribbling,
       alternative="greater", 
       var.equal=FALSE)
```

## Tabla de resultados

Incorporad una tabla de resultados con el formato que se indica a continuación. Adjuntamos el fragmento de
código que hemos usado para generar la tabla para que podáis usar este mismo formato. Necesitáis usar la
librería kableExtra (si es necesario, debéis instalarla previamente a su uso).

Escribimos el código proporcionado en la práctica:
```{r}
library(kableExtra)

out <- data.frame( var=c("Rating", "BallControl", "Dribbling"), 
                   mean_Left=c(mean(df_copy_players_left$Rating), mean(df_copy_players_left$Ball_Control), mean(df_copy_players_left$Dribbling)),
                   mean_Right=c(mean(df_copy_players_right$Rating), mean(df_copy_players_right$Ball_Control), mean(df_copy_players_right$Dribbling)), 
                   n_Left=c(length(df_copy_players_left$Rating),length(df_copy_players_left$Ball_Control), length(df_copy_players_left$Dribbling)), 
                   n_Right=c(length(df_copy_players_right$Rating), length(df_copy_players_right$Ball_Control), length(df_copy_players_right$Dribbling)), 
                   obs_value=c(contraste_hipotesis_Rating$Estadistico_Contraste, contraste_hipotesis_Ball_Control$Estadistico_Contraste, contraste_hipotesis_Dribbling$Estadistico_Contraste),
                   critical=c(contraste_hipotesis_Rating$U, contraste_hipotesis_Ball_Control$U, contraste_hipotesis_Dribbling$U), 
                   pvalue=c(contraste_hipotesis_Rating$P_Valor, contraste_hipotesis_Ball_Control$P_Valor, contraste_hipotesis_Dribbling$P_Valor))

out %>% kable() %>% kable_styling()
```

Cabe destacar que en la tabla el p-valor lo redondea directamente a 0, ya que éste es un número muy pequeño.

## Intepretación

A partir de los resultados obtenidos, realizad la interpretación de los mismos, dando respuesta a las preguntas
formuladas.

Una vez que ya tenemos todos los resultados calculados debemos responder a cada una de las pregutnas que nos hemos propuesto en el primer apartado:

- ¿El control de la pelota de los jugadores zurdos es mejor que el control de pelota de los jugadores diestros?

- ¿La valoración de los jugadores zurdos es mejor que la valoración de los jugadores diestros?

- ¿El dribbling de los jugadores zurdos es mejor que el dribbling de los jugadores diestros?

Para ello realizamos el contraste de hipótesis, para cada pregunta lo podemos resolver de dos maneras diferentes:

- La primera, comprobar si valor observado está fuera de la región de aceptación. Si está fuera podemos rechazar la hipótesis nula a favor de la alternativa. En nuestro caso la región de aceptación para todas las variables (Ball_Control, Rating, Dribbling) era un intervalo aproximado [-infinitoi, 1.645] y los valores observados que hemos obtenido para las variables Ball_Control, Rating, Dribbling son respectivamente: 15.182, 5.934 y 18.138. Como podemos apreciar, todos los valores están fuera de la región de aceptación, por lo que rechazamos la hipótesis nula a favor de la alternativa, lo cual significa, que es verdad que los jugadores zurdos son mejores que los diestros respecto al Ball_Control, al Rating y al Dribbling con un nivel de confianza del 95%.

- La segunda forma, podemos observar si el p-valor es menor que el nivel de significancia (p-valor < alfa), de ser cierto, podríamos rechazar la hipótesis nula en favor de la alternativa. En nuestro caso, el nivel de significancia es de 0.05, por lo que comprobamos si p-valor < 0.05, todas las variables analizadas tienen un p-valor próximo a 0, por lo que el p-valor siempre es menor que el alfa, por lo tanto, rechazamos la hipótesis nula y confirmamos que los jugadores zurdos son mejores que los diestros con un nivel de confianza del 95%.

# Comparación por pares

Nos preguntamos si obtendríamos el mismo resultado si comparásemos los jugadores de campo zurdos con aquellos jugadores de campo diestros que tienen un peso, altura y edad similar. Para dar respuesta a esta pregunta, realizaremos un proceso similar al denominado propensity score matching, aunque un poco simplificado. Realizaremos lo siguiente:

- Para cada jugador de campo zurdo, localizaremos el jugador de campo diestro más similar, en cuanto a peso, altura y edad.

- Para realizar esta búsqueda, debemos implementar un algoritmo del tipo vecino más cercano.

- Para calcular la similitud entre dos jugadores, nos basaremos en la función de distancia euclídea.

A partir de estas muestras, nos preguntaremos si los jugadores zurdos son mejores en Rating que los jugadores diestros relacionados.

## Jugador más similar

Lo primer de todo es definir la función que nos va a calcular la similitud entre dos jugadores, para ellos definimos la función de distancia euclídea:
```{r}
euclidean = function(x1, x2) {
  return(sqrt(sum((x1 - x2)^2)))
}
```

Posteriormente, definimos la función que dado un jugador calcule el jugador más similar en términos de edad, peso y altura:
```{r}
my.nn = function(x, sample) {
  dist_min = 9999999
  dist = 9999999
  pos = 0
  
  for(i in 1:nrow(sample)) {
    dist = euclidean(x, sample[i,])
    
    if(dist < dist_min) {
      dist_min = dist
      pos = i
    }
  }
  
  return(pos)
}
```

Una vez que hemos definido la función que dado un jugador calcula el más similar, creamos una nueva función para iterar sobre la muestra de los zurdos y así obtener la lista de emparejados:
```{r}
my.nn.sample = function(sample1, sample2) {
  Right.paired = data.frame()
  pos = 0
  
  for(i in 1:nrow(sample1)) {
    pos = my.nn(sample1[i, c("Height", "Weight", "Age")], sample2[, c("Height", "Weight", "Age")])
    Right.paired = rbind(Right.paired, sample2[pos,])
  }
  
  return(Right.paired)
}
```

## Muestras

Llegados a este punto, tenemos dos muestras: Left.sample, con los jugadores de campo zurdos. Y Right.paired, que contiene los jugadores diestros más similares a los jugadores de la muestra Left.sample.

Mostrad las primeras filas de las dos muestras.

Nota: Puede que el algoritmo del vecino más cercano necesite bastante tiempo en computarse, ya que las muestras contienen muchos datos. Si es así, os recomendamos que apliquéis el cálculo sobre una muestra de 100 jugadores zurdos. Podéis también tomar una muestra de 200 jugadores diestros. Así evitaréis el exceso de tiempo computacional requerido y la actividad se considera igualmente válida.

Lo primero que vamos a hacer es un sample de la muestra de zurdos de 100 y de diestros de 200:
```{r}
Left.sample = df_copy_players_left[1:100,]
Right.sample = df_copy_players_right[1:200,]
```

Una vez que tenemos las muestras llamamos a la función anterior para que nos devuelva la muestra emparejada:
```{r}
Right.paired = my.nn.sample(Left.sample, Right.sample)
```

Mostramos el dataframe correspondiente a la muestra de zurdos:
```{r}
head(Left.sample)
```

Mostramos el dataframe correspondiente a la muestra de diestros similares a los zurdos:
```{r}
head(Right.paired)
```

## Hipótesis nula y alternativa

A partir de las dos muestras, ¿podemos afirmar que los zurdos son mejores en Rating que los correspondientes
jugadores diestros? Escribid la hipótesis nula y alternativa.

Dada la pregunta establecida en el ejercicio, tenemos las siguientes hipótesis:

- H0 (hipótesis nula): rating de zurdos = rating de diestros.

- H1 (hipótesis alternativa): rating de zurdos > rating de diestros.

## Método

Explicad el método que aplicaréis y el por qué de su elección.

En este problema estamos hablando de un contraste sobre dos muestras que están relacionadas, ya que, para cada observación de la primera muestra se establece un relación (el jugador diestro más similar, según su peso, altura y edad) con una observación de la segunda muestra.

Además, sí que podríamos asumir normalidad, para asumir normalidad podemos aplicar el teorema del límite central, el cual nos indica que la media de una muestra que sea lo suficientemente grande (mayor de 30 observaciones) sigue una distribución normal. Al poder calcular la media de ambas muestras esto lo cumplimos, solo nos hace falta comprobar que tenemos el número de observaciones mínimas, pero tal y como vemos a continuación esto también se cumple:
```{r}
cat("El número de observaciones de zurdos es: ", nrow(Left.sample))
cat("El número de observaciones de diestros es: ", nrow(Right.paired))
```

El test es paramétrico, esto se debe a que los tests paramétricos son aquellos contrastes que trabajan con la asunción de que los datos siguen una determinada distribución, siendo la más habitual la normalidad de los datos, como bien hemos mencionado en el punto anterior sí que podríamos asumir normalidad de los datos por lo tanto es paramétrico.

Para saber si el bilateral o unilateral nos podemos fijar en cómo está definida la hipótesis alternativa, en nuestro caso está definida con el símbolo mayor ">", por lo que solo vamos a aceptar la hipótesis alternativa si el valor observado es mayor que el valor crítico, en ese caso rechazaríamos la hipótesis nula. Por lo tanto, este caso se trata de un problema unilateral por la derecha.

En resumen, estamos ante el contraste de dos muestras emparejadas sobre la media, con un test unilateral por la derecha.

## Cálculos

Realizad los cálculos de: estadístico de contraste, valor cítico y valor p. Usad un nivel de confianza del 95 %.

Nota: Los cálculos se deben realizar manualmente. No se pueden usar funciones de R que calculen directamente el contraste. En cambio, sí se pueden usar funciones como qnorm, pnorm, qt y pt.

Lo primero que debemos de hacer es definir la función que va a realizar los cálculos:
```{r}
muestrasEmparejadas = function(valores_left, valores_right, alfa) {
  
  # Calculamos los valores de las diferencias
  valores = valores_left - valores_right
  
  # Calculamos el estadístico de contraste
  d = mean(valores)
  sd = sd(valores)
  n = length(valores)
  
  z_obs = d / (sd / sqrt(n))
  
  # Calculamos los grados de libertad
  grados_libertad = n - 1
  
  # Calculamos el punto crítico
  z_cri = qt(alfa, df = grados_libertad, lower.tail = FALSE)
  
  # Calculamos el p-valor
  p_value = pt(z_obs, df = grados_libertad, lower.tail = FALSE)
  
  # Devolvemos los valores
  return(data.frame(L = "-INF", U = z_cri, Estadistico_Contraste = z_obs, P_Valor = p_value, Grados_Libertad = grados_libertad))
}
```

Una vez que hemos definidos la función que nos calcula los valores, la llamamos:
```{r}
contraste_hipotesis_Rating = muestrasEmparejadas(Left.sample$Rating, Right.paired$Rating, 0.05)
contraste_hipotesis_Rating
```

```{r}
t.test(Left.sample$Rating, Right.paired$Rating, paired = TRUE, alternative = "greater")
```

## Interpretación

Interpretad el resultado obtenido.

Una vez que ya tenemos todos los resultados calculados debemos responder a la pregunta que nos hemos planteado:

- ¿podemos afirmar que los zurdos son mejores en Rating que los correspondientes jugadores diestros?

Para ello realizamos el contraste de hipótesis, y lo podemos resolver de dos maneras diferentes:

- La primera, comprobar si valor observado está fuera de la región de aceptación. Si está fuera podemos rechazar la hipótesis nula a favor de la alternativa. En nuestro caso la región de aceptación es un intervalo aproximado [-infinito, 1.66] y el valor observado que hemos obtenido para el Rating es -6.312. Como podemos apreciar, el valor está dentro de la región de aceptación, por lo que no podemos rechazar la hipótesis nula, lo cual significa, que no es verdad que los jugadores zurdos son mejores que los diestros respecto al Rating con un nivel de confianza del 95%.

- La segunda forma, podemos observar si el p-valor es menor que el nivel de significancia (p-valor < alfa), de ser cierto, podríamos rechazar la hipótesis nula en favor de la alternativa. En nuestro caso, el nivel de significancia es de 0.05, por lo que comprobamos si p-valor < 0.05, la variable analizada tiene un p-valor igual a 1, por lo que el p-valor es mayor que alfa, por lo tanto, no podemos rechazar la hipótesis nula y confirmamos que los jugadores zurdos no son mejores que los diestros con un nivel de confianza del 95%.

## Reflexión

Comparad el análisis realizado en el apartado 3, con el realizado en este apartado. Explicad también qué sentido puede tener realizar una comparación de este tipo en relación al contraste de la pregunta 3.

Si recordamos el análisis realizado en el apartado 3, nos indicaba que sí que podíamos asumir que los jugadores zurdos tenían un mejor rating que los jugadores diestros con un nivel de confianza al 95%, mientras que en este ejercicio hemos comprobado para cada jugador zurdo si tenía una diferencia significativa en el rating respecto a los diestros, y hemos visto que no, que no podíamos asumir que los jugadores zurdos tengan un mejor rating que los jugadores diestros con un nivel de confianza al 95%.

Realizar este tipo de análisis respecto al del ejercicio 3 es muy interesante, ya que como podemos apreciar nos proporcionan resultados contradictorios, en el ejercicio 3 nos indica que sí que hay una diferencia significativa mientras que en este ejercicio no la hay.

Es interesante hacer este tipo de análisis, es decir, comparar las observaciones similares, ya que en el ejercicio 3 estábamos comparando a todos con todos, lo cual no es del todo correcto, porque si cogemos a Messi y lo comparamos con Puyol lógicamente sí que va a haber una diferencia significativa, tienen diferente altura, peso, edad, posición en el campo, habilidades técnicas... Lo más lógico es comparar aquellos jugadores que son más similares y ver de verdad si hay una diferencia significativa o no, ya que si en este tipo de análisis hay una diferencia significativa si realizamos el otro análisis lo más probable es que también la haya, por lo que considero que es mejor realizar este tipo de análisis (comparar si una muestra es mejor que otra pero con observaciones similares).

# Comparación entre clubes

Es bien conocida la rivalidad entre los clubes de Barcelona y Madrid. Se desea calcular si el porcentaje de jugadores con un Rating superior a 90 es diferente en Barcelona y Madrid con un nivel de confianza del 97 %.

Para ello, seguid los pasos que se especifican a continuación.

## Hipótesis nula y alternativa

Escribid la hipótesis nula y alternativa.

Las hipótesis que nos planteamos dada la pregunta del ejercicio son:

- H0 (hipótesis nula): proporción de jugadores del Barsa respecto al Rating = proporción de jugadores del Madrid respecto al Rating.

- H1 (hipótesis alternativa): proporción de jugadores del Barsa respecto al Rating != proporción de jugadores del Madrid respecto al Rating.

## Método

Explicad qué método aplicaréis para dar respuesta a la pregunta formulada. Justificad vuestra elección.

Dada la pregunta formulada estamos ante un caso de contraste entre dos muestras sobre la proporción, vamos a tener una muestra para los jugadores del Barsa y otra muestra para los jugadores del Madrid, y comprobaremos si la proporción de los jugadores del Barsa con un Rating mayor a 90 es diferente de la del Madrid.

El test por otro lado es paramétrico, esto se debe a que los tests paramétricos son aquellos contrastes que trabajan con la asunción de que los datos siguen una determinada distribución, siendo la más habitual la normalidad de los datos, como este tipo de contraste siguen una distribución normal(0,1) asumimos la normalidad de los datos.

Para saber si el bilateral o unilateral nos podemos fijar en cómo está definida la hipótesis alternativa, en nuestro caso está definida con el símbolo distinto "!=", por lo que vamos a rechazar la hipótesis nula tanto si es menor como si es mayor el valor observado respecto a la región de aceptación, por lo tanto estamos frente un problema bilateral.

## Cálculos

Preparad las muestras y realizad los cálculos oportunos. Al igual que anteriormente, no podéis usar funciones que ya realicen este contraste automáticamente. Sí podéis usar pnorm, qnorm, pt, qt.

Lo primero que debemos hacer es definir la función que nos va a proporcionar los calculos:
```{r}
muestrasProporcion = function(p1, p2, n1, n2, alfa) {
  
  # Calculamos el parámetro p a partir de la estimación
  p = ((n1 * p1) + (n2 * p2)) / (n1 + n2)
  
  # Calculamos el estadístico de contraste
  z_obs = (p1 - p2) / sqrt((p * (1 - p)) * ((1 / n1) + (1 / n2)))
  
  # Calculamos el punto crítico
  z_cri_left = qnorm(alfa/2, lower.tail = TRUE)
  z_cri_right = qnorm(alfa/2, lower.tail = FALSE)
  
  # Calculamos el p-valor
  p_value = pnorm(z_obs, lower.tail = FALSE) * 2
  
  # Devolvemos los valores
  return(data.frame(L = z_cri_left, U = z_cri_right, Estadistico_Contraste = z_obs, P_Valor = p_value))
}
```

Una vez definida la función la llamamos con los datos correspondientes, en este caso tenemos en cuenta también a los porteros:
```{r}
df_barsa = df_copy[df_copy$Club == "FC Barcelona",]
df_madrid = df_copy[df_copy$Club == "Real Madrid",]
n1 = nrow(df_barsa)
n2 = nrow(df_madrid)
p1 = nrow(df_barsa[df_barsa$Rating > 90, ]) / n1
p2 = nrow(df_madrid[df_madrid$Rating > 90, ]) / n2

contraste_hipotesis_proporcion = muestrasProporcion(p1, p2, n1, n2, 0.03)
contraste_hipotesis_proporcion
```

```{r}
prop.test(c(p1 * n1, p2 * n2), c(n1, n2), alternative = "two.sided", correct = FALSE, conf.level = 0.97)
```

## Resultados e interpretación

Tal y como podemos ver el intervalo de la región de aceptación es próximo a [-2.17, 2.17], nuestro estadístico nos proporciona una valor aproximado de 1.03, como el valor aproximado está dentro de la región de aceptación no podemos rechazar la hipótesis nula, lo que significa que la proporción de los jugadores del barsa con un rating mayor que 90 respecto a la del madrid no es significatva con un nivel de confianza al 97%.

Otra forma de concluir los resultados es a partir del p-valor, si el p-valor < alfa rechazamos la hipótesis nula, en nuestro caso el p-valor es aproximadamente 0.302 y nuestro nivel de significancia es de 0.03, por lo tanto, p-valor > alfa, entonces no podemos rechazar la hipótesis nula.

# Resumen ejecutivo

Una vez resueltos cada uno de los ejercicios, hemos llegado a las siguientes conclusiones:

- Respecto al ejercicio 3, buscábamos comparar si era verdad que los jugadores zurdos eran mejores que los jugadores diestros, pero en este caso todos con todos. Tras el análisis hemos visto que sí que podíamos concluir que los jugadores zurdos eran mejores que los diestros con un nivel de confianza al 95%.

- Respecto al ejercicio 4, hemos vuelto a comparar si era verdad que los jugadores zurdos eran mejores que los diestros, pero haciendo esta comparación entre los similares (peso, edad y altura). Tras haber realizado el análisis correspondiente, llegamos a la conclusión de que no podíamos afirmar que los jugadores zurdos eran mejores que los jugadores diestros similares con un nivel de confianza al 95%.

- Respecto al ejercicio 5, hemos tenido que analizar si la proporción de jugadores del barsa con un rating superior a 90 era mayor que la de los jugadores del madrid, pero hemos llegado a la conclusión de que no era una diferencia significativa con un nivel de confianza del 97%.
